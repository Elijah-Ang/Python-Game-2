{
  "1": {
    "id": 1,
    "title": "What is a Variable?",
    "content": "# üì¶ What is a Variable?\n\n## Definition\nA **variable** is a named container that stores data in your computer's memory. Think of it like a labeled box where you can put things and retrieve them later.\n\n## Why Do We Need Variables?\n\nImagine you're calculating someone's age. Without variables, you'd have to remember the number (like 25) and type it every time. With a variable, you give it a name (like `age`) and the computer remembers it for you!\n\n## Real-World Analogy\n\nThink of a variable like a **sticky note on a box**:\n- The **box** holds something (a piece of data)\n- The **sticky note** has a name written on it (the variable name)\n- When you need what's inside, you just look for the note!\n\n## How to Create a Variable\n\nIn Python, creating a variable is simple:\n\n```python\n# variable_name = value\nage = 25\nname = \"Alice\"\nprice = 19.99\n```\n\nThe `=` sign means \"store this value in this variable name.\"\n\n## Key Vocabulary\n\n| Term | Meaning |\n| --- | --- |\n| **Variable** | A named container for data |\n| **Value** | The actual data stored (like 25 or \"Alice\") |\n| **Assignment** | The act of storing a value in a variable using `=` |\n\n---\n\n## üéØ Your Task\n\nCreate a variable called `student` and set it to `\"Alice\"`. Then print it!\n",
    "starter_code": "# Create a variable called student with value \"Alice\"\n\n\n# Print the variable\n",
    "solution_code": "# Create a variable called student with value \"Alice\"\nstudent = \"Alice\"\n\n# Print the variable\nprint(student)",
    "expected_output": "Alice",
    "chapter_id": 1,
    "chapter_title": "Variables, Types & Memory"
  },
  "2": {
    "id": 2,
    "title": "Naming Variables",
    "content": "# üè∑Ô∏è How to Name Variables\n\n## Why Does Naming Matter?\n\nGood variable names make your code **readable**. Compare:\n\n```python\n# Bad - What is x? What is y?\nx = 25\ny = 75000\n\n# Good - Clear what each variable represents!\nage = 25\nsalary = 75000\n```\n\nWhen you (or someone else) read the code later, good names save time and prevent confusion.\n\n## Python's Naming Rules\n\nThese are rules you MUST follow or Python will give an error:\n\n| Rule | ‚úÖ Valid | ‚ùå Invalid |\n| --- | --- | --- |\n| Can start with letter or _ | `name`, `_count` | ‚Äî |\n| Cannot start with number | ‚Äî | `2name` |\n| No spaces allowed | `my_name` | `my name` |\n| Only letters, numbers, _ | `user_1` | `user-name` |\n| Case sensitive | `Age` ‚â† `age` | ‚Äî |\n\n## Naming Conventions (Best Practices)\n\nThese aren't required, but make your code professional:\n\n```python\n# ‚úÖ Use snake_case (lowercase with underscores)\nuser_name = \"Alice\"\ntotal_price = 99.99\n\n# ‚ùå Avoid starting with uppercase (reserved for classes)\nUserName = \"Alice\"  # Works but not conventional\n\n# ‚úÖ Be descriptive\ncustomer_email = \"alice@email.com\"\n\n# ‚ùå Avoid single letters (except for loops)\ne = \"alice@email.com\"  # What is 'e'?\n```\n\n---\n\n## üéØ Your Task\n\nCreate these two properly named variables:\n- `first_name` = `\"John\"`\n- `last_name` = `\"Doe\"`\n\nThen print both.\n",
    "starter_code": "# Create first_name variable\n\n\n# Create last_name variable\n\n\n# Print both\n",
    "solution_code": "# Create first_name variable\nfirst_name = \"John\"\n\n# Create last_name variable\nlast_name = \"Doe\"\n\n# Print both\nprint(first_name)\nprint(last_name)",
    "expected_output": "John\nDoe",
    "chapter_id": 1,
    "chapter_title": "Variables, Types & Memory"
  },
  "3": {
    "id": 3,
    "title": "Reassigning Variables",
    "content": "# üîÑ Changing Variable Values\n\n## What is Reassignment?\n\nVariables can change! You can update a variable by assigning a new value:\n\n```python\nscore = 0          # Start at 0\nprint(score)       # Output: 0\n\nscore = 100        # Now it's 100!\nprint(score)       # Output: 100\n```\n\n## Why Does This Matter?\n\nIn real programs, values change constantly:\n- A player's score goes up\n- A shopping cart total increases\n- A countdown timer decreases\n\n## How It Works in Memory\n\nWhen you reassign:\n1. Python finds the variable name\n2. Throws away the old value\n3. Stores the new value\n\n```python\ntemperature = 72   # Box now holds 72\ntemperature = 85   # Box now holds 85 (72 is gone!)\n```\n\n## Using the Current Value\n\nYou can use a variable's current value to calculate a new one:\n\n```python\ncount = 5\ncount = count + 1  # Take current (5), add 1, store result (6)\nprint(count)       # Output: 6\n```\n\nShorthand version:\n```python\ncount += 1  # Same as: count = count + 1\n```\n\n---\n\n## üéØ Your Task\n\n1. Start with `points = 0`\n2. Add 10 to points using `+=`\n3. Add 5 more to points using `+=`\n4. Print the final value (should be 15)\n",
    "starter_code": "# Start with 0 points\npoints = 0\n\n# Add 10 points\n\n\n# Add 5 more points\n\n\n# Print final value\n",
    "solution_code": "# Start with 0 points\npoints = 0\n\n# Add 10 points\npoints += 10\n\n# Add 5 more points\npoints += 5\n\n# Print final value\nprint(points)",
    "expected_output": "15",
    "chapter_id": 1,
    "chapter_title": "Variables, Types & Memory"
  },
  "4": {
    "id": 4,
    "title": "Multiple Variables",
    "content": "# üìã Working with Multiple Variables\n\n## Assigning Multiple Variables\n\nYou can create several variables at once:\n\n```python\n# One per line (most clear)\nname = \"Alice\"\nage = 25\ncity = \"New York\"\n\n# All on one line (for related values)\nx, y, z = 10, 20, 30\n```\n\n## Swapping Variables\n\nSometimes you need to swap two values. Python makes this easy:\n\n```python\na = 5\nb = 10\n\n# Swap them!\na, b = b, a\n\nprint(a)  # 10\nprint(b)  # 5\n```\n\nIn other languages, you'd need a temporary variable. Python handles it elegantly!\n\n## Using Variables Together\n\nVariables can reference each other:\n\n```python\nprice = 20\nquantity = 3\ntotal = price * quantity  # total is now 60\n\nprint(f\"Total: ${total}\")\n```\n\n---\n\n## üéØ Your Task\n\nCreate variables for a product's name, price, and quantity:\n- `product` = `\"Laptop\"`\n- `price` = `999`\n- `quantity` = `2`\n\nCalculate `total` as price √ó quantity, then print:\n```\nProduct: Laptop\nTotal: 1998\n```\n",
    "starter_code": "# Product information\nproduct = \"Laptop\"\nprice = 999\nquantity = 2\n\n# Calculate total\n\n\n# Print product and total\n",
    "solution_code": "# Product information\nproduct = \"Laptop\"\nprice = 999\nquantity = 2\n\n# Calculate total\ntotal = price * quantity\n\n# Print product and total\nprint(f\"Product: {product}\")\nprint(f\"Total: {total}\")",
    "expected_output": "Product: Laptop\nTotal: 1998",
    "chapter_id": 1,
    "chapter_title": "Variables, Types & Memory"
  },
  "5": {
    "id": 5,
    "title": "What are Strings?",
    "content": "# üìù What is a String?\n\n## Definition\n\nA **string** is a sequence of characters (letters, numbers, symbols, spaces) surrounded by quotes. It's how we represent text in programming.\n\n```python\nmessage = \"Hello, World!\"\nname = 'Alice'  # Single or double quotes both work\n```\n\n## Why Do We Need Strings?\n\nNearly every program works with text:\n- User names, emails, addresses\n- Messages and notifications\n- File paths and URLs\n- Any data that isn't purely numeric\n\n## Types of Quotes\n\nPython accepts three types:\n\n```python\n# Single quotes\ngreeting = 'Hello'\n\n# Double quotes (same as single)\ngreeting = \"Hello\"\n\n# Triple quotes (for multi-line text)\npoem = \"\"\"Roses are red,\nViolets are blue,\nPython is awesome,\nAnd so are you!\"\"\"\n```\n\n## When to Use Which?\n\n```python\n# Use double quotes if string contains single quote\nsentence = \"It's a beautiful day\"\n\n# Use single quotes if string contains double quote\nhtml = '<div class=\"container\">'\n```\n\n---\n\n## üéØ Your Task\n\nCreate these strings:\n- `greeting` = `\"Hello\"`\n- `name` = `\"Python\"`\n\nPrint: `Hello, Python!`\n",
    "starter_code": "# Create greeting\ngreeting = \"Hello\"\n\n# Create name\nname = \"Python\"\n\n# Print greeting, name!\n",
    "solution_code": "# Create greeting\ngreeting = \"Hello\"\n\n# Create name\nname = \"Python\"\n\n# Print greeting, name!\nprint(greeting + \", \" + name + \"!\")",
    "expected_output": "Hello, Python!",
    "chapter_id": 1,
    "chapter_title": "Variables, Types & Memory"
  },
  "6": {
    "id": 6,
    "title": "String Concatenation",
    "content": "# üîó Joining Strings Together\n\n## What is Concatenation?\n\n**Concatenation** means joining strings end-to-end. Use the `+` operator:\n\n```python\nfirst = \"Hello\"\nsecond = \"World\"\ncombined = first + second\nprint(combined)  # HelloWorld\n```\n\n## Adding Spaces\n\nNotice there's no automatic space! You must add it:\n\n```python\ncombined = first + \" \" + second\nprint(combined)  # Hello World\n```\n\n## Why Use Concatenation?\n\nBuilding messages with dynamic data:\n\n```python\nname = \"Alice\"\nmessage = \"Welcome, \" + name + \"!\"\nprint(message)  # Welcome, Alice!\n```\n\n## Repeating Strings\n\nUse `*` to repeat a string:\n\n```python\nline = \"-\" * 20\nprint(line)  # --------------------\n\ncheer = \"Hip \" * 2 + \"Hooray!\"\nprint(cheer)  # Hip Hip Hooray!\n```\n\n---\n\n## üéØ Your Task\n\nGiven:\n- `first_name` = `\"Jane\"`\n- `last_name` = `\"Smith\"`\n\nCreate `full_name` by joining them with a space.\nThen print: `Welcome, Jane Smith!`\n",
    "starter_code": "# Given names\nfirst_name = \"Jane\"\nlast_name = \"Smith\"\n\n# Join them into full_name\n\n\n# Print welcome message\n",
    "solution_code": "# Given names\nfirst_name = \"Jane\"\nlast_name = \"Smith\"\n\n# Join them into full_name\nfull_name = first_name + \" \" + last_name\n\n# Print welcome message\nprint(\"Welcome, \" + full_name + \"!\")",
    "expected_output": "Welcome, Jane Smith!",
    "chapter_id": 1,
    "chapter_title": "Variables, Types & Memory"
  },
  "7": {
    "id": 7,
    "title": "F-Strings (Formatted Strings)",
    "content": "# ‚ú® F-Strings: The Modern Way\n\n## What are F-Strings?\n\nF-strings (formatted string literals) let you embed variables directly in text. Just add `f` before the quote and put variables in `{}`:\n\n```python\nname = \"Alice\"\nage = 25\nmessage = f\"My name is {name} and I'm {age} years old.\"\nprint(message)\n# Output: My name is Alice and I'm 25 years old.\n```\n\n## Why F-Strings are Better\n\nCompare concatenation vs f-strings:\n\n```python\n# Old way (messy)\nmessage = \"Hello, \" + name + \"! You have \" + str(score) + \" points.\"\n\n# F-string way (clean!)\nmessage = f\"Hello, {name}! You have {score} points.\"\n```\n\nF-strings are:\n- Easier to read\n- Less error-prone\n- No need to convert numbers to strings\n\n## Expressions Inside F-Strings\n\nYou can put any expression in `{}`:\n\n```python\nprice = 19.99\nquantity = 3\nprint(f\"Total: ${price * quantity}\")  # Total: $59.97\n\n# Formatting numbers\nprint(f\"Price: ${price:.2f}\")  # Price: $19.99 (2 decimal places)\n```\n\n---\n\n## üéØ Your Task\n\nGiven:\n- `item` = `\"Coffee\"`\n- `price` = `4.50`\n\nUse an f-string to print: `Coffee costs $4.5`\n",
    "starter_code": "# Given data\nitem = \"Coffee\"\nprice = 4.50\n\n# Print using f-string\n",
    "solution_code": "# Given data\nitem = \"Coffee\"\nprice = 4.50\n\n# Print using f-string\nprint(f\"{item} costs ${price}\")",
    "expected_output": "Coffee costs $4.5",
    "chapter_id": 1,
    "chapter_title": "Variables, Types & Memory"
  },
  "8": {
    "id": 8,
    "title": "String Methods",
    "content": "# üõ†Ô∏è String Methods\n\n## What are Methods?\n\nMethods are **actions** you can perform on strings. Use dot notation: `string.method()`\n\n## Common String Methods\n\n```python\ntext = \"Hello World\"\n\ntext.upper()      # \"HELLO WORLD\"\ntext.lower()      # \"hello world\"\ntext.title()      # \"Hello World\"\ntext.strip()      # Removes whitespace from ends\ntext.replace(\"Hello\", \"Hi\")  # \"Hi World\"\ntext.split(\" \")   # [\"Hello\", \"World\"]\nlen(text)         # 11 (length - not a method, but useful!)\n```\n\n## Why These Are Useful\n\n| Method | Use Case |\n| --- | --- |\n| `.upper()/.lower()` | Case-insensitive comparison |\n| `.strip()` | Clean user input |\n| `.replace()` | Find and replace text |\n| `.split()` | Break text into parts |\n\n## Example: Cleaning User Input\n\n```python\nuser_input = \"  Alice  \"\nclean_name = user_input.strip().title()\nprint(clean_name)  # \"Alice\"\n```\n\n## Chaining Methods\n\nMethods return new strings, so you can chain them:\n\n```python\nmessy = \"   hELLo wORLD   \"\nclean = messy.strip().lower().title()\nprint(clean)  # \"Hello World\"\n```\n\n---\n\n## üéØ Your Task\n\nGiven: `messy_email = \"  JOHN@EMAIL.COM  \"`\n\nClean it up:\n1. Remove extra spaces with `.strip()`\n2. Convert to lowercase with `.lower()`\n3. Print the result: `john@email.com`\n",
    "starter_code": "# Messy email\nmessy_email = \"  JOHN@EMAIL.COM  \"\n\n# Clean it: strip and lowercase\n\n\n# Print cleaned email\n",
    "solution_code": "# Messy email\nmessy_email = \"  JOHN@EMAIL.COM  \"\n\n# Clean it: strip and lowercase\nclean_email = messy_email.strip().lower()\n\n# Print cleaned email\nprint(clean_email)",
    "expected_output": "john@email.com",
    "chapter_id": 1,
    "chapter_title": "Variables, Types & Memory"
  },
  "9": {
    "id": 9,
    "title": "Numbers: Integers and Floats",
    "content": "# üî¢ Numbers in Python\n\n## Two Main Types of Numbers\n\nPython has two types of numbers:\n\n| Type | Definition | Examples |\n| --- | --- | --- |\n| **Integer (int)** | Whole numbers, no decimal | `10`, `-5`, `0`, `1000` |\n| **Float** | Numbers with decimals | `3.14`, `-2.5`, `0.0` |\n\n## Why Two Types?\n\n- **Integers** are precise and faster (good for counting)\n- **Floats** are needed for measurements, science, money\n\n```python\ncount = 42       # Integer - exact count\nprice = 19.99    # Float - needs decimals\ntemperature = 98.6\n```\n\n## Python Auto-Detects the Type\n\n```python\nwhole = 10      # Python sees int\ndecimal = 10.0  # Python sees float\n\n# Check the type\nprint(type(whole))    # <class 'int'>\nprint(type(decimal))  # <class 'float'>\n```\n\n## Converting Between Types\n\n```python\nx = 10\ny = float(x)    # 10.0 (now a float)\n\nz = 10.7\nw = int(z)      # 10 (decimals cut off, not rounded!)\n```\n\n---\n\n## üéØ Your Task\n\nCreate:\n- `quantity` = `5` (integer)\n- `unit_price` = `12.50` (float)\n- `total` = quantity √ó unit_price\n\nPrint: `Total: 62.5`\n",
    "starter_code": "# Create quantity (integer)\nquantity = 5\n\n# Create unit_price (float)\nunit_price = 12.50\n\n# Calculate total\n\n\n# Print total\n",
    "solution_code": "# Create quantity (integer)\nquantity = 5\n\n# Create unit_price (float)\nunit_price = 12.50\n\n# Calculate total\ntotal = quantity * unit_price\n\n# Print total\nprint(f\"Total: {total}\")",
    "expected_output": "Total: 62.5",
    "chapter_id": 1,
    "chapter_title": "Variables, Types & Memory"
  },
  "10": {
    "id": 10,
    "title": "Math Operations",
    "content": "# ‚ûï Math in Python\n\n## Basic Operations\n\nPython supports all standard math:\n\n| Operator | Name | Example | Result |\n| --- | --- | --- | --- |\n| `+` | Addition | `5 + 3` | `8` |\n| `-` | Subtraction | `5 - 3` | `2` |\n| `*` | Multiplication | `5 * 3` | `15` |\n| `/` | Division | `5 / 2` | `2.5` |\n| `**` | Power | `5 ** 2` | `25` |\n| `//` | Floor Division | `5 // 2` | `2` |\n| `%` | Modulo (remainder) | `5 % 2` | `1` |\n\n## Understanding Floor Division and Modulo\n\n- `//` gives the **whole number** part of division\n- `%` gives the **remainder**\n\n```python\n17 // 5  # 3 (17 goes into 5 three times)\n17 % 5   # 2 (with 2 left over)\n```\n\n## Order of Operations (PEMDAS)\n\nPython follows standard math order:\n1. **P**arentheses `()`\n2. **E**xponents `**`\n3. **M**ultiplication & **D**ivision `* / // %`\n4. **A**ddition & **S**ubtraction `+ -`\n\n```python\nresult = 2 + 3 * 4      # 14 (not 20!)\nresult = (2 + 3) * 4    # 20 (parentheses first)\n```\n\n---\n\n## üéØ Your Task\n\nCalculate a restaurant tip:\n- `bill` = `80.00`\n- `tip_percent` = `20`\n- Calculate `tip` as 20% of bill\n- Calculate `total` as bill + tip\n\nPrint: `Tip: 16.0` and `Total: 96.0`\n",
    "starter_code": "# Bill amount\nbill = 80.00\ntip_percent = 20\n\n# Calculate tip (20% of bill)\n\n\n# Calculate total\n\n\n# Print tip and total\n",
    "solution_code": "# Bill amount\nbill = 80.00\ntip_percent = 20\n\n# Calculate tip (20% of bill)\ntip = bill * (tip_percent / 100)\n\n# Calculate total\ntotal = bill + tip\n\n# Print tip and total\nprint(f\"Tip: {tip}\")\nprint(f\"Total: {total}\")",
    "expected_output": "Tip: 16.0\nTotal: 96.0",
    "chapter_id": 1,
    "chapter_title": "Variables, Types & Memory"
  },
  "11": {
    "id": 11,
    "title": "Compound Assignment",
    "content": "# üìù Shorthand Math Operations\n\n## What is Compound Assignment?\n\nInstead of writing `x = x + 5`, Python has shorter versions:\n\n| Long Form | Shorthand | Meaning |\n| --- | --- | --- |\n| `x = x + 5` | `x += 5` | Add 5 to x |\n| `x = x - 5` | `x -= 5` | Subtract 5 from x |\n| `x = x * 5` | `x *= 5` | Multiply x by 5 |\n| `x = x / 5` | `x /= 5` | Divide x by 5 |\n| `x = x ** 2` | `x **= 2` | Square x |\n\n## Why Use Shorthand?\n\n1. Less typing\n2. Clearer intent (you're modifying, not replacing)\n3. Industry standard practice\n\n```python\nscore = 0\nscore += 10   # Player earns 10 points\nscore += 25   # Player earns 25 more\nscore -= 5    # Player loses 5 points\nprint(score)  # 30\n```\n\n## Common Use: Counters and Accumulators\n\n```python\n# Counting\ncount = 0\ncount += 1\ncount += 1\ncount += 1\nprint(count)  # 3\n\n# Running total\ntotal = 0\ntotal += 100\ntotal += 50\ntotal += 25\nprint(total)  # 175\n```\n\n---\n\n## üéØ Your Task\n\nSimulate a game:\n1. Start `health = 100`\n2. Take 25 damage (use `-=`)\n3. Heal 10 health (use `+=`)\n4. Print final health (should be 85)\n",
    "starter_code": "# Start with full health\nhealth = 100\n\n# Take 25 damage\n\n\n# Heal 10 health\n\n\n# Print final health\n",
    "solution_code": "# Start with full health\nhealth = 100\n\n# Take 25 damage\nhealth -= 25\n\n# Heal 10 health\nhealth += 10\n\n# Print final health\nprint(health)",
    "expected_output": "85",
    "chapter_id": 1,
    "chapter_title": "Variables, Types & Memory"
  },
  "12": {
    "id": 12,
    "title": "Booleans and Type Conversion",
    "content": "# ‚≠ï Booleans: True or False\n\n## What is a Boolean?\n\nA **Boolean** (named after mathematician George Boole) can only be one of two values:\n- `True`\n- `False`\n\n```python\nis_sunny = True\nis_raining = False\n```\n\n## Why Are Booleans Important?\n\nBooleans are the foundation of **decision making** in code:\n\n```python\nis_adult = age >= 18\nis_logged_in = True\nhas_permission = user_role == \"admin\"\n```\n\nWe'll use these extensively in the Logic chapter!\n\n## Type Conversion\n\nYou can convert between types:\n\n```python\n# To integer\nint(\"42\")       # 42\nint(3.7)        # 3 (truncates, doesn't round!)\n\n# To float\nfloat(\"3.14\")   # 3.14\nfloat(5)        # 5.0\n\n# To string\nstr(42)         # \"42\"\nstr(3.14)       # \"3.14\"\n\n# To boolean\nbool(1)         # True\nbool(0)         # False\nbool(\"\")        # False (empty string)\nbool(\"hello\")   # True (non-empty string)\n```\n\n## Common Use: User Input\n\n```python\n# input() always returns a string!\nage_text = \"25\"\nage = int(age_text)  # Convert to number for math\n```\n\n---\n\n## üéØ Your Task\n\nGiven: `age_text = \"25\"`\n\n1. Convert it to an integer using `int()`\n2. Add 5 to get age in 5 years\n3. Print the future age (should be 30)\n",
    "starter_code": "# Age as a string\nage_text = \"25\"\n\n# Convert to integer\n\n\n# Add 5 years\n\n\n# Print future age\n",
    "solution_code": "# Age as a string\nage_text = \"25\"\n\n# Convert to integer\nage = int(age_text)\n\n# Add 5 years\nfuture_age = age + 5\n\n# Print future age\nprint(future_age)",
    "expected_output": "30",
    "chapter_id": 1,
    "chapter_title": "Variables, Types & Memory"
  },
  "13": {
    "id": 13,
    "title": "For Loop Basics",
    "content": "# üîÅ For Loops: Repeat Actions\n\n## What is a Loop?\n\nA **loop** lets you repeat code multiple times without writing it over and over. It's one of the most powerful tools in programming!\n\n## Real-World Analogy\n\nImagine you need to greet 100 guests at a party. Instead of saying \"Hello\" 100 times manually, you'd use a loop: \"For each guest, say Hello.\"\n\n## The For Loop\n\nA `for` loop repeats code for each item in a sequence:\n\n```python\n# For each item in the sequence...\nfor item in sequence:\n    # Do something with item\n    print(item)\n```\n\n## Example: Looping Through a List\n\n```python\nfruits = [\"apple\", \"banana\", \"cherry\"]\nfor fruit in fruits:\n    print(fruit)\n```\n\nOutput:\n```\napple\nbanana\ncherry\n```\n\n## How It Works Step by Step\n\n1. Python takes the first item (\"apple\") and stores it in `fruit`\n2. Runs the indented code (prints \"apple\")\n3. Takes the next item (\"banana\") and stores it in `fruit`\n4. Runs the indented code (prints \"banana\")\n5. Continues until no items left\n\n---\n\n## üéØ Your Task\n\nGiven this list:\n```python\ncolors = [\"red\", \"green\", \"blue\"]\n```\n\nUse a for loop to print each color on a new line.\n",
    "starter_code": "colors = [\"red\", \"green\", \"blue\"]\n\n# Print each color\n",
    "solution_code": "colors = [\"red\", \"green\", \"blue\"]\n\n# Print each color\nfor color in colors:\n    print(color)",
    "expected_output": "red\ngreen\nblue",
    "chapter_id": 2,
    "chapter_title": "Loops (Iteration)"
  },
  "14": {
    "id": 14,
    "title": "Looping Through Strings",
    "content": "# üìù Looping Through Strings\n\n## Strings Are Sequences Too!\n\nA string is actually a sequence of characters. You can loop through it just like a list:\n\n```python\nword = \"Hello\"\nfor letter in word:\n    print(letter)\n```\n\nOutput:\n```\nH\ne\nl\nl\no\n```\n\n## Why Loop Through Strings?\n\nCommon use cases:\n- Counting specific characters\n- Checking each character for validity\n- Transforming characters one by one\n- Finding patterns\n\n## Example: Count Vowels\n\n```python\ntext = \"hello world\"\nvowel_count = 0\nfor char in text:\n    if char in \"aeiou\":\n        vowel_count += 1\nprint(f\"Vowels: {vowel_count}\")  # Vowels: 3\n```\n\n## Understanding Characters\n\nEach loop iteration gives you ONE character:\n\n```python\nfor char in \"ABC\":\n    print(f\"Character: '{char}'\")\n# Output:\n# Character: 'A'\n# Character: 'B'\n# Character: 'C'\n```\n\n---\n\n## üéØ Your Task\n\nLoop through the word `\"Python\"` and print each letter on a separate line.\n",
    "starter_code": "word = \"Python\"\n\n# Print each letter\n",
    "solution_code": "word = \"Python\"\n\n# Print each letter\nfor letter in word:\n    print(letter)",
    "expected_output": "P\ny\nt\nh\no\nn",
    "chapter_id": 2,
    "chapter_title": "Loops (Iteration)"
  },
  "15": {
    "id": 15,
    "title": "Accumulating Values",
    "content": "# ‚ûï Accumulating Values in Loops\n\n## The Accumulator Pattern\n\nOne of the most common loop patterns: start with a value, then update it each iteration.\n\n```python\n# Start with an initial value\ntotal = 0\n\n# Loop and accumulate\nfor num in [1, 2, 3, 4, 5]:\n    total += num  # Add each number\n\nprint(total)  # 15\n```\n\n## How It Works Step by Step\n\n| Iteration | `num` | `total` before | Action | `total` after |\n| --- | --- | --- | --- | --- |\n| 1 | 1 | 0 | 0 + 1 | 1 |\n| 2 | 2 | 1 | 1 + 2 | 3 |\n| 3 | 3 | 3 | 3 + 3 | 6 |\n| 4 | 4 | 6 | 6 + 4 | 10 |\n| 5 | 5 | 10 | 10 + 5 | 15 |\n\n## Other Accumulator Examples\n\n```python\n# Product\nproduct = 1\nfor num in [2, 3, 4]:\n    product *= num\nprint(product)  # 24\n\n# String building\nsentence = \"\"\nwords = [\"Hello\", \"World\", \"!\"]\nfor word in words:\n    sentence += word + \" \"\nprint(sentence)  # \"Hello World ! \"\n```\n\n---\n\n## üéØ Your Task\n\nGiven: `numbers = [10, 20, 30, 40]`\n\nCalculate and print the sum using the accumulator pattern.\n",
    "starter_code": "numbers = [10, 20, 30, 40]\ntotal = 0\n\n# Add each number to total\n\n\n# Print the sum\n",
    "solution_code": "numbers = [10, 20, 30, 40]\ntotal = 0\n\n# Add each number to total\nfor num in numbers:\n    total += num\n\n# Print the sum\nprint(total)",
    "expected_output": "100",
    "chapter_id": 2,
    "chapter_title": "Loops (Iteration)"
  },
  "16": {
    "id": 16,
    "title": "Using range()",
    "content": "# üìä The range() Function\n\n## What is range()?\n\n`range()` generates a sequence of numbers. It's perfect when you need to repeat something a specific number of times.\n\n```python\nfor i in range(5):\n    print(i)\n# Output: 0, 1, 2, 3, 4\n```\n\n## Why Start at 0?\n\nPython (like most languages) uses **zero-based indexing**. This means counting starts at 0, not 1.\n\n```python\nrange(5)  # Generates: 0, 1, 2, 3, 4 (that's 5 numbers!)\n```\n\n## Common Pattern: Repeat N Times\n\nIf you just want to repeat something:\n\n```python\nfor i in range(3):\n    print(\"Hello!\")\n# Output: Hello! Hello! Hello!\n```\n\n## range() Returns a Special Object\n\nNote: `range()` doesn't create a list immediately (to save memory). But it works in for loops!\n\n```python\nprint(range(5))       # range(0, 5) - the object\nprint(list(range(5))) # [0, 1, 2, 3, 4] - converted to list\n```\n\n---\n\n## üéØ Your Task\n\nUse `range(5)` to print numbers 0 through 4, each on a new line.\n",
    "starter_code": "# Print 0 through 4 using range\n",
    "solution_code": "# Print 0 through 4 using range\nfor i in range(5):\n    print(i)",
    "expected_output": "0\n1\n2\n3\n4",
    "chapter_id": 2,
    "chapter_title": "Loops (Iteration)"
  },
  "17": {
    "id": 17,
    "title": "range() with Start and End",
    "content": "# üìà range(start, end)\n\n## Two Arguments: Start and Stop\n\nWith two arguments, you control where to start:\n\n```python\nrange(start, stop)  # From start up to (but not including) stop\n```\n\n## Example\n\n```python\nfor i in range(2, 5):\n    print(i)\n# Output: 2, 3, 4\n```\n\nNotice: 5 is NOT included! Python ranges are **exclusive** of the end value.\n\n## Mental Model\n\nThink of it as: \"start here, stop BEFORE this\"\n\n```python\nrange(1, 4)   # 1, 2, 3 (stops before 4)\nrange(5, 10)  # 5, 6, 7, 8, 9 (stops before 10)\n```\n\n## To Include the End Number\n\nIf you want 1-10 inclusive, use `range(1, 11)`:\n\n```python\nfor i in range(1, 11):\n    print(i, end=\" \")\n# Output: 1 2 3 4 5 6 7 8 9 10\n```\n\n---\n\n## üéØ Your Task\n\nPrint numbers from 5 to 10 (inclusive).\nUse `range(5, 11)` since the end is exclusive.\n",
    "starter_code": "# Print 5 through 10\n",
    "solution_code": "# Print 5 through 10\nfor i in range(5, 11):\n    print(i)",
    "expected_output": "5\n6\n7\n8\n9\n10",
    "chapter_id": 2,
    "chapter_title": "Loops (Iteration)"
  },
  "18": {
    "id": 18,
    "title": "range() with Step",
    "content": "# ü¶ò range(start, end, step)\n\n## Three Arguments: Adding a Step\n\nThe third argument controls how much to increment:\n\n```python\nrange(start, stop, step)\n```\n\n## Example: Skip by 2\n\n```python\nfor i in range(0, 10, 2):\n    print(i)\n# Output: 0, 2, 4, 6, 8\n```\n\n## Common Step Patterns\n\n```python\n# Even numbers (0-10)\nrange(0, 11, 2)  # 0, 2, 4, 6, 8, 10\n\n# Odd numbers (1-9)\nrange(1, 10, 2)  # 1, 3, 5, 7, 9\n\n# Count by 5s\nrange(0, 26, 5)  # 0, 5, 10, 15, 20, 25\n\n# Count by 10s\nrange(10, 101, 10)  # 10, 20, 30, ... 100\n```\n\n## Counting Backwards\n\nUse a negative step to go in reverse:\n\n```python\nfor i in range(10, 0, -1):\n    print(i)\n# Output: 10, 9, 8, 7, 6, 5, 4, 3, 2, 1\n```\n\n---\n\n## üéØ Your Task\n\nPrint even numbers from 2 to 10 (inclusive).\nUse `range(2, 11, 2)`.\n",
    "starter_code": "# Print even numbers 2 to 10\n",
    "solution_code": "# Print even numbers 2 to 10\nfor i in range(2, 11, 2):\n    print(i)",
    "expected_output": "2\n4\n6\n8\n10",
    "chapter_id": 2,
    "chapter_title": "Loops (Iteration)"
  },
  "19": {
    "id": 19,
    "title": "While Loop Basics",
    "content": "# ‚è≥ While Loops\n\n## For vs While\n\n| Loop Type | Use Case |\n| --- | --- |\n| `for` | When you know how many times to loop |\n| `while` | When you loop until a condition changes |\n\n## While Loop Syntax\n\n```python\nwhile condition:\n    # Do something\n    # Update something (to eventually stop!)\n```\n\n## Example\n\n```python\ncount = 0\nwhile count < 5:\n    print(count)\n    count += 1\n# Output: 0, 1, 2, 3, 4\n```\n\n## ‚ö†Ô∏è Warning: Infinite Loops!\n\nIf the condition never becomes False, the loop runs forever!\n\n```python\n# DANGER! Never stops!\nwhile True:\n    print(\"Forever...\")\n\n# SAFE: Will eventually stop\nx = 0\nwhile x < 10:\n    print(x)\n    x += 1  # This makes x eventually reach 10\n```\n\n## When to Use While\n\n- User input validation (keep asking until valid)\n- Game loops (run until game over)\n- Processing data until a condition is met\n\n---\n\n## üéØ Your Task\n\nStart with `x = 1`. \nUse a while loop to print x and double it (`x *= 2`) while x <= 16.\n",
    "starter_code": "x = 1\n\n# While x <= 16, print x and double it\n",
    "solution_code": "x = 1\n\n# While x <= 16, print x and double it\nwhile x <= 16:\n    print(x)\n    x *= 2",
    "expected_output": "1\n2\n4\n8\n16",
    "chapter_id": 2,
    "chapter_title": "Loops (Iteration)"
  },
  "20": {
    "id": 20,
    "title": "Loop Control: break",
    "content": "# üõë Breaking Out of Loops\n\n## The break Statement\n\n`break` immediately exits the loop, even if there are more items:\n\n```python\nfor i in range(10):\n    if i == 5:\n        break  # Exit NOW!\n    print(i)\n# Output: 0, 1, 2, 3, 4\n```\n\n## Why Use break?\n\n- **Early exit**: Stop when you find what you're looking for\n- **Performance**: Don't process unnecessary items\n- **Error handling**: Exit if something goes wrong\n\n## Example: Find First Match\n\n```python\nnames = [\"Alice\", \"Bob\", \"Charlie\", \"Diana\"]\ntarget = \"Charlie\"\n\nfor name in names:\n    if name == target:\n        print(f\"Found {target}!\")\n        break\n    print(f\"Checking {name}...\")\n\n# Output:\n# Checking Alice...\n# Checking Bob...\n# Found Charlie!\n```\n\nNotice: We never check Diana because we broke out early!\n\n---\n\n## üéØ Your Task\n\nLoop through `[1, 2, 3, 4, 5, 6, 7]`.\nPrint each number, but use `break` to exit when you reach 5.\n",
    "starter_code": "numbers = [1, 2, 3, 4, 5, 6, 7]\n\n# Print each, break at 5\n",
    "solution_code": "numbers = [1, 2, 3, 4, 5, 6, 7]\n\n# Print each, break at 5\nfor num in numbers:\n    if num == 5:\n        break\n    print(num)",
    "expected_output": "1\n2\n3\n4",
    "chapter_id": 2,
    "chapter_title": "Loops (Iteration)"
  },
  "21": {
    "id": 21,
    "title": "Loop Control: continue",
    "content": "# ‚è≠Ô∏è Skipping with continue\n\n## The continue Statement\n\n`continue` skips the rest of the current iteration and moves to the next one:\n\n```python\nfor i in range(5):\n    if i == 2:\n        continue  # Skip 2\n    print(i)\n# Output: 0, 1, 3, 4\n```\n\n## break vs continue\n\n| Statement | What It Does |\n| --- | --- |\n| `break` | **EXIT** the entire loop |\n| `continue` | **SKIP** to next iteration |\n\n## Example: Skip Negative Numbers\n\n```python\nnumbers = [1, -2, 3, -4, 5]\nfor num in numbers:\n    if num < 0:\n        continue  # Skip negatives\n    print(num)\n# Output: 1, 3, 5\n```\n\n## When to Use continue\n\n- Skip invalid data\n- Filter out unwanted items\n- Process only items that meet criteria\n\n```python\n# Process only adults\nfor person in people:\n    if person.age < 18:\n        continue\n    # ... process adult ...\n```\n\n---\n\n## üéØ Your Task\n\nPrint numbers 1-5, but skip 3 using `continue`.\n",
    "starter_code": "# Print 1-5, skip 3\n",
    "solution_code": "# Print 1-5, skip 3\nfor i in range(1, 6):\n    if i == 3:\n        continue\n    print(i)",
    "expected_output": "1\n2\n4\n5",
    "chapter_id": 2,
    "chapter_title": "Loops (Iteration)"
  },
  "22": {
    "id": 22,
    "title": "If Statements",
    "content": "# üéØ If Statements: Making Decisions\n\n## What is an If Statement?\n\nAn `if` statement lets your code make decisions. It runs code ONLY when a condition is True.\n\n## Real-World Analogy\n\nThink of a bouncer at a club:\n- **IF** you're 21 or older ‚Üí you can enter\n- Otherwise ‚Üí you're turned away\n\nIn Python:\n```python\nage = 25\nif age >= 21:\n    print(\"Welcome!\")\n```\n\n## The Basic Syntax\n\n```python\nif condition:\n    # This code runs if condition is True\n    # Notice the indentation!\n```\n\n**Important**: The colon `:` and indentation are required!\n\n## How Python Evaluates Conditions\n\nPython checks if the condition is `True` or `False`:\n\n```python\nage = 20\nif age >= 18:  # 20 >= 18 is True\n    print(\"You're an adult!\")  # This runs!\n\nif age >= 21:  # 20 >= 21 is False\n    print(\"You can drink!\")  # This does NOT run\n```\n\n---\n\n## üéØ Your Task\n\nGiven `score = 85`:\n- If score >= 70, print `\"Pass\"`\n",
    "starter_code": "score = 85\n\n# If score >= 70, print Pass\n",
    "solution_code": "score = 85\n\n# If score >= 70, print Pass\nif score >= 70:\n    print(\"Pass\")",
    "expected_output": "Pass",
    "chapter_id": 3,
    "chapter_title": "Logic & Control Flow"
  },
  "23": {
    "id": 23,
    "title": "If-Else",
    "content": "# ‚öñÔ∏è If-Else: Two Paths\n\n## Adding an Alternative\n\nWhat if you want to do something when the condition is False? Use `else`:\n\n```python\nif condition:\n    # Runs if True\nelse:\n    # Runs if False\n```\n\n## Example\n\n```python\nage = 15\nif age >= 18:\n    print(\"You can vote!\")\nelse:\n    print(\"Too young to vote\")\n# Output: Too young to vote\n```\n\n## Only ONE Path Runs\n\nWith if-else, exactly ONE block runs - never both, never neither:\n\n```python\ntemperature = 75\nif temperature > 80:\n    print(\"Hot!\")\nelse:\n    print(\"Nice weather!\")\n# Output: Nice weather! (only this one runs)\n```\n\n## Common Mistake\n\nDon't use two separate `if` statements when you want if-else:\n\n```python\n# WRONG - both might run!\nif x > 0:\n    print(\"Positive\")\nif x <= 0:\n    print(\"Non-positive\")\n\n# RIGHT - only one runs\nif x > 0:\n    print(\"Positive\")\nelse:\n    print(\"Non-positive\")\n```\n\n---\n\n## üéØ Your Task\n\nGiven `temperature = 35`:\n- If temperature > 30, print `\"Hot\"`\n- Else print `\"Nice\"`\n",
    "starter_code": "temperature = 35\n\n# Check if hot or nice\n",
    "solution_code": "temperature = 35\n\n# Check if hot or nice\nif temperature > 30:\n    print(\"Hot\")\nelse:\n    print(\"Nice\")",
    "expected_output": "Hot",
    "chapter_id": 3,
    "chapter_title": "Logic & Control Flow"
  },
  "24": {
    "id": 24,
    "title": "If-Elif-Else",
    "content": "# üìä Multiple Conditions with Elif\n\n## When You Have More Than Two Options\n\n`elif` (short for \"else if\") lets you check multiple conditions:\n\n```python\nif condition1:\n    # First choice\nelif condition2:\n    # Second choice\nelif condition3:\n    # Third choice\nelse:\n    # Default (if nothing else matches)\n```\n\n## Example: Letter Grades\n\n```python\nscore = 85\n\nif score >= 90:\n    grade = \"A\"\nelif score >= 80:\n    grade = \"B\"\nelif score >= 70:\n    grade = \"C\"\nelif score >= 60:\n    grade = \"D\"\nelse:\n    grade = \"F\"\n\nprint(grade)  # B\n```\n\n## Order Matters!\n\nPython checks conditions from top to bottom and stops at the first True:\n\n```python\nscore = 95\n\n# WRONG order - 95 >= 60 is True, so prints D!\nif score >= 60: print(\"D\")\nelif score >= 70: print(\"C\")\nelif score >= 80: print(\"B\")\nelif score >= 90: print(\"A\")\n\n# CORRECT order - checks highest first\nif score >= 90: print(\"A\")\nelif score >= 80: print(\"B\")\nelif score >= 70: print(\"C\")\nelif score >= 60: print(\"D\")\n```\n\n---\n\n## üéØ Your Task\n\nGiven `score = 75`:\n- >= 90: print `\"A\"`\n- >= 80: print `\"B\"`\n- >= 70: print `\"C\"`\n- else: print `\"F\"`\n",
    "starter_code": "score = 75\n\n# Determine grade\n",
    "solution_code": "score = 75\n\n# Determine grade\nif score >= 90:\n    print(\"A\")\nelif score >= 80:\n    print(\"B\")\nelif score >= 70:\n    print(\"C\")\nelse:\n    print(\"F\")",
    "expected_output": "C",
    "chapter_id": 3,
    "chapter_title": "Logic & Control Flow"
  },
  "25": {
    "id": 25,
    "title": "Comparison Operators",
    "content": "# ‚öñÔ∏è Comparison Operators\n\n## Comparing Values\n\nComparison operators compare two values and return `True` or `False`:\n\n| Operator | Meaning | Example | Result |\n| --- | --- | --- | --- |\n| `==` | Equal to | `5 == 5` | `True` |\n| `!=` | Not equal to | `5 != 3` | `True` |\n| `>` | Greater than | `5 > 3` | `True` |\n| `<` | Less than | `5 < 3` | `False` |\n| `>=` | Greater or equal | `5 >= 5` | `True` |\n| `<=` | Less or equal | `5 <= 3` | `False` |\n\n## Common Mistake: = vs ==\n\n```python\n# = is ASSIGNMENT (storing a value)\nx = 5\n\n# == is COMPARISON (checking equality)\nif x == 5:\n    print(\"x is five!\")\n```\n\n## Comparing Strings\n\nYou can compare strings too:\n\n```python\nname = \"Alice\"\nif name == \"Alice\":\n    print(\"Hello, Alice!\")\n\n# Alphabetical comparison\n\"apple\" < \"banana\"  # True (a comes before b)\n```\n\n---\n\n## üéØ Your Task\n\nGiven `a = 10` and `b = 10`:\nCheck if they are equal and print: `Equal: True`\n",
    "starter_code": "a = 10\nb = 10\n\n# Check if equal\nresult = a == b\nprint(f\"Equal: {result}\")",
    "solution_code": "a = 10\nb = 10\n\n# Check if equal\nresult = a == b\nprint(f\"Equal: {result}\")",
    "expected_output": "Equal: True",
    "chapter_id": 3,
    "chapter_title": "Logic & Control Flow"
  },
  "26": {
    "id": 26,
    "title": "Logical AND",
    "content": "# üîó Logical AND\n\n## Combining Conditions\n\n`and` requires BOTH conditions to be True:\n\n```python\nif condition1 and condition2:\n    # Runs only if BOTH are True\n```\n\n## Real-World Example\n\nTo enter a bar, you need to be 21+ AND have ID:\n\n```python\nage = 25\nhas_id = True\n\nif age >= 21 and has_id:\n    print(\"Welcome!\")\nelse:\n    print(\"Sorry, can't enter\")\n```\n\n## Truth Table for AND\n\n| A | B | A and B |\n| --- | --- | --- |\n| True | True | **True** |\n| True | False | False |\n| False | True | False |\n| False | False | False |\n\nOnly True if BOTH are True!\n\n## Multiple ANDs\n\nYou can chain multiple conditions:\n\n```python\nif age >= 18 and has_license and not is_suspended:\n    print(\"You can drive!\")\n```\n\n---\n\n## üéØ Your Task\n\nGiven:\n- `age = 25`\n- `has_ticket = True`\n\nIf age >= 18 AND has_ticket, print `\"Can enter\"`\n",
    "starter_code": "age = 25\nhas_ticket = True\n\n# Check both conditions\n",
    "solution_code": "age = 25\nhas_ticket = True\n\n# Check both conditions\nif age >= 18 and has_ticket:\n    print(\"Can enter\")",
    "expected_output": "Can enter",
    "chapter_id": 3,
    "chapter_title": "Logic & Control Flow"
  },
  "27": {
    "id": 27,
    "title": "Logical OR",
    "content": "# üîÄ Logical OR\n\n## Either Condition\n\n`or` requires AT LEAST ONE condition to be True:\n\n```python\nif condition1 or condition2:\n    # Runs if EITHER (or both) is True\n```\n\n## Real-World Example\n\nFree shipping if order is $50+ OR member is premium:\n\n```python\norder_total = 35\nis_premium = True\n\nif order_total >= 50 or is_premium:\n    print(\"Free shipping!\")\nelse:\n    print(\"Shipping: $5\")\n```\n\n## Truth Table for OR\n\n| A | B | A or B |\n| --- | --- | --- |\n| True | True | True |\n| True | False | True |\n| False | True | True |\n| False | False | **False** |\n\nOnly False if BOTH are False!\n\n## Combining AND and OR\n\nUse parentheses for clarity:\n\n```python\nif (is_weekend or is_holiday) and not is_working:\n    print(\"Day off!\")\n```\n\n---\n\n## üéØ Your Task\n\nGiven:\n- `is_member = False`\n- `has_coupon = True`\n\nIf is_member OR has_coupon, print `\"Discount applied\"`\n",
    "starter_code": "is_member = False\nhas_coupon = True\n\n# Check if either is true\n",
    "solution_code": "is_member = False\nhas_coupon = True\n\n# Check if either is true\nif is_member or has_coupon:\n    print(\"Discount applied\")",
    "expected_output": "Discount applied",
    "chapter_id": 3,
    "chapter_title": "Logic & Control Flow"
  },
  "28": {
    "id": 28,
    "title": "Logical NOT",
    "content": "# ‚ùå Logical NOT\n\n## Reversing Conditions\n\n`not` flips True to False and False to True:\n\n```python\nis_raining = False\nif not is_raining:\n    print(\"No umbrella needed!\")\n```\n\n## Truth Table for NOT\n\n| A | not A |\n| --- | --- |\n| True | False |\n| False | True |\n\n## When to Use NOT\n\n```python\n# Instead of checking for False\nif logged_in == False:  # Works but awkward\n    print(\"Please log in\")\n\n# Use NOT (more Pythonic!)\nif not logged_in:\n    print(\"Please log in\")\n```\n\n## NOT with Collections\n\n```python\n# Check if list is empty\nitems = []\nif not items:  # Empty list is \"falsy\"\n    print(\"Cart is empty!\")\n\n# Check if string is empty\nname = \"\"\nif not name:\n    print(\"Name is required!\")\n```\n\n---\n\n## üéØ Your Task\n\nGiven `is_blocked = False`:\nIf NOT blocked, print `\"Welcome!\"`\n",
    "starter_code": "is_blocked = False\n\n# If not blocked\n",
    "solution_code": "is_blocked = False\n\n# If not blocked\nif not is_blocked:\n    print(\"Welcome!\")",
    "expected_output": "Welcome!",
    "chapter_id": 3,
    "chapter_title": "Logic & Control Flow"
  },
  "29": {
    "id": 29,
    "title": "Nested Conditionals",
    "content": "# ü™Ü Nested If Statements\n\n## If Inside If\n\nYou can put if statements inside other if statements:\n\n```python\nif has_account:\n    if is_verified:\n        print(\"Full access\")\n    else:\n        print(\"Please verify your email\")\nelse:\n    print(\"Please create an account\")\n```\n\n## When to Nest\n\nUseful when second check only makes sense if first is True:\n\n```python\nif user_input:  # First check: did they enter anything?\n    if user_input.isdigit():  # Only check this if there's input\n        print(\"Valid number!\")\n    else:\n        print(\"Not a number\")\nelse:\n    print(\"No input provided\")\n```\n\n## Avoid Deep Nesting\n\nToo many levels becomes hard to read:\n\n```python\n# BAD - too nested!\nif a:\n    if b:\n        if c:\n            if d:\n                do_something()\n\n# BETTER - use AND\nif a and b and c and d:\n    do_something()\n```\n\n---\n\n## üéØ Your Task\n\nGiven:\n- `logged_in = True`\n- `is_admin = True`\n\nIf logged_in, check if is_admin:\n- If admin: print `\"Admin panel\"`\n- Else: print `\"User dashboard\"`\n",
    "starter_code": "logged_in = True\nis_admin = True\n\n# Nested check\n",
    "solution_code": "logged_in = True\nis_admin = True\n\n# Nested check\nif logged_in:\n    if is_admin:\n        print(\"Admin panel\")\n    else:\n        print(\"User dashboard\")",
    "expected_output": "Admin panel",
    "chapter_id": 3,
    "chapter_title": "Logic & Control Flow"
  },
  "30": {
    "id": 30,
    "title": "Ternary Operator",
    "content": "# ‚ö° One-Line Conditionals\n\n## The Ternary Operator\n\nPython has a shorthand for simple if-else:\n\n```python\nvalue_if_true if condition else value_if_false\n```\n\n## Example\n\n```python\nage = 20\nstatus = \"Adult\" if age >= 18 else \"Minor\"\nprint(status)  # Adult\n```\n\nThis is equivalent to:\n```python\nif age >= 18:\n    status = \"Adult\"\nelse:\n    status = \"Minor\"\n```\n\n## When to Use\n\n‚úÖ Good for simple, short conditions:\n```python\nresult = \"Pass\" if score >= 70 else \"Fail\"\nmessage = f\"Welcome, {name}!\" if name else \"Welcome, Guest!\"\n```\n\n‚ùå Avoid for complex logic:\n```python\n# Too complex for ternary - use regular if-else\ngrade = \"A\" if score >= 90 else \"B\" if score >= 80 else \"C\" if score >= 70 else \"F\"\n```\n\n---\n\n## üéØ Your Task\n\nGiven `points = 150`:\nSet `level` to `\"Gold\"` if points >= 100, else `\"Silver\"`.\nPrint the level.\n",
    "starter_code": "points = 150\n\n# Set level using ternary\n\n\n# Print level\n",
    "solution_code": "points = 150\n\n# Set level using ternary\nlevel = \"Gold\" if points >= 100 else \"Silver\"\n\n# Print level\nprint(level)",
    "expected_output": "Gold",
    "chapter_id": 3,
    "chapter_title": "Logic & Control Flow"
  },
  "31": {
    "id": 31,
    "title": "Defining Functions",
    "content": "# üîß Creating Functions\n\n## What is a Function?\n\nA **function** is a reusable block of code that performs a specific task. Instead of writing the same code over and over, you define it once and call it whenever needed.\n\n## Real-World Analogy\n\nThink of a function like a **recipe**:\n- You write the recipe once\n- Every time you want that dish, you follow the same recipe\n- You don't have to figure it out from scratch each time!\n\n## Why Use Functions?\n\n1. **Reusability**: Write once, use many times\n2. **Organization**: Break complex code into manageable pieces\n3. **Readability**: Give meaningful names to code blocks\n4. **Maintenance**: Fix bugs in one place\n\n## Defining a Function\n\n```python\ndef function_name():\n    # Code inside the function\n    print(\"Hello from the function!\")\n```\n\n- `def` keyword starts the definition\n- `function_name` is what you call it\n- `():` parentheses and colon are required\n- Indented code is the function body\n\n## Calling a Function\n\nThe function doesn't run until you **call** it:\n\n```python\ndef greet():\n    print(\"Hello!\")\n\ngreet()  # Call the function - output: Hello!\ngreet()  # Call it again!\n```\n\n---\n\n## üéØ Your Task\n\nDefine a function called `say_hello` that prints `\"Hello, World!\"`.\nThen call it.\n",
    "starter_code": "# Define the function\n\n\n# Call the function\n",
    "solution_code": "# Define the function\ndef say_hello():\n    print(\"Hello, World!\")\n\n# Call the function\nsay_hello()",
    "expected_output": "Hello, World!",
    "chapter_id": 4,
    "chapter_title": "Functions"
  },
  "32": {
    "id": 32,
    "title": "Function Parameters",
    "content": "# üì• Parameters: Passing Data to Functions\n\n## What are Parameters?\n\nParameters let you pass data INTO a function. They're like ingredients for a recipe - different ingredients, different results!\n\n```python\ndef greet(name):  # 'name' is a parameter\n    print(f\"Hello, {name}!\")\n\ngreet(\"Alice\")  # Output: Hello, Alice!\ngreet(\"Bob\")    # Output: Hello, Bob!\n```\n\n## Parameters vs Arguments\n\n| Term | Definition |\n| --- | --- |\n| **Parameter** | Variable in function definition |\n| **Argument** | Actual value passed when calling |\n\n```python\ndef greet(name):    # 'name' is the PARAMETER\n    print(f\"Hello, {name}!\")\n\ngreet(\"Alice\")      # \"Alice\" is the ARGUMENT\n```\n\n## Multiple Parameters\n\nFunctions can have multiple parameters:\n\n```python\ndef add(a, b):\n    result = a + b\n    print(result)\n\nadd(5, 3)  # Output: 8\nadd(10, 20)  # Output: 30\n```\n\n---\n\n## üéØ Your Task\n\nDefine `greet(name)` that prints `\"Welcome, {name}!\"`.\nCall it with `\"Python\"`.\n",
    "starter_code": "# Define greet with name parameter\n\n\n# Call with \"Python\"\n",
    "solution_code": "# Define greet with name parameter\ndef greet(name):\n    print(f\"Welcome, {name}!\")\n\n# Call with \"Python\"\ngreet(\"Python\")",
    "expected_output": "Welcome, Python!",
    "chapter_id": 4,
    "chapter_title": "Functions"
  },
  "33": {
    "id": 33,
    "title": "Return Values",
    "content": "# üì§ Return Values: Getting Data Back\n\n## What is Return?\n\n`return` sends a value back to where the function was called. This value can be stored, used in calculations, or printed.\n\n```python\ndef add(a, b):\n    return a + b  # Send the result back\n\nresult = add(5, 3)  # result now equals 8\nprint(result)       # Output: 8\n```\n\n## Return vs Print\n\n| `print()` | `return` |\n| --- | --- |\n| Shows output to screen | Sends value back to caller |\n| Value is lost after printing | Value can be used further |\n| Debugging/user display | Building blocks for programs |\n\n```python\n# With print - can't use the result\ndef add_print(a, b):\n    print(a + b)\n\nx = add_print(5, 3)  # Prints 8, but x is None!\n\n# With return - can use the result\ndef add_return(a, b):\n    return a + b\n\ny = add_return(5, 3)  # y equals 8\nz = y * 2             # z equals 16\n```\n\n## Return Ends the Function\n\nCode after `return` doesn't run:\n\n```python\ndef example():\n    return \"Done\"\n    print(\"This never runs!\")  # Unreachable!\n```\n\n---\n\n## üéØ Your Task\n\nDefine `double(n)` that returns `n * 2`.\nCall it with `7` and print the result.\n",
    "starter_code": "# Define double function\n\n\n# Call with 7 and print\n",
    "solution_code": "# Define double function\ndef double(n):\n    return n * 2\n\n# Call with 7 and print\nresult = double(7)\nprint(result)",
    "expected_output": "14",
    "chapter_id": 4,
    "chapter_title": "Functions"
  },
  "34": {
    "id": 34,
    "title": "Multiple Parameters",
    "content": "# üìä Working with Multiple Parameters\n\n## Functions with Several Inputs\n\nFunctions often need multiple pieces of data:\n\n```python\ndef calculate_area(width, height):\n    return width * height\n\narea = calculate_area(5, 3)\nprint(area)  # 15\n```\n\n## Order Matters (Positional Arguments)\n\nArguments are matched to parameters by position:\n\n```python\ndef greet(first_name, last_name):\n    print(f\"Hello, {first_name} {last_name}!\")\n\ngreet(\"John\", \"Doe\")    # Hello, John Doe!\ngreet(\"Doe\", \"John\")    # Hello, Doe John! (wrong order!)\n```\n\n## Practical Example\n\n```python\ndef create_email(username, domain):\n    return f\"{username}@{domain}\"\n\nemail = create_email(\"alice\", \"gmail.com\")\nprint(email)  # alice@gmail.com\n```\n\n---\n\n## üéØ Your Task\n\nDefine `calculate_area(width, height)` that returns `width * height`.\nCall it with `5` and `3`, print the result.\n",
    "starter_code": "# Define calculate_area\n\n\n# Call with 5, 3 and print\n",
    "solution_code": "# Define calculate_area\ndef calculate_area(width, height):\n    return width * height\n\n# Call with 5, 3 and print\narea = calculate_area(5, 3)\nprint(area)",
    "expected_output": "15",
    "chapter_id": 4,
    "chapter_title": "Functions"
  },
  "35": {
    "id": 35,
    "title": "Default Parameters",
    "content": "# ‚öôÔ∏è Default Parameter Values\n\n## What are Default Values?\n\nYou can give parameters default values. If no argument is passed, the default is used:\n\n```python\ndef greet(name=\"Guest\"):\n    print(f\"Hello, {name}!\")\n\ngreet(\"Alice\")  # Hello, Alice!\ngreet()         # Hello, Guest! (uses default)\n```\n\n## Why Use Defaults?\n\n- Make functions more flexible\n- Reduce required arguments\n- Provide sensible fallbacks\n\n## Rules for Default Parameters\n\nDefault parameters must come AFTER non-default ones:\n\n```python\n# CORRECT - default at the end\ndef greet(name, greeting=\"Hello\"):\n    print(f\"{greeting}, {name}!\")\n\n# ERROR - default before non-default\ndef greet(greeting=\"Hello\", name):  # SyntaxError!\n    print(f\"{greeting}, {name}!\")\n```\n\n---\n\n## üéØ Your Task\n\nDefine `power(base, exp=2)` that returns `base ** exp`.\nCall it with just `4` (should return 16 since exp defaults to 2).\n",
    "starter_code": "# Define power with default exp=2\n\n\n# Call with just 4\n",
    "solution_code": "# Define power with default exp=2\ndef power(base, exp=2):\n    return base ** exp\n\n# Call with just 4\nresult = power(4)\nprint(result)",
    "expected_output": "16",
    "chapter_id": 4,
    "chapter_title": "Functions"
  },
  "36": {
    "id": 36,
    "title": "Keyword Arguments",
    "content": "# üè∑Ô∏è Keyword Arguments\n\n## What are Keyword Arguments?\n\nYou can specify arguments by name, not just position:\n\n```python\ndef greet(name, greeting):\n    print(f\"{greeting}, {name}!\")\n\n# Using keyword arguments\ngreet(name=\"Alice\", greeting=\"Hi\")\ngreet(greeting=\"Hello\", name=\"Bob\")  # Order doesn't matter!\n```\n\n## Why Use Keyword Arguments?\n\n1. **Clarity**: Makes code more readable\n2. **Flexibility**: Call in any order\n3. **Skip defaults**: Override only specific defaults\n\n```python\ndef create_user(name, age, email, is_admin=False):\n    # ...\n    \n# Skip to the argument you need\ncreate_user(\"Alice\", 25, \"a@b.com\", is_admin=True)\n```\n\n## Mixing Positional and Keyword\n\nPositional arguments must come before keyword arguments:\n\n```python\ndef func(a, b, c):\n    print(a, b, c)\n\nfunc(1, 2, c=3)      # OK\nfunc(1, b=2, c=3)    # OK\nfunc(a=1, 2, 3)      # ERROR!\n```\n\n---\n\n## üéØ Your Task\n\nDefine `describe(item, price)` that prints `\"{item}: ${price}\"`.\nCall it with keyword arguments: `price=9.99, item=\"Book\"`.\n",
    "starter_code": "# Define describe\n\n\n# Call with keyword arguments\n",
    "solution_code": "# Define describe\ndef describe(item, price):\n    print(f\"{item}: ${price}\")\n\n# Call with keyword arguments\ndescribe(price=9.99, item=\"Book\")",
    "expected_output": "Book: $9.99",
    "chapter_id": 4,
    "chapter_title": "Functions"
  },
  "37": {
    "id": 37,
    "title": "Lambda Functions",
    "content": "# ‚ö° Lambda Functions: One-Line Functions\n\n## What is a Lambda?\n\nA **lambda** is a small anonymous function defined in one line:\n\n```python\n# Regular function\ndef square(x):\n    return x ** 2\n\n# Lambda equivalent\nsquare = lambda x: x ** 2\n```\n\n## Lambda Syntax\n\n```python\nlambda arguments: expression\n```\n\n- No `def` or `return` keywords\n- Expression is automatically returned\n- Can have multiple arguments\n\n## Examples\n\n```python\n# One argument\ndouble = lambda x: x * 2\nprint(double(5))  # 10\n\n# Two arguments\nadd = lambda a, b: a + b\nprint(add(3, 4))  # 7\n\n# Conditional\nis_adult = lambda age: \"Adult\" if age >= 18 else \"Minor\"\nprint(is_adult(20))  # Adult\n```\n\n## When to Use Lambda\n\n- Short, simple operations\n- Passing to other functions (like `sort`, `map`, `filter`)\n- One-time use functions\n\n---\n\n## üéØ Your Task\n\nCreate a lambda function `triple` that multiplies by 3.\nCall it with `10` and print the result.\n",
    "starter_code": "# Create lambda triple\n\n\n# Call with 10\n",
    "solution_code": "# Create lambda triple\ntriple = lambda x: x * 3\n\n# Call with 10\nprint(triple(10))",
    "expected_output": "30",
    "chapter_id": 4,
    "chapter_title": "Functions"
  },
  "38": {
    "id": 38,
    "title": "Docstrings",
    "content": "# üìù Documenting Functions with Docstrings\n\n## What is a Docstring?\n\nA **docstring** is a string that describes what your function does. It goes right after the function definition:\n\n```python\ndef add(a, b):\n    \"\"\"Returns the sum of a and b.\"\"\"\n    return a + b\n```\n\n## Why Write Docstrings?\n\n1. Help other developers understand your code\n2. Remind yourself what the function does\n3. Tools can auto-generate documentation\n4. Shows up in `help()` function!\n\n```python\nhelp(add)\n# Output:\n# add(a, b)\n#     Returns the sum of a and b.\n```\n\n## Multi-line Docstrings\n\nFor more complex functions:\n\n```python\ndef calculate_tip(bill, tip_percent=15):\n    \"\"\"\n    Calculate the tip amount for a bill.\n    \n    Args:\n        bill: Total bill amount\n        tip_percent: Tip percentage (default 15)\n    \n    Returns:\n        The tip amount as a float\n    \"\"\"\n    return bill * (tip_percent / 100)\n```\n\n---\n\n## üéØ Your Task\n\nDefine `multiply(a, b)` with a docstring.\nReturn `a * b` and call with `6, 7`.\n",
    "starter_code": "# Define multiply with docstring\n\n\n# Call with 6, 7\n",
    "solution_code": "# Define multiply with docstring\ndef multiply(a, b):\n    \"\"\"Returns the product of a and b.\"\"\"\n    return a * b\n\n# Call with 6, 7\nprint(multiply(6, 7))",
    "expected_output": "42",
    "chapter_id": 4,
    "chapter_title": "Functions"
  },
  "39": {
    "id": 39,
    "title": "Variable Scope",
    "content": "# üî≠ Variable Scope\n\n## What is Scope?\n\n**Scope** determines where a variable can be accessed. Variables created inside a function only exist inside that function!\n\n```python\ndef my_function():\n    x = 10  # Local variable - only exists inside function\n    print(x)\n\nmy_function()  # Output: 10\nprint(x)       # ERROR! x doesn't exist here\n```\n\n## Local vs Global\n\n| Type | Where Created | Where Accessible |\n| --- | --- | --- |\n| **Local** | Inside a function | Only that function |\n| **Global** | Outside all functions | Everywhere |\n\n```python\ny = 20  # Global variable\n\ndef show():\n    print(y)  # Can read global variable\n\nshow()  # Output: 20\n```\n\n## Shadowing\n\nA local variable can have the same name as a global (but it's a different variable!):\n\n```python\nx = 100  # Global\n\ndef test():\n    x = 5  # Local - different variable!\n    print(x)  # 5\n\ntest()\nprint(x)  # 100 (global unchanged)\n```\n\n---\n\n## üéØ Your Task\n\nDefine a function `show_secret()` that:\n1. Creates a local variable `secret = \"Python rocks!\"`\n2. Prints it\n\nCall the function.\n",
    "starter_code": "# Define show_secret\n\n\n# Call it\n",
    "solution_code": "# Define show_secret\ndef show_secret():\n    secret = \"Python rocks!\"\n    print(secret)\n\n# Call it\nshow_secret()",
    "expected_output": "Python rocks!",
    "chapter_id": 4,
    "chapter_title": "Functions"
  },
  "40": {
    "id": 40,
    "title": "üêç Sand Sphinx Challenge",
    "content": "# üêç BOSS BATTLE: The Sand Sphinx\n\nThe Sand Sphinx guards the way forward. To pass, you must prove your mastery of the fundamentals!\n\n## The Challenge\n\nCreate a **mini program** that combines everything from Chapters 1-4:\n- Variables & data types\n- String manipulation\n- Math operations\n- Loops\n- Conditionals\n- Functions\n\n## Your Mission\n\nBuild a simple **Number Guessing Game**:\n1. Generate a random number 1-10\n2. Let the user \"guess\" (we'll simulate with a variable)\n3. Tell them if they're too high, too low, or correct\n4. Keep track of attempts\n\n---\n\n## üéØ Complete the Challenge\n\n\n> [!NOTE]\n> **Professor's Tip**: We've added `random.seed(42)` to your code. This ensures the random numbers are the same every time you run it, which is necessary for the auto-grader to work!",
    "starter_code": "import random\n\n# üîí PROFESSOR'S NOTE: We set a seed so the Sphinx plays the same numbers every time.\n# This helps us verify your solution!\nrandom.seed(42)\n\n# Write your Number Guessing Game here\nimport random\n\n# Step 1: Generate secret number (1-10)\n\n\n# Step 2: Create a list of guesses to simulate user input\n# guesses = [5, 8, 3, 7]\n\n\n# Step 3: Track attempts\n\n\n# Step 4: Loop through guesses and provide feedback\n\n",
    "solution_code": "import random\n\n# Generate secret number\nrandom.seed(42)  # For consistent testing\nsecret = random.randint(1, 10)\nprint(f\"(Secret is: {secret})\")  # For testing\n\n# Simulate user guesses\nguesses = [5, 8, 3, 7]  # Simulated guesses\nattempts = 0\n\nfor guess in guesses:\n    attempts += 1\n    if guess == secret:\n        print(f\"Correct! It took {attempts} attempts.\")\n        break\n    elif guess < secret:\n        print(f\"{guess} is too low!\")\n    else:\n        print(f\"{guess} is too high!\")\nelse:\n    print(f\"Out of guesses! Secret was {secret}\")\n",
    "expected_output": "(Secret is: 2)\n5 is too high!\n8 is too high!\n3 is too high!\nOut of guesses! Secret was 2",
    "chapter_id": 100,
    "chapter_title": "Sand Sphinx Boss"
  },
  "41": {
    "id": 41,
    "title": "Lists Basics",
    "content": "# üìã Lists: Collections of Items\n\n## What is a List?\n\nA **list** is an ordered collection that can hold multiple items. Think of it like a shopping list or a playlist.\n\n```python\nfruits = [\"apple\", \"banana\", \"cherry\"]\nnumbers = [1, 2, 3, 4, 5]\nmixed = [1, \"hello\", 3.14, True]  # Can mix types!\n```\n\n## Why Use Lists?\n\n- Store multiple related items together\n- Access items by position (index)\n- Add, remove, or modify items\n- Loop through all items\n\n## Accessing Items by Index\n\nLists use **zero-based indexing** (counting starts at 0):\n\n```python\nfruits = [\"apple\", \"banana\", \"cherry\"]\n#          [0]       [1]       [2]\n\nprint(fruits[0])  # apple\nprint(fruits[1])  # banana\nprint(fruits[2])  # cherry\nprint(fruits[-1]) # cherry (last item)\n```\n\n## List Length\n\n```python\nprint(len(fruits))  # 3\n```\n\n---\n\n## üéØ Your Task\n\nCreate a list `colors = [\"red\", \"green\", \"blue\"]`.\nPrint the second item (index 1).\n",
    "starter_code": "# Create colors list\n\n\n# Print second item\n",
    "solution_code": "# Create colors list\ncolors = [\"red\", \"green\", \"blue\"]\n\n# Print second item\nprint(colors[1])",
    "expected_output": "green",
    "chapter_id": 7,
    "chapter_title": "Data Structures"
  },
  "42": {
    "id": 42,
    "title": "List Methods",
    "content": "# üìù Modifying Lists\n\n## Common List Methods\n\n| Method | What It Does | Example |\n| --- | --- | --- |\n| `.append(x)` | Add to end | `list.append(4)` |\n| `.insert(i, x)` | Insert at index | `list.insert(0, \"first\")` |\n| `.remove(x)` | Remove first occurrence | `list.remove(\"apple\")` |\n| `.pop()` | Remove and return last | `last = list.pop()` |\n| `.pop(i)` | Remove at index | `list.pop(0)` |\n| `.sort()` | Sort in place | `list.sort()` |\n| `.reverse()` | Reverse in place | `list.reverse()` |\n\n## Examples\n\n```python\nfruits = [\"apple\", \"banana\"]\n\n# Add items\nfruits.append(\"cherry\")     # [\"apple\", \"banana\", \"cherry\"]\nfruits.insert(0, \"mango\")   # [\"mango\", \"apple\", \"banana\", \"cherry\"]\n\n# Remove items\nfruits.remove(\"banana\")     # [\"mango\", \"apple\", \"cherry\"]\nlast = fruits.pop()         # last = \"cherry\", list = [\"mango\", \"apple\"]\n```\n\n## Modifying Lists Changes the Original\n\nUnlike strings (which are immutable), lists can be changed:\n\n```python\nnums = [3, 1, 2]\nnums.sort()       # nums is now [1, 2, 3]\nnums.reverse()    # nums is now [3, 2, 1]\n```\n\n---\n\n## üéØ Your Task\n\nStart with: `numbers = [1, 2, 3]`\n1. Append `4`\n2. Print the list\n",
    "starter_code": "numbers = [1, 2, 3]\n\n# Append 4\n\n\n# Print list\n",
    "solution_code": "numbers = [1, 2, 3]\n\n# Append 4\nnumbers.append(4)\n\n# Print list\nprint(numbers)",
    "expected_output": "[1, 2, 3, 4]",
    "chapter_id": 7,
    "chapter_title": "Data Structures"
  },
  "43": {
    "id": 43,
    "title": "List Slicing",
    "content": "# ‚úÇÔ∏è Slicing Lists\n\n## What is Slicing?\n\n**Slicing** extracts a portion of a list:\n\n```python\nlist[start:stop]  # Elements from start up to (not including) stop\n```\n\n## Examples\n\n```python\nnums = [0, 1, 2, 3, 4, 5]\n\nnums[1:4]   # [1, 2, 3]     (index 1, 2, 3)\nnums[:3]    # [0, 1, 2]     (start to index 2)\nnums[3:]    # [3, 4, 5]     (index 3 to end)\nnums[:]     # [0, 1, 2, 3, 4, 5]  (copy entire list)\n```\n\n## Negative Indices\n\n```python\nnums[-3:]   # [3, 4, 5]     (last 3 elements)\nnums[:-2]   # [0, 1, 2, 3]  (all except last 2)\n```\n\n## Step in Slicing\n\n```python\nnums[::2]   # [0, 2, 4]     (every 2nd element)\nnums[::-1]  # [5, 4, 3, 2, 1, 0]  (reversed!)\n```\n\n---\n\n## üéØ Your Task\n\nGiven: `letters = [\"a\", \"b\", \"c\", \"d\", \"e\"]`\nPrint the slice from index 1 to 3 (should be `[\"b\", \"c\", \"d\"]`).\n",
    "starter_code": "letters = [\"a\", \"b\", \"c\", \"d\", \"e\"]\n\n# Print slice [1:4]\n",
    "solution_code": "letters = [\"a\", \"b\", \"c\", \"d\", \"e\"]\n\n# Print slice [1:4]\nprint(letters[1:4])",
    "expected_output": "['b', 'c', 'd']",
    "chapter_id": 7,
    "chapter_title": "Data Structures"
  },
  "44": {
    "id": 44,
    "title": "Dictionaries",
    "content": "# üìñ Dictionaries: Key-Value Pairs\n\n## What is a Dictionary?\n\nA **dictionary** stores data as key-value pairs. Instead of accessing by index, you access by key name.\n\n```python\nperson = {\n    \"name\": \"Alice\",\n    \"age\": 25,\n    \"city\": \"New York\"\n}\n```\n\n## Why Use Dictionaries?\n\n- Access data by meaningful names (not numbers)\n- Store related information together\n- Fast lookups\n- Real-world mapping (word ‚Üí definition, ID ‚Üí record)\n\n## Accessing Values\n\n```python\nprint(person[\"name\"])  # Alice\nprint(person[\"age\"])   # 25\n```\n\n## Adding/Modifying\n\n```python\nperson[\"email\"] = \"alice@email.com\"  # Add new key\nperson[\"age\"] = 26                    # Modify existing\n```\n\n## Safe Access with .get()\n\n```python\n# If key doesn't exist:\nperson[\"phone\"]           # KeyError!\nperson.get(\"phone\")       # None (no error)\nperson.get(\"phone\", \"N/A\")  # \"N/A\" (custom default)\n```\n\n---\n\n## üéØ Your Task\n\nCreate a dictionary:\n```python\nbook = {\"title\": \"Python 101\", \"author\": \"John Doe\", \"pages\": 300}\n```\nPrint the author.\n",
    "starter_code": "# Create book dictionary\n\n\n# Print author\n",
    "solution_code": "# Create book dictionary\nbook = {\"title\": \"Python 101\", \"author\": \"John Doe\", \"pages\": 300}\n\n# Print author\nprint(book[\"author\"])",
    "expected_output": "John Doe",
    "chapter_id": 7,
    "chapter_title": "Data Structures"
  },
  "45": {
    "id": 45,
    "title": "Dictionary Methods",
    "content": "# üîß Dictionary Methods\n\n## Common Methods\n\n| Method | What It Does |\n| --- | --- |\n| `.keys()` | Get all keys |\n| `.values()` | Get all values |\n| `.items()` | Get key-value pairs |\n| `.get(key)` | Safe access |\n| `.update(dict2)` | Merge dictionaries |\n| `.pop(key)` | Remove and return value |\n\n## Examples\n\n```python\nscores = {\"Alice\": 85, \"Bob\": 92}\n\n# Get keys and values\nprint(list(scores.keys()))    # ['Alice', 'Bob']\nprint(list(scores.values()))  # [85, 92]\n\n# Loop through items\nfor name, score in scores.items():\n    print(f\"{name}: {score}\")\n```\n\n## Checking if Key Exists\n\n```python\nif \"Alice\" in scores:\n    print(scores[\"Alice\"])\n```\n\n---\n\n## üéØ Your Task\n\nGiven:\n```python\nscores = {\"Alice\": 85, \"Bob\": 92}\n```\nAdd `\"Charlie\": 78` and print all keys.\n",
    "starter_code": "scores = {\"Alice\": 85, \"Bob\": 92}\n\n# Add Charlie: 78\n\n\n# Print keys\n",
    "solution_code": "scores = {\"Alice\": 85, \"Bob\": 92}\n\n# Add Charlie: 78\nscores[\"Charlie\"] = 78\n\n# Print keys\nprint(list(scores.keys()))",
    "expected_output": "['Alice', 'Bob', 'Charlie']",
    "chapter_id": 7,
    "chapter_title": "Data Structures"
  },
  "46": {
    "id": 46,
    "title": "Tuples",
    "content": "# üìå Tuples: Immutable Sequences\n\n## What is a Tuple?\n\nA **tuple** is like a list, but it **cannot be changed** (immutable):\n\n```python\npoint = (10, 20)\ncolors = (\"red\", \"green\", \"blue\")\n```\n\n## Tuples vs Lists\n\n| Feature | List `[]` | Tuple `()` |\n| --- | --- | --- |\n| Mutable | ‚úÖ Yes | ‚ùå No |\n| Use case | Data that changes | Data that shouldn't change |\n| Syntax | `[1, 2, 3]` | `(1, 2, 3)` |\n\n## Why Use Tuples?\n\n- Protect data from accidental changes\n- Dictionary keys (must be immutable)\n- Return multiple values from functions\n- Slightly faster than lists\n\n## Tuple Unpacking\n\nAssign tuple values to multiple variables:\n\n```python\npoint = (100, 200)\nx, y = point  # x=100, y=200\n\n# Swap variables!\na, b = b, a\n```\n\n---\n\n## üéØ Your Task\n\nCreate `coordinates = (100, 200)`.\nUnpack into `x` and `y`.\nPrint `x` and `y`.\n",
    "starter_code": "# Create coordinates tuple\n\n\n# Unpack\n\n\n# Print x and y\n",
    "solution_code": "# Create coordinates tuple\ncoordinates = (100, 200)\n\n# Unpack\nx, y = coordinates\n\n# Print x and y\nprint(x)\nprint(y)",
    "expected_output": "100\n200",
    "chapter_id": 7,
    "chapter_title": "Data Structures"
  },
  "47": {
    "id": 47,
    "title": "Sets",
    "content": "# üéØ Sets: Unique Collections\n\n## What is a Set?\n\nA **set** is an unordered collection of unique items:\n\n```python\nnumbers = {1, 2, 3, 2, 1}  # {1, 2, 3} - duplicates removed!\n```\n\n## Why Use Sets?\n\n- Automatic duplicate removal\n- Fast membership testing\n- Mathematical set operations (union, intersection)\n\n## Set Operations\n\n```python\na = {1, 2, 3}\nb = {2, 3, 4}\n\na | b  # {1, 2, 3, 4}  - Union\na & b  # {2, 3}        - Intersection\na - b  # {1}           - Difference\n```\n\n## Common Methods\n\n```python\ns = {1, 2, 3}\ns.add(4)       # {1, 2, 3, 4}\ns.remove(2)    # {1, 3, 4}\ns.discard(10)  # No error if not found\n```\n\n---\n\n## üéØ Your Task\n\nCreate `letters = {\"a\", \"b\", \"c\"}`.\nAdd `\"d\"` and print the set.\n",
    "starter_code": "# Create set\n\n\n# Add \"d\"\n\n\n# Print set\n",
    "solution_code": "# Create set\nletters = {\"a\", \"b\", \"c\"}\n\n# Add \"d\"\nletters.add(\"d\")\n\n# Print set\nprint(letters)",
    "expected_output": "{'a', 'b', 'c', 'd'}",
    "chapter_id": 7,
    "chapter_title": "Data Structures"
  },
  "48": {
    "id": 48,
    "title": "List Comprehension",
    "content": "# ‚ö° List Comprehension\n\n## What is List Comprehension?\n\nA concise way to create lists:\n\n```python\n# Traditional way\nsquares = []\nfor x in range(5):\n    squares.append(x ** 2)\n\n# List comprehension\nsquares = [x ** 2 for x in range(5)]\n```\n\nBoth produce: `[0, 1, 4, 9, 16]`\n\n## Syntax\n\n```python\n[expression for item in iterable]\n[expression for item in iterable if condition]\n```\n\n## Examples\n\n```python\n# Double each number\n[x * 2 for x in range(5)]  # [0, 2, 4, 6, 8]\n\n# Filter: only evens\n[x for x in range(10) if x % 2 == 0]  # [0, 2, 4, 6, 8]\n\n# Transform strings\nnames = [\"alice\", \"bob\"]\n[name.upper() for name in names]  # [\"ALICE\", \"BOB\"]\n```\n\n---\n\n## üéØ Your Task\n\nCreate a list `doubled` containing each number from 1-5 doubled.\nResult: `[2, 4, 6, 8, 10]`\n",
    "starter_code": "# Create doubled list using comprehension\n\n\n# Print it\n",
    "solution_code": "# Create doubled list using comprehension\ndoubled = [x * 2 for x in range(1, 6)]\n\n# Print it\nprint(doubled)",
    "expected_output": "[2, 4, 6, 8, 10]",
    "chapter_id": 7,
    "chapter_title": "Data Structures"
  },
  "49": {
    "id": 49,
    "title": "Nested Data Structures",
    "content": "# ü™Ü Nested Data Structures\n\n## Lists of Dictionaries\n\nVery common pattern for storing collections of records:\n\n```python\nstudents = [\n    {\"name\": \"Alice\", \"grade\": 90},\n    {\"name\": \"Bob\", \"grade\": 85},\n    {\"name\": \"Charlie\", \"grade\": 92}\n]\n\n# Access\nprint(students[0][\"name\"])  # Alice\nprint(students[1][\"grade\"]) # 85\n```\n\n## Dictionaries of Lists\n\n```python\ngrades = {\n    \"Alice\": [90, 85, 88],\n    \"Bob\": [78, 82, 80]\n}\n\n# Average for Alice\nprint(sum(grades[\"Alice\"]) / len(grades[\"Alice\"]))  # 87.67\n```\n\n## Looping Through Nested Structures\n\n```python\nfor student in students:\n    print(f\"{student['name']}: {student['grade']}\")\n```\n\n---\n\n## üéØ Your Task\n\nGiven:\n```python\nbooks = [\n    {\"title\": \"Python Guide\", \"pages\": 200},\n    {\"title\": \"Data Science\", \"pages\": 350}\n]\n```\nPrint the pages of the second book.\n",
    "starter_code": "books = [\n    {\"title\": \"Python Guide\", \"pages\": 200},\n    {\"title\": \"Data Science\", \"pages\": 350}\n]\n\n# Print pages of second book\n",
    "solution_code": "books = [\n    {\"title\": \"Python Guide\", \"pages\": 200},\n    {\"title\": \"Data Science\", \"pages\": 350}\n]\n\n# Print pages of second book\nprint(books[1][\"pages\"])",
    "expected_output": "350",
    "chapter_id": 7,
    "chapter_title": "Data Structures"
  },
  "50": {
    "id": 50,
    "title": "Reading Files",
    "content": "# üìñ Reading Files\n\n## Why Work with Files?\n\nPrograms need to read and write data that persists beyond when they run: configuration files, user data, logs, exports, and more.\n\n## The with Statement\n\nPython's `with` statement automatically handles opening and closing files:\n\n```python\nwith open(\"file.txt\", \"r\") as f:\n    content = f.read()\n    print(content)\n# File automatically closed when block ends\n```\n\n## File Modes\n\n| Mode | Description |\n| --- | --- |\n| `\"r\"` | Read (default) |\n| `\"w\"` | Write (overwrites!) |\n| `\"a\"` | Append |\n| `\"r+\"` | Read and write |\n\nNote: In this browser environment, we'll simulate file operations with strings.\n\n---\n\n## üéØ Your Task\n\nCreate a string `data = \"Hello from file!\"` and print it as if you read it from a file.\n",
    "starter_code": "# Simulate file content\ndata = \"Hello from file!\"\n\n# Print it\n",
    "solution_code": "# Simulate file content\ndata = \"Hello from file!\"\n\n# Print it\nprint(data)",
    "expected_output": "Hello from file!",
    "chapter_id": 8,
    "chapter_title": "File Handling"
  },
  "51": {
    "id": 51,
    "title": "Reading Lines",
    "content": "# üìã Reading Line by Line\n\n## Processing Files Line by Line\n\nFor large files, reading line by line is memory efficient:\n\n```python\nwith open(\"file.txt\") as f:\n    for line in f:\n        print(line.strip())  # strip() removes newline\n```\n\n## Other Reading Methods\n\n```python\nf.read()        # Entire file as one string\nf.readline()    # One line at a time\nf.readlines()   # List of all lines\n```\n\n## Working with Multi-line Strings\n\nIn the browser, we simulate files with multi-line strings:\n\n```python\ncontent = \"\"\"Line 1\nLine 2\nLine 3\"\"\"\n\nfor line in content.split('\\n'):\n    print(line)\n```\n\n---\n\n## üéØ Your Task\n\nGiven this multiline string:\n```python\nfile_content = \"\"\"Line 1\nLine 2\nLine 3\"\"\"\n```\nLoop through each line and print it.\n",
    "starter_code": "file_content = \"\"\"Line 1\nLine 2\nLine 3\"\"\"\n\n# Print each line\n",
    "solution_code": "file_content = \"\"\"Line 1\nLine 2\nLine 3\"\"\"\n\n# Print each line\nfor line in file_content.split('\\n'):\n    print(line)",
    "expected_output": "Line 1\nLine 2\nLine 3",
    "chapter_id": 8,
    "chapter_title": "File Handling"
  },
  "52": {
    "id": 52,
    "title": "CSV Data",
    "content": "# üìä Working with CSV\n\n## What is CSV?\n\n**CSV** (Comma-Separated Values) is a common format for data exchange:\n\n```\nname,age,city\nAlice,25,NYC\nBob,30,LA\n```\n\nEach line is a row, values separated by commas.\n\n## Parsing CSV Manually\n\n```python\ncsv_data = \"name,age\\nAlice,25\\nBob,30\"\nlines = csv_data.split('\\n')\n\nheader = lines[0].split(',')  # ['name', 'age']\nfor line in lines[1:]:\n    values = line.split(',')\n    print(dict(zip(header, values)))\n```\n\n## The csv Module\n\nPython has a built-in module for complex CSV:\n\n```python\nimport csv\nwith open('data.csv') as f:\n    reader = csv.reader(f)\n    for row in reader:\n        print(row)\n```\n\n---\n\n## üéØ Your Task\n\nGiven: `csv_data = \"name,age,city\\nAlice,25,NYC\\nBob,30,LA\"`\nSkip the header and print each person's name.\n",
    "starter_code": "csv_data = \"name,age,city\\nAlice,25,NYC\\nBob,30,LA\"\n\n# Skip header and print names\n",
    "solution_code": "csv_data = \"name,age,city\\nAlice,25,NYC\\nBob,30,LA\"\n\n# Skip header and print names\nlines = csv_data.split('\\n')\nfor line in lines[1:]:\n    name = line.split(',')[0]\n    print(name)",
    "expected_output": "Alice\nBob",
    "chapter_id": 8,
    "chapter_title": "File Handling"
  },
  "53": {
    "id": 53,
    "title": "JSON Basics",
    "content": "# üì¶ JSON Data\n\n## What is JSON?\n\n**JSON** (JavaScript Object Notation) is the standard for web data:\n\n```json\n{\"name\": \"Alice\", \"age\": 25, \"skills\": [\"Python\", \"SQL\"]}\n```\n\n## Working with JSON in Python\n\n```python\nimport json\n\n# Parse JSON string ‚Üí Python dict\ndata = json.loads('{\"name\": \"Alice\", \"age\": 25}')\nprint(data[\"name\"])  # Alice\n\n# Python dict ‚Üí JSON string\njson_str = json.dumps({\"name\": \"Bob\"})\nprint(json_str)  # {\"name\": \"Bob\"}\n```\n\n## JSON and Files\n\n```python\n# Read from file\nwith open(\"data.json\") as f:\n    data = json.load(f)\n\n# Write to file\nwith open(\"output.json\", \"w\") as f:\n    json.dump(data, f)\n```\n\n---\n\n## üéØ Your Task\n\nGiven: `json_str = '{\"name\": \"Alice\", \"score\": 95}'`\nParse it and print the name.\n",
    "starter_code": "import json\n\njson_str = '{\"name\": \"Alice\", \"score\": 95}'\n\n# Parse and print name\n",
    "solution_code": "import json\n\njson_str = '{\"name\": \"Alice\", \"score\": 95}'\n\n# Parse and print name\ndata = json.loads(json_str)\nprint(data[\"name\"])",
    "expected_output": "Alice",
    "chapter_id": 8,
    "chapter_title": "File Handling"
  },
  "54": {
    "id": 54,
    "title": "String Processing",
    "content": "# üîç Processing Text Data\n\n## Common String Operations\n\nWhen working with file data, you often need to clean and parse text:\n\n```python\ntext = \"  hello world  \"\n\ntext.strip()       # Remove whitespace\ntext.split()       # Split by whitespace\ntext.split(',')    # Split by comma\ntext.replace('a', 'b')\ntext.upper() / text.lower()\n```\n\n## Splitting Strings\n\n```python\n# Split by whitespace (default)\n\"hello world\".split()  # ['hello', 'world']\n\n# Split by specific character\n\"a,b,c\".split(',')     # ['a', 'b', 'c']\n\n# Split with limit\n\"a,b,c,d\".split(',', 2)  # ['a', 'b', 'c,d']\n```\n\n---\n\n## üéØ Your Task\n\nGiven: `text = \"apple,banana,cherry\"`\nSplit by comma and print each fruit.\n",
    "starter_code": "text = \"apple,banana,cherry\"\n\n# Split and print each\n",
    "solution_code": "text = \"apple,banana,cherry\"\n\n# Split and print each\nfruits = text.split(',')\nfor fruit in fruits:\n    print(fruit)",
    "expected_output": "apple\nbanana\ncherry",
    "chapter_id": 8,
    "chapter_title": "File Handling"
  },
  "55": {
    "id": 55,
    "title": "Data Parsing",
    "content": "# üîß Parsing Structured Data\n\n## Extracting Information\n\nReal data is often messy and needs parsing:\n\n```python\nlog = \"2024-01-15 14:30:00 - User logged in\"\n\n# Split and extract\nparts = log.split(' - ')\ntimestamp = parts[0]  # \"2024-01-15 14:30:00\"\nmessage = parts[1]    # \"User logged in\"\n```\n\n## Multiple Levels of Parsing\n\n```python\ntimestamp = \"2024-01-15 14:30:00\"\ndate, time = timestamp.split(' ')\nyear, month, day = date.split('-')\n```\n\n---\n\n## üéØ Your Task\n\nGiven: `log = \"2024-01-15: User logged in\"`\nExtract and print just the date part.\n",
    "starter_code": "log = \"2024-01-15: User logged in\"\n\n# Extract and print date\n",
    "solution_code": "log = \"2024-01-15: User logged in\"\n\n# Extract and print date\ndate = log.split(':')[0]\nprint(date)",
    "expected_output": "2024-01-15",
    "chapter_id": 8,
    "chapter_title": "File Handling"
  },
  "56": {
    "id": 56,
    "title": "Counting Words",
    "content": "# üìä Word Count\n\n## Counting Elements in Text\n\nWord count is a fundamental text analysis operation:\n\n```python\ntext = \"Hello world hello\"\nwords = text.split()\nprint(len(words))  # 3\n```\n\n## Counting Specific Items\n\n```python\nfrom collections import Counter\nwords = \"the cat sat on the mat\".split()\ncounts = Counter(words)\nprint(counts)  # Counter({'the': 2, 'cat': 1, 'sat': 1, ...})\n```\n\n---\n\n## üéØ Your Task\n\nGiven: `text = \"The quick brown fox jumps\"`\nCount and print the number of words.\n",
    "starter_code": "text = \"The quick brown fox jumps\"\n\n# Count and print\n",
    "solution_code": "text = \"The quick brown fox jumps\"\n\n# Count and print\nwords = text.split()\nprint(len(words))",
    "expected_output": "5",
    "chapter_id": 8,
    "chapter_title": "File Handling"
  },
  "57": {
    "id": 57,
    "title": "Search in Text",
    "content": "# üîç Finding Text\n\n## Checking for Substrings\n\n```python\ntext = \"Hello, World!\"\n\n# Check if contains\n\"World\" in text      # True\n\"world\" in text      # False (case-sensitive)\n\"world\" in text.lower()  # True (after lowercasing)\n\n# Find position\ntext.find(\"World\")   # 7 (index)\ntext.find(\"xyz\")     # -1 (not found)\n```\n\n## String Methods for Searching\n\n```python\ntext.startswith(\"Hello\")  # True\ntext.endswith(\"!\")        # True\ntext.count(\"l\")           # 3\n```\n\n---\n\n## üéØ Your Task\n\nGiven: `message = \"Welcome to Python programming\"`\nCheck if \"Python\" is in the message. Print `\"Found\"` if yes.\n",
    "starter_code": "message = \"Welcome to Python programming\"\n\n# Check for \"Python\"\n",
    "solution_code": "message = \"Welcome to Python programming\"\n\n# Check for \"Python\"\nif \"Python\" in message:\n    print(\"Found\")",
    "expected_output": "Found",
    "chapter_id": 8,
    "chapter_title": "File Handling"
  },
  "58": {
    "id": 58,
    "title": "Replace Text",
    "content": "# üîÑ Replacing Text\n\n## The replace() Method\n\n```python\ntext = \"Hello World\"\nnew_text = text.replace(\"World\", \"Python\")\nprint(new_text)  # Hello Python\n```\n\n## Multiple Replacements\n\n```python\ntext = \"a-b-c-d\"\nclean = text.replace(\"-\", \" \")\nprint(clean)  # a b c d\n```\n\n## Case-Sensitive\n\nReplace is case-sensitive:\n```python\n\"Hello World\".replace(\"world\", \"Python\")  # \"Hello World\" (no change!)\n\"Hello World\".replace(\"World\", \"Python\")  # \"Hello Python\"\n```\n\n---\n\n## üéØ Your Task\n\nGiven: `text = \"Hello World\"`\nReplace \"World\" with \"Python\" and print.\n",
    "starter_code": "text = \"Hello World\"\n\n# Replace and print\n",
    "solution_code": "text = \"Hello World\"\n\n# Replace and print\nnew_text = text.replace(\"World\", \"Python\")\nprint(new_text)",
    "expected_output": "Hello Python",
    "chapter_id": 8,
    "chapter_title": "File Handling"
  },
  "59": {
    "id": 59,
    "title": "Importing Modules",
    "content": "# üì¶ Importing Modules\n\n## What is a Module?\n\nA **module** is a file containing Python code (functions, classes, variables) that you can reuse in other programs. Think of it as a toolbox of pre-written code.\n\n## Why Use Modules?\n\n| Benefit | Description |\n| --- | --- |\n| **Don't reinvent the wheel** | Experts have already written tested code |\n| **Organization** | Split large programs into manageable files |\n| **Reusability** | Write once, use everywhere |\n| **Community** | Access thousands of open-source packages |\n\n## Built-in Modules\n\nPython comes with many useful modules:\n\n```python\nimport math\nprint(math.sqrt(16))  # 4.0\nprint(math.pi)        # 3.14159...\nprint(math.floor(3.7))  # 3\nprint(math.ceil(3.2))   # 4\n```\n\n## How Import Works\n\nWhen you write `import math`:\n1. Python finds the module file\n2. Runs the code once\n3. Creates a namespace `math` with all its contents\n4. You access items with `math.something`\n\n---\n\n## üéØ Your Task\n\nImport the `math` module and print the square root of `25`.\n",
    "starter_code": "# Import math\n\n\n# Print sqrt of 25\n",
    "solution_code": "# Import math\nimport math\n\n# Print sqrt of 25\nprint(math.sqrt(25))",
    "expected_output": "5.0",
    "chapter_id": 9,
    "chapter_title": "Modules & Packages"
  },
  "60": {
    "id": 60,
    "title": "From Import",
    "content": "# üéØ Specific Imports\n\n## Import Only What You Need\n\nInstead of importing the entire module, import specific items:\n\n```python\nfrom math import pi, sqrt\n\n# Now use directly - no math. prefix needed!\nprint(pi)       # 3.14159...\nprint(sqrt(16)) # 4.0\n```\n\n## Comparison\n\n| Style | Syntax | Usage |\n| --- | --- | --- |\n| Full import | `import math` | `math.sqrt(16)` |\n| Specific import | `from math import sqrt` | `sqrt(16)` |\n\n## Import All (Use Carefully!)\n\n```python\nfrom math import *  # Imports EVERYTHING\n```\n\n‚ö†Ô∏è **Warning**: This can cause naming conflicts if two modules have functions with the same name!\n\n## Best Practices\n\n```python\n# Good - explicit about what you're using\nfrom math import pi, sqrt, floor\n\n# Good - clear namespace\nimport math\n\n# Risky - unclear what's available\nfrom math import *\n```\n\n---\n\n## üéØ Your Task\n\nFrom the `math` module, import `pi` and print it rounded to 2 decimal places.\n",
    "starter_code": "# Import pi from math\n\n\n# Print rounded to 2 decimals\n",
    "solution_code": "# Import pi from math\nfrom math import pi\n\n# Print rounded to 2 decimals\nprint(round(pi, 2))",
    "expected_output": "3.14",
    "chapter_id": 9,
    "chapter_title": "Modules & Packages"
  },
  "61": {
    "id": 61,
    "title": "Random Module",
    "content": "# üé≤ Random Numbers\n\n## The random Module\n\nGenerate random values for games, simulations, testing, and more!\n\n```python\nimport random\n\nrandom.randint(1, 10)           # Random integer 1-10 (inclusive)\nrandom.random()                  # Random float 0.0 to 1.0\nrandom.choice(['a', 'b', 'c'])  # Random pick from list\nrandom.shuffle(my_list)          # Shuffle list in place\nrandom.sample(my_list, 3)        # Pick 3 random items\n```\n\n## Real-World Uses\n\n- Games: dice rolls, card dealing, enemy spawns\n- Testing: generating test data\n- Statistics: sampling data\n- Security: generating tokens (use `secrets` module for true security)\n\n## Reproducibility with Seeds\n\nFor testing, you often need the same \"random\" results:\n\n```python\nrandom.seed(42)  # Set the seed\nprint(random.randint(1, 100))  # Always 82 with seed 42!\nprint(random.randint(1, 100))  # Always 35 with seed 42!\n```\n\nResetting the seed gives the same sequence every time.\n\n---\n\n## üéØ Your Task\n\nSet `random.seed(42)`, then generate and print a random integer between 1 and 100 (inclusive).\n",
    "starter_code": "import random\n\n# Set seed for consistency\nrandom.seed(42)\n\n# Print random 1-100\n",
    "solution_code": "import random\n\n# Set seed for consistency\nrandom.seed(42)\n\n# Print random 1-100\nprint(random.randint(1, 100))",
    "expected_output": "82",
    "chapter_id": 9,
    "chapter_title": "Modules & Packages"
  },
  "62": {
    "id": 62,
    "title": "Datetime Module",
    "content": "# üìÖ Working with Dates and Times\n\n## The datetime Module\n\nHandle dates, times, and durations:\n\n```python\nfrom datetime import date, datetime, timedelta\n\n# Current date/time\ntoday = date.today()      # 2024-01-15\nnow = datetime.now()      # 2024-01-15 14:30:00\n\n# Create specific dates\nbirthday = date(1995, 6, 15)\nmeeting = datetime(2024, 12, 25, 10, 30)\n```\n\n## Date Formatting\n\nConvert dates to custom string formats:\n\n```python\nnow = datetime.now()\nnow.strftime(\"%Y-%m-%d\")     # \"2024-01-15\"\nnow.strftime(\"%B %d, %Y\")    # \"January 15, 2024\"\nnow.strftime(\"%H:%M:%S\")     # \"14:30:00\"\n```\n\n## Date Arithmetic\n\nAdd or subtract time using `timedelta`:\n\n```python\nfrom datetime import timedelta\n\ntoday = date.today()\ntomorrow = today + timedelta(days=1)\nnext_week = today + timedelta(weeks=1)\n```\n\n---\n\n## üéØ Your Task\n\nCreate a date object for January 1, 2024 using `date(2024, 1, 1)` and print it.\n",
    "starter_code": "from datetime import date\n\n# Create Jan 1, 2024\n\n\n# Print it\n",
    "solution_code": "from datetime import date\n\n# Create Jan 1, 2024\nnew_year = date(2024, 1, 1)\n\n# Print it\nprint(new_year)",
    "expected_output": "2024-01-01",
    "chapter_id": 9,
    "chapter_title": "Modules & Packages"
  },
  "63": {
    "id": 63,
    "title": "Collections Module",
    "content": "# üìä Counter from Collections\n\n## The Counter Class\n\n`Counter` is a specialized dictionary for counting things:\n\n```python\nfrom collections import Counter\n\n# Count items in a list\ncolors = ['red', 'blue', 'red', 'green', 'blue', 'red']\ncounts = Counter(colors)\nprint(counts)  # Counter({'red': 3, 'blue': 2, 'green': 1})\n\n# Count characters in a string\nletter_counts = Counter(\"mississippi\")\n# Counter({'i': 4, 's': 4, 'p': 2, 'm': 1})\n```\n\n## Useful Counter Methods\n\n```python\ncounts.most_common(2)      # [('red', 3), ('blue', 2)]\ncounts['red']              # 3\ncounts['purple']           # 0 (no KeyError!)\ncounts.total()             # Sum of all counts\n```\n\n## Why Use Counter?\n\n- Count word frequencies in text\n- Find most common items\n- Tally votes or scores\n- Analyze data distributions\n\n---\n\n## üéØ Your Task\n\nCount the letters in the word `\"hello\"` using Counter and print the result.\n",
    "starter_code": "from collections import Counter\n\nword = \"hello\"\n\n# Count and print\n",
    "solution_code": "from collections import Counter\n\nword = \"hello\"\n\n# Count and print\ncounts = Counter(word)\nprint(counts)",
    "expected_output": "Counter({'l': 2, 'h': 1, 'e': 1, 'o': 1})",
    "chapter_id": 9,
    "chapter_title": "Modules & Packages"
  },
  "64": {
    "id": 64,
    "title": "Aliases",
    "content": "# üè∑Ô∏è Import Aliases\n\n## Shortening Module Names\n\nSome modules have long names. Use `as` to create shorter aliases:\n\n```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n```\n\n## Why Use Aliases?\n\n1. **Less typing**: `np.array()` vs `numpy.array()`\n2. **Industry standard**: Everyone uses these conventions\n3. **Code readability**: Familiar patterns\n\n## Common Conventions\n\n| Module | Standard Alias |\n| --- | --- |\n| numpy | np |\n| pandas | pd |\n| matplotlib.pyplot | plt |\n| seaborn | sns |\n| tensorflow | tf |\n\n## Creating Your Own Aliases\n\n```python\nimport statistics as stats\nprint(stats.mean([1, 2, 3, 4, 5]))\n\nimport math as m\nprint(m.sqrt(16))  # 4.0\n```\n\n---\n\n## üéØ Your Task\n\nImport `math` with the alias `m` and print `m.floor(7.8)`.\n",
    "starter_code": "# Import math as m\n\n\n# Print floor of 7.8\n",
    "solution_code": "# Import math as m\nimport math as m\n\n# Print floor of 7.8\nprint(m.floor(7.8))",
    "expected_output": "7",
    "chapter_id": 9,
    "chapter_title": "Modules & Packages"
  },
  "65": {
    "id": 65,
    "title": "OS Path",
    "content": "# üìÇ OS Path Operations\n\n## Working with File Paths\n\nThe `os` module helps work with file paths in a **cross-platform** way:\n\n```python\nimport os\n\n# Join paths (works on Windows AND Mac/Linux)\npath = os.path.join(\"folder\", \"subfolder\", \"file.txt\")\n# Windows: folder\\subfolder\\file.txt\n# Mac/Linux: folder/subfolder/file.txt\n```\n\n## Common Path Operations\n\n```python\nimport os\n\n# Check if exists\nos.path.exists(\"file.txt\")     # True/False\n\n# Get parts of a path\nos.path.dirname(\"/a/b/c.txt\")  # \"/a/b\"\nos.path.basename(\"/a/b/c.txt\") # \"c.txt\"\nos.path.splitext(\"data.csv\")   # (\"data\", \".csv\")\n\n# Get current directory\nos.getcwd()\n\n# List files in directory\nos.listdir(\".\")\n```\n\n## Why Use os.path?\n\nNever hardcode paths like `\"folder/file.txt\"` because:\n- Windows uses `\\`, Mac/Linux use `/`\n- `os.path.join()` handles this automatically!\n\n---\n\n## üéØ Your Task\n\nUse `os.path.join()` to combine `\"data\"` and `\"report.csv\"` into a path, then print it.\n",
    "starter_code": "import os\n\n# Join path parts\n\n\n# Print path\n",
    "solution_code": "import os\n\n# Join path parts\npath = os.path.join(\"data\", \"report.csv\")\n\n# Print path\nprint(path)",
    "expected_output": "data/report.csv",
    "chapter_id": 9,
    "chapter_title": "Modules & Packages"
  },
  "66": {
    "id": 66,
    "title": "Itertools",
    "content": "# üîÑ Itertools Module\n\n## Powerful Iteration Tools\n\nThe `itertools` module provides advanced iteration utilities:\n\n```python\nfrom itertools import combinations, permutations, product\n\n# Combinations: order doesn't matter\nlist(combinations([1, 2, 3], 2))\n# [(1, 2), (1, 3), (2, 3)]\n\n# Permutations: order matters\nlist(permutations([1, 2, 3], 2))\n# [(1, 2), (1, 3), (2, 1), (2, 3), (3, 1), (3, 2)]\n\n# Product: all combinations of multiple lists\nlist(product(['A', 'B'], [1, 2]))\n# [('A', 1), ('A', 2), ('B', 1), ('B', 2)]\n```\n\n## Other Useful Functions\n\n```python\nfrom itertools import cycle, count, chain\n\n# Infinite repeating\ncolors = cycle(['red', 'green', 'blue'])\nnext(colors)  # 'red', 'green', 'blue', 'red'...\n\n# Chain multiple iterables\nlist(chain([1, 2], [3, 4]))  # [1, 2, 3, 4]\n```\n\n---\n\n## üéØ Your Task\n\nGet all combinations of 2 items from the list `[\"A\", \"B\", \"C\"]` and print the result.\n",
    "starter_code": "from itertools import combinations\n\nletters = [\"A\", \"B\", \"C\"]\n\n# Get pairs and print\n",
    "solution_code": "from itertools import combinations\n\nletters = [\"A\", \"B\", \"C\"]\n\n# Get pairs and print\npairs = list(combinations(letters, 2))\nprint(pairs)",
    "expected_output": "[('A', 'B'), ('A', 'C'), ('B', 'C')]",
    "chapter_id": 9,
    "chapter_title": "Modules & Packages"
  },
  "67": {
    "id": 67,
    "title": "Functools",
    "content": "# ‚öôÔ∏è Functools Module\n\n## Functions That Work with Functions\n\n`functools` provides higher-order functions - functions that work on other functions.\n\n## The reduce Function\n\nApplies a function cumulatively to reduce a list to a single value:\n\n```python\nfrom functools import reduce\n\n# Sum all numbers: ((1+2)+3)+4 = 10\nresult = reduce(lambda x, y: x + y, [1, 2, 3, 4])\n\n# Find maximum\nmax_val = reduce(lambda x, y: x if x > y else y, [3, 1, 4, 1, 5])\n# Result: 5\n```\n\n## How reduce Works Step by Step\n\n```python\nreduce(lambda x, y: x * y, [2, 3, 4, 5])\n# Step 1: 2 * 3 = 6\n# Step 2: 6 * 4 = 24\n# Step 3: 24 * 5 = 120\n```\n\n## Other Useful Functions\n\n```python\nfrom functools import partial\n\n# Create a specialized function\ndef power(base, exp):\n    return base ** exp\n\nsquare = partial(power, exp=2)\ncube = partial(power, exp=3)\n\nprint(square(5))  # 25\nprint(cube(5))    # 125\n```\n\n---\n\n## üéØ Your Task\n\nUse `reduce` with a lambda to multiply all numbers in `[2, 3, 4]` together. Print the result (should be 24).\n",
    "starter_code": "from functools import reduce\n\nnumbers = [2, 3, 4]\n\n# Multiply all and print\n",
    "solution_code": "from functools import reduce\n\nnumbers = [2, 3, 4]\n\n# Multiply all and print\nresult = reduce(lambda x, y: x * y, numbers)\nprint(result)",
    "expected_output": "24",
    "chapter_id": 9,
    "chapter_title": "Modules & Packages"
  },
  "68": {
    "id": 68,
    "title": "Creating DataFrames",
    "content": "# üêº Pandas DataFrames\n\n## What is Pandas?\n\n**Pandas** is Python's premier library for data analysis. It provides powerful tools for working with tabular data (rows and columns).\n\n## What is a DataFrame?\n\nA **DataFrame** is a 2D table with labeled rows and columns - like a spreadsheet or SQL table.\n\n```python\nimport pandas as pd\n\ndata = {\n    \"name\": [\"Alice\", \"Bob\", \"Charlie\"],\n    \"age\": [25, 30, 35],\n    \"city\": [\"NYC\", \"LA\", \"Chicago\"]\n}\n\ndf = pd.DataFrame(data)\nprint(df)\n```\n\nOutput:\n```\n      name  age     city\n0    Alice   25      NYC\n1      Bob   30       LA\n2  Charlie   35  Chicago\n```\n\n## Why Pandas?\n\n| Feature | Benefit |\n| --- | --- |\n| Handles millions of rows | Process big data efficiently |\n| Built-in data cleaning | Handle missing values, duplicates |\n| Powerful grouping | Aggregate and summarize data |\n| File I/O | Read CSV, Excel, JSON, SQL |\n\n---\n\n## üéØ Your Task\n\nCreate a DataFrame from `{\"name\": [\"Alice\", \"Bob\"], \"score\": [85, 90]}` and print it.\n",
    "starter_code": "import pandas as pd\n\ndata = {\"name\": [\"Alice\", \"Bob\"], \"score\": [85, 90]}\n\n# Create DataFrame\n\n\n# Print it\n",
    "solution_code": "import pandas as pd\n\ndata = {\"name\": [\"Alice\", \"Bob\"], \"score\": [85, 90]}\n\n# Create DataFrame\ndf = pd.DataFrame(data)\n\n# Print it\nprint(df)",
    "expected_output": "    name  score\n0  Alice     85\n1    Bob     90",
    "chapter_id": 10,
    "chapter_title": "Pandas & Data Wrangling"
  },
  "69": {
    "id": 69,
    "title": "Selecting Columns",
    "content": "# üìä Selecting Data from DataFrames\n\n## Accessing Columns\n\nThere are several ways to select data:\n\n```python\n# Single column ‚Üí returns a Series\ndf[\"name\"]\ndf.name  # Dot notation (if column name is valid identifier)\n\n# Multiple columns ‚Üí returns a DataFrame\ndf[[\"name\", \"age\"]]\n```\n\n## Accessing Rows\n\n```python\n# By position (integer index)\ndf.iloc[0]       # First row\ndf.iloc[0:3]     # First 3 rows\ndf.iloc[-1]      # Last row\n\n# By label\ndf.loc[0]        # Row with label 0\ndf.loc[0:2]      # Rows with labels 0 through 2 (inclusive!)\n\n# Handy shortcuts\ndf.head(3)       # First 3 rows\ndf.tail(2)       # Last 2 rows\n```\n\n## Selecting Both Rows and Columns\n\n```python\n# Specific rows and columns\ndf.loc[0:2, [\"name\", \"age\"]]\ndf.iloc[0:3, 0:2]\n```\n\n---\n\n## üéØ Your Task\n\nGiven a DataFrame with name, age, and city columns, print only the \"name\" column.\n",
    "starter_code": "import pandas as pd\n\ndata = {\"name\": [\"Alice\", \"Bob\"], \"age\": [25, 30], \"city\": [\"NYC\", \"LA\"]}\ndf = pd.DataFrame(data)\n\n# Print name column\n",
    "solution_code": "import pandas as pd\n\ndata = {\"name\": [\"Alice\", \"Bob\"], \"age\": [25, 30], \"city\": [\"NYC\", \"LA\"]}\ndf = pd.DataFrame(data)\n\n# Print name column\nprint(df[\"name\"])",
    "expected_output": "0    Alice\n1      Bob\nName: name, dtype: object",
    "chapter_id": 10,
    "chapter_title": "Pandas & Data Wrangling"
  },
  "70": {
    "id": 70,
    "title": "Filtering Rows",
    "content": "# üîç Filtering Data\n\n## Boolean Indexing\n\nFilter rows based on conditions:\n\n```python\n# Rows where age > 25\ndf[df[\"age\"] > 25]\n\n# Rows where name is \"Alice\"\ndf[df[\"name\"] == \"Alice\"]\n\n# Rows where score is between 80 and 90\ndf[(df[\"score\"] >= 80) & (df[\"score\"] <= 90)]\n```\n\n## Multiple Conditions\n\nUse `&` for AND, `|` for OR (wrap each condition in parentheses):\n\n```python\n# AND: both conditions must be true\ndf[(df[\"age\"] > 25) & (df[\"city\"] == \"NYC\")]\n\n# OR: at least one must be true\ndf[(df[\"age\"] > 40) | (df[\"score\"] > 90)]\n```\n\n## Filtering with isin()\n\n```python\n# Check if value is in a list\ndf[df[\"city\"].isin([\"NYC\", \"LA\"])]\n```\n\n## Filtering String Columns\n\n```python\ndf[df[\"name\"].str.contains(\"li\")]     # Contains \"li\"\ndf[df[\"name\"].str.startswith(\"A\")]    # Starts with \"A\"\n```\n\n---\n\n## üéØ Your Task\n\nFilter rows where score > 80 and print the result.\n",
    "starter_code": "import pandas as pd\n\ndata = {\"name\": [\"Alice\", \"Bob\", \"Charlie\"], \"score\": [85, 70, 95]}\ndf = pd.DataFrame(data)\n\n# Filter score > 80\n",
    "solution_code": "import pandas as pd\n\ndata = {\"name\": [\"Alice\", \"Bob\", \"Charlie\"], \"score\": [85, 70, 95]}\ndf = pd.DataFrame(data)\n\n# Filter score > 80\nprint(df[df[\"score\"] > 80])",
    "expected_output": "      name  score\n0    Alice     85\n2  Charlie     95",
    "chapter_id": 10,
    "chapter_title": "Pandas & Data Wrangling"
  },
  "71": {
    "id": 71,
    "title": "Basic Statistics",
    "content": "# üìà Statistics in Pandas\n\n## Quick Column Statistics\n\nPandas makes statistical analysis easy:\n\n```python\ndf[\"column\"].mean()     # Average\ndf[\"column\"].median()   # Middle value\ndf[\"column\"].sum()      # Total\ndf[\"column\"].min()      # Minimum\ndf[\"column\"].max()      # Maximum\ndf[\"column\"].std()      # Standard deviation\ndf[\"column\"].count()    # Count non-null values\n```\n\n## Get All Stats at Once\n\n```python\ndf.describe()\n```\n\nReturns count, mean, std, min, 25%, 50%, 75%, max for all numeric columns!\n\n## Statistics Across the DataFrame\n\n```python\ndf.mean()         # Mean of each column\ndf.sum(axis=1)    # Sum across each row\n```\n\n## Value Distribution\n\n```python\ndf[\"column\"].value_counts()   # Count each unique value\ndf[\"column\"].unique()         # Get unique values\ndf[\"column\"].nunique()        # Count unique values\n```\n\n---\n\n## üéØ Your Task\n\nCalculate and print the mean of the \"value\" column.\n",
    "starter_code": "import pandas as pd\n\ndata = {\"value\": [10, 20, 30, 40, 50]}\ndf = pd.DataFrame(data)\n\n# Print mean\n",
    "solution_code": "import pandas as pd\n\ndata = {\"value\": [10, 20, 30, 40, 50]}\ndf = pd.DataFrame(data)\n\n# Print mean\nprint(df[\"value\"].mean())",
    "expected_output": "30.0",
    "chapter_id": 10,
    "chapter_title": "Pandas & Data Wrangling"
  },
  "72": {
    "id": 72,
    "title": "Adding Columns",
    "content": "# ‚ûï Creating New Columns\n\n## Calculate from Existing Columns\n\nCreate new columns based on existing data:\n\n```python\n# Simple calculation\ndf[\"total\"] = df[\"price\"] * df[\"quantity\"]\n\n# Using multiple columns\ndf[\"profit\"] = df[\"revenue\"] - df[\"cost\"]\n\n# Apply a function\ndf[\"age_in_months\"] = df[\"age\"] * 12\n```\n\n## Transform String Columns\n\n```python\ndf[\"name_upper\"] = df[\"name\"].str.upper()\ndf[\"name_length\"] = df[\"name\"].str.len()\ndf[\"first_initial\"] = df[\"name\"].str[0]\n```\n\n## Conditional Columns\n\n```python\n# Using apply with lambda\ndf[\"status\"] = df[\"score\"].apply(lambda x: \"Pass\" if x >= 70 else \"Fail\")\n\n# Using numpy where\nimport numpy as np\ndf[\"status\"] = np.where(df[\"score\"] >= 70, \"Pass\", \"Fail\")\n```\n\n## Modify Existing Columns\n\n```python\ndf[\"price\"] = df[\"price\"] * 1.10  # 10% increase\n```\n\n---\n\n## üéØ Your Task\n\nAdd a \"total\" column that equals price √ó quantity, then print the DataFrame.\n",
    "starter_code": "import pandas as pd\n\ndata = {\"price\": [100, 200], \"quantity\": [2, 3]}\ndf = pd.DataFrame(data)\n\n# Add total column\n\n\n# Print df\n",
    "solution_code": "import pandas as pd\n\ndata = {\"price\": [100, 200], \"quantity\": [2, 3]}\ndf = pd.DataFrame(data)\n\n# Add total column\ndf[\"total\"] = df[\"price\"] * df[\"quantity\"]\n\n# Print df\nprint(df)",
    "expected_output": "   price  quantity  total\n0    100         2    200\n1    200         3    600",
    "chapter_id": 10,
    "chapter_title": "Pandas & Data Wrangling"
  },
  "73": {
    "id": 73,
    "title": "GroupBy",
    "content": "# üìä Grouping and Aggregating\n\n## The Power of GroupBy\n\nGroup data by categories and calculate statistics:\n\n```python\n# Group by one column\ndf.groupby(\"category\").sum()\ndf.groupby(\"category\")[\"value\"].mean()\n\n# Group by multiple columns\ndf.groupby([\"year\", \"category\"]).count()\n```\n\n## How GroupBy Works\n\n1. **Split**: Divide data into groups\n2. **Apply**: Calculate statistic for each group\n3. **Combine**: Merge results\n\n```python\n# Multiple aggregations at once\ndf.groupby(\"category\").agg({\n    \"sales\": \"sum\",\n    \"profit\": \"mean\",\n    \"orders\": \"count\"\n})\n```\n\n## Common Use Cases\n\n- Sales by region\n- Average score by grade level\n- Count of users by country\n- Revenue by product category\n\n---\n\n## üéØ Your Task\n\nGroup the data by category and print the sum of values for each category.\n",
    "starter_code": "import pandas as pd\n\ndata = {\"category\": [\"A\", \"B\", \"A\"], \"value\": [10, 20, 30]}\ndf = pd.DataFrame(data)\n\n# Group and sum\n",
    "solution_code": "import pandas as pd\n\ndata = {\"category\": [\"A\", \"B\", \"A\"], \"value\": [10, 20, 30]}\ndf = pd.DataFrame(data)\n\n# Group and sum\nprint(df.groupby(\"category\").sum())",
    "expected_output": "          value\ncategory       \nA            40\nB            20",
    "chapter_id": 10,
    "chapter_title": "Pandas & Data Wrangling"
  },
  "74": {
    "id": 74,
    "title": "Sorting",
    "content": "# üîÑ Sorting DataFrames\n\n## Sort by Column\n\n```python\n# Ascending (default)\ndf.sort_values(\"score\")\n\n# Descending\ndf.sort_values(\"score\", ascending=False)\n\n# Sort by multiple columns\ndf.sort_values([\"grade\", \"score\"], ascending=[True, False])\n```\n\n## Sort by Index\n\n```python\ndf.sort_index()                    # Sort by row labels\ndf.sort_index(ascending=False)     # Reverse order\n```\n\n## Keeping Changes\n\nBy default, sorting returns a new DataFrame:\n\n```python\n# Returns new DataFrame\nsorted_df = df.sort_values(\"score\")\n\n# Modify in place\ndf.sort_values(\"score\", inplace=True)\n```\n\n## Practical Example\n\n```python\n# Top 10 highest scores\ntop_10 = df.sort_values(\"score\", ascending=False).head(10)\n```\n\n---\n\n## üéØ Your Task\n\nSort the DataFrame by score in descending order and print it.\n",
    "starter_code": "import pandas as pd\n\ndata = {\"name\": [\"Alice\", \"Bob\", \"Charlie\"], \"score\": [85, 95, 70]}\ndf = pd.DataFrame(data)\n\n# Sort by score descending\n",
    "solution_code": "import pandas as pd\n\ndata = {\"name\": [\"Alice\", \"Bob\", \"Charlie\"], \"score\": [85, 95, 70]}\ndf = pd.DataFrame(data)\n\n# Sort by score descending\nprint(df.sort_values(\"score\", ascending=False))",
    "expected_output": "      name  score\n1      Bob     95\n0    Alice     85\n2  Charlie     70",
    "chapter_id": 10,
    "chapter_title": "Pandas & Data Wrangling"
  },
  "75": {
    "id": 75,
    "title": "Handling Missing Data",
    "content": "# ‚ùì Handling Missing Values\n\n## Detecting Missing Data\n\nIn Pandas, missing values are represented as `NaN` (Not a Number):\n\n```python\nimport numpy as np\n\ndf.isna()           # True where NaN\ndf.notna()          # True where NOT NaN\ndf.isna().sum()     # Count NaN per column\ndf.isna().any()     # Any NaN in each column?\n```\n\n## Dealing with Missing Data\n\n```python\n# Drop rows with any NaN\ndf.dropna()\n\n# Drop rows where specific column is NaN\ndf.dropna(subset=[\"name\"])\n\n# Fill NaN with a value\ndf.fillna(0)\ndf.fillna(df.mean())  # Fill with column mean\ndf.fillna(method=\"ffill\")  # Forward fill\n```\n\n## Real-World Approach\n\nDecide based on context:\n- **Drop**: If few missing and rows not critical\n- **Fill with value**: If you have a sensible default\n- **Fill with statistic**: Mean, median, mode for numeric data\n- **Keep as-is**: Some algorithms handle NaN\n\n---\n\n## üéØ Your Task\n\nFill NaN values with 0 and print the result.\n",
    "starter_code": "import pandas as pd\nimport numpy as np\n\ndata = {\"value\": [1, np.nan, 3]}\ndf = pd.DataFrame(data)\n\n# Fill NaN with 0\n",
    "solution_code": "import pandas as pd\nimport numpy as np\n\ndata = {\"value\": [1, np.nan, 3]}\ndf = pd.DataFrame(data)\n\n# Fill NaN with 0\nprint(df.fillna(0))",
    "expected_output": "   value\n0    1.0\n1    0.0\n2    3.0",
    "chapter_id": 10,
    "chapter_title": "Pandas & Data Wrangling"
  },
  "76": {
    "id": 76,
    "title": "Value Counts",
    "content": "# üìä Counting Unique Values\n\n## value_counts()\n\nSee the distribution of values in a column:\n\n```python\ndf[\"color\"].value_counts()\n# red      10\n# blue      7\n# green     3\n```\n\n## Options\n\n```python\n# Normalize to get percentages\ndf[\"color\"].value_counts(normalize=True)\n# red      0.50\n# blue     0.35\n# green    0.15\n\n# Include NaN values\ndf[\"color\"].value_counts(dropna=False)\n\n# Sort by index instead of count\ndf[\"color\"].value_counts().sort_index()\n```\n\n## Use Cases\n\n- Analyze category distributions\n- Find most common values\n- Detect class imbalance in ML\n- Quality check data\n\n## With groupby\n\n```python\n# Count by multiple columns\ndf.groupby([\"year\", \"category\"]).size()\n```\n\n---\n\n## üéØ Your Task\n\nCount how many times each color appears and print the result.\n",
    "starter_code": "import pandas as pd\n\ndata = {\"color\": [\"red\", \"blue\", \"red\", \"green\", \"blue\", \"red\"]}\ndf = pd.DataFrame(data)\n\n# Count colors\n",
    "solution_code": "import pandas as pd\n\ndata = {\"color\": [\"red\", \"blue\", \"red\", \"green\", \"blue\", \"red\"]}\ndf = pd.DataFrame(data)\n\n# Count colors\nprint(df[\"color\"].value_counts())",
    "expected_output": "color\nred      3\nblue     2\ngreen    1\nName: count, dtype: int64",
    "chapter_id": 10,
    "chapter_title": "Pandas & Data Wrangling"
  },
  "77": {
    "id": 77,
    "title": "Line Plot",
    "content": "# üìà Creating Line Charts\n\n## Why Visualize Data?\n\nVisualizations help us:\n- **Understand patterns** at a glance\n- **Communicate insights** to others\n- **Spot trends, outliers, and anomalies**\n- **Tell stories with data**\n\n## Matplotlib: Python's Plotting Library\n\n```python\nimport matplotlib.pyplot as plt\n\n# Create a simple line plot\nx = [1, 2, 3, 4, 5]\ny = [1, 4, 9, 16, 25]  # Squares\n\nplt.plot(x, y)\nplt.show()\n```\n\n## How plt.plot() Works\n\n1. Create a figure and axes\n2. Plot the data points\n3. Connect them with lines\n4. `plt.show()` displays the result\n\n## When to Use Line Charts\n\n- **Time series data** (stock prices over time)\n- **Trends** (website traffic by month)\n- **Continuous data** where order matters\n\n---\n\n## üéØ Your Task\n\nCreate a line plot with x values `[0, 1, 2, 3, 4]` and y values `[0, 1, 4, 9, 16]` (squares).\n",
    "starter_code": "import matplotlib.pyplot as plt\n\nx = [0, 1, 2, 3, 4]\ny = [0, 1, 4, 9, 16]\n\n# Create line plot and show\n",
    "solution_code": "import matplotlib.pyplot as plt\n\nx = [0, 1, 2, 3, 4]\ny = [0, 1, 4, 9, 16]\n\n# Create line plot and show\nplt.plot(x, y)\nplt.show()",
    "expected_output": "[Graph: Line plot showing squares 0-16]",
    "chapter_id": 11,
    "chapter_title": "Data Visualization"
  },
  "78": {
    "id": 78,
    "title": "Bar Chart",
    "content": "# üìä Bar Charts\n\n## When to Use Bar Charts\n\nBar charts are perfect for:\n- **Comparing categories** (sales by region)\n- **Showing quantities** across groups\n- **Discrete, categorical data**\n\n## Creating a Bar Chart\n\n```python\nimport matplotlib.pyplot as plt\n\ncategories = [\"Apples\", \"Oranges\", \"Bananas\"]\nvalues = [25, 40, 30]\n\nplt.bar(categories, values)\nplt.show()\n```\n\n## Customization Options\n\n```python\n# Horizontal bars\nplt.barh(categories, values)\n\n# Custom colors\nplt.bar(categories, values, color=['red', 'orange', 'yellow'])\n\n# Add border\nplt.bar(categories, values, edgecolor='black', linewidth=1)\n```\n\n## Bar Chart vs Line Chart\n\n| Bar Chart | Line Chart |\n| --- | --- |\n| Categorical data | Sequential data |\n| Comparing groups | Showing trends |\n| No inherent order | Order matters |\n\n---\n\n## üéØ Your Task\n\nCreate a bar chart with categories `[\"A\", \"B\", \"C\"]` and values `[25, 40, 30]`.\n",
    "starter_code": "import matplotlib.pyplot as plt\n\ncategories = [\"A\", \"B\", \"C\"]\nvalues = [25, 40, 30]\n\n# Create bar chart\n",
    "solution_code": "import matplotlib.pyplot as plt\n\ncategories = [\"A\", \"B\", \"C\"]\nvalues = [25, 40, 30]\n\n# Create bar chart\nplt.bar(categories, values)\nplt.show()",
    "expected_output": "[Graph: Bar chart with A=25, B=40, C=30]",
    "chapter_id": 11,
    "chapter_title": "Data Visualization"
  },
  "79": {
    "id": 79,
    "title": "Scatter Plot",
    "content": "# ‚≠ê Scatter Plots\n\n## When to Use Scatter Plots\n\nScatter plots show the **relationship between two variables**:\n- Do taller people weigh more?\n- Does more advertising lead to more sales?\n- Is there a correlation?\n\n## Creating a Scatter Plot\n\n```python\nimport matplotlib.pyplot as plt\n\nx = [1, 2, 3, 4, 5]\ny = [2, 4, 5, 4, 5]\n\nplt.scatter(x, y)\nplt.show()\n```\n\n## Customization\n\n```python\n# Size and color\nplt.scatter(x, y, s=100, c='red')\n\n# Different sizes per point\nsizes = [20, 50, 100, 200, 500]\nplt.scatter(x, y, s=sizes)\n\n# Color by a third variable\ncolors = [1, 2, 3, 4, 5]\nplt.scatter(x, y, c=colors, cmap='viridis')\nplt.colorbar()  # Add color legend\n```\n\n## Reading Scatter Plots\n\n- **Positive correlation**: Points trend up-right\n- **Negative correlation**: Points trend down-right\n- **No correlation**: Points randomly scattered\n\n---\n\n## üéØ Your Task\n\nCreate a scatter plot with x `[1, 2, 3, 4, 5]` and y `[2, 4, 5, 4, 5]`.\n",
    "starter_code": "import matplotlib.pyplot as plt\n\nx = [1, 2, 3, 4, 5]\ny = [2, 4, 5, 4, 5]\n\n# Create scatter plot\n",
    "solution_code": "import matplotlib.pyplot as plt\n\nx = [1, 2, 3, 4, 5]\ny = [2, 4, 5, 4, 5]\n\n# Create scatter plot\nplt.scatter(x, y)\nplt.show()",
    "expected_output": "[Graph: Scatter plot with 5 points]",
    "chapter_id": 11,
    "chapter_title": "Data Visualization"
  },
  "80": {
    "id": 80,
    "title": "Histogram",
    "content": "# üìä Histograms\n\n## What is a Histogram?\n\nA histogram shows the **distribution** of data - how values are spread across ranges (bins).\n\n## Bar Chart vs Histogram\n\n| Bar Chart | Histogram |\n| --- | --- |\n| Categorical data | Continuous data |\n| Each bar is a category | Each bar is a range |\n| Bars have gaps | Bars touch |\n\n## Creating a Histogram\n\n```python\nimport matplotlib.pyplot as plt\n\nscores = [65, 70, 75, 80, 85, 90, 95, 70, 75, 80]\n\nplt.hist(scores, bins=5)\nplt.show()\n```\n\n## Bins: Dividing Your Data\n\nThe `bins` parameter controls how data is grouped:\n- More bins = more detail\n- Fewer bins = smoother view\n\n```python\nplt.hist(data, bins=10)   # Default\nplt.hist(data, bins=20)   # More detail\nplt.hist(data, bins=[0, 50, 70, 90, 100])  # Custom edges\n```\n\n## Reading Histograms\n\n- **Normal distribution**: Bell curve shape\n- **Skewed right**: Tail extends right\n- **Skewed left**: Tail extends left\n- **Uniform**: All bars similar height\n\n---\n\n## üéØ Your Task\n\nCreate a histogram of exam scores `[65, 70, 75, 80, 85, 90, 95, 70, 75, 80, 85, 80]` with 5 bins.\n",
    "starter_code": "import matplotlib.pyplot as plt\n\nscores = [65, 70, 75, 80, 85, 90, 95, 70, 75, 80, 85, 80]\n\n# Create histogram with 5 bins\n",
    "solution_code": "import matplotlib.pyplot as plt\n\nscores = [65, 70, 75, 80, 85, 90, 95, 70, 75, 80, 85, 80]\n\n# Create histogram with 5 bins\nplt.hist(scores, bins=5)\nplt.show()",
    "expected_output": "[Graph: Histogram of score distribution]",
    "chapter_id": 11,
    "chapter_title": "Data Visualization"
  },
  "81": {
    "id": 81,
    "title": "Pie Chart",
    "content": "# ü•ß Pie Charts\n\n## When to Use Pie Charts\n\nPie charts show **parts of a whole**:\n- Market share percentages\n- Budget allocation\n- Survey response distribution\n\n## Creating a Pie Chart\n\n```python\nimport matplotlib.pyplot as plt\n\nlabels = [\"Rent\", \"Food\", \"Transport\", \"Entertainment\"]\nvalues = [30, 25, 20, 25]\n\nplt.pie(values, labels=labels)\nplt.show()\n```\n\n## Customization\n\n```python\n# Add percentages\nplt.pie(values, labels=labels, autopct='%1.1f%%')\n\n# Explode a slice\nexplode = [0.1, 0, 0, 0]  # First slice stands out\nplt.pie(values, labels=labels, explode=explode)\n\n# Custom colors\ncolors = ['#ff9999', '#66b3ff', '#99ff99', '#ffcc99']\nplt.pie(values, labels=labels, colors=colors)\n\n# Make it a circle (equal aspect ratio)\nplt.axis('equal')\n```\n\n## Pie Chart Best Practices\n\n- Use for **5 or fewer categories** (too many is confusing)\n- Label clearly\n- Start largest slice at 12 o'clock\n- Consider bar charts for precise comparisons\n\n---\n\n## üéØ Your Task\n\nCreate a pie chart showing market share with labels `[\"Apple\", \"Google\", \"Microsoft\"]` and values `[30, 45, 25]`.\n",
    "starter_code": "import matplotlib.pyplot as plt\n\nlabels = [\"Apple\", \"Google\", \"Microsoft\"]\nvalues = [30, 45, 25]\n\n# Create pie chart\n",
    "solution_code": "import matplotlib.pyplot as plt\n\nlabels = [\"Apple\", \"Google\", \"Microsoft\"]\nvalues = [30, 45, 25]\n\n# Create pie chart\nplt.pie(values, labels=labels)\nplt.show()",
    "expected_output": "[Graph: Pie chart with 3 segments]",
    "chapter_id": 11,
    "chapter_title": "Data Visualization"
  },
  "82": {
    "id": 82,
    "title": "Adding Labels",
    "content": "# üè∑Ô∏è Chart Labels and Titles\n\n## Professional Charts Need Labels\n\nA chart without labels is like a map without names - useless!\n\n```python\nimport matplotlib.pyplot as plt\n\nplt.plot([1, 2, 3], [1, 4, 9])\n\n# Add labels and title\nplt.title(\"My Chart Title\")\nplt.xlabel(\"X Axis Label\")\nplt.ylabel(\"Y Axis Label\")\n\nplt.show()\n```\n\n## More Customization\n\n```python\n# Font sizes\nplt.title(\"Title\", fontsize=16, fontweight='bold')\nplt.xlabel(\"X Label\", fontsize=12)\nplt.ylabel(\"Y Label\", fontsize=12)\n\n# Add a grid\nplt.grid(True)\nplt.grid(True, linestyle='--', alpha=0.7)\n\n# Set axis limits\nplt.xlim(0, 10)\nplt.ylim(0, 100)\n\n# Add text annotation\nplt.text(x, y, \"Label here\")\n```\n\n## Complete Example\n\n```python\nplt.plot(days, temps)\nplt.title(\"Daily Temperature\")\nplt.xlabel(\"Day\")\nplt.ylabel(\"Temperature (¬∞C)\")\nplt.grid(True)\nplt.show()\n```\n\n---\n\n## üéØ Your Task\n\nPlot temperatures `[20, 22, 25, 23, 21]` over days 1-5. Add title \"Daily Temperature\" and labels \"Day\" and \"Temp (¬∞C)\".\n",
    "starter_code": "import matplotlib.pyplot as plt\n\ndays = [1, 2, 3, 4, 5]\ntemps = [20, 22, 25, 23, 21]\n\n# Create plot with labels\n",
    "solution_code": "import matplotlib.pyplot as plt\n\ndays = [1, 2, 3, 4, 5]\ntemps = [20, 22, 25, 23, 21]\n\n# Create plot with labels\nplt.plot(days, temps)\nplt.title(\"Daily Temperature\")\nplt.xlabel(\"Day\")\nplt.ylabel(\"Temp (¬∞C)\")\nplt.show()",
    "expected_output": "[Graph: Line plot with labeled axes]",
    "chapter_id": 11,
    "chapter_title": "Data Visualization"
  },
  "83": {
    "id": 83,
    "title": "Multiple Lines",
    "content": "# üìà Plotting Multiple Series\n\n## Comparing Multiple Datasets\n\nPlot multiple lines to compare trends:\n\n```python\nimport matplotlib.pyplot as plt\n\nx = [1, 2, 3, 4]\ny1 = [1, 2, 3, 4]\ny2 = [1, 4, 9, 16]\n\nplt.plot(x, y1, label=\"Linear\")\nplt.plot(x, y2, label=\"Quadratic\")\nplt.legend()  # Show the legend!\nplt.show()\n```\n\n## The Legend\n\nThe `label` parameter names each line, and `plt.legend()` displays them:\n\n```python\nplt.plot(x, y1, label=\"Sales 2023\")\nplt.plot(x, y2, label=\"Sales 2024\")\nplt.legend()\n\n# Position the legend\nplt.legend(loc='upper left')\nplt.legend(loc='best')  # Auto-position\n```\n\n## Different Line Styles\n\n```python\nplt.plot(x, y1, 'b-', label=\"Solid blue\")   # blue, solid\nplt.plot(x, y2, 'r--', label=\"Dashed red\")  # red, dashed\nplt.plot(x, y3, 'g:', label=\"Dotted green\") # green, dotted\n```\n\n---\n\n## üéØ Your Task\n\nPlot two sales lines for months 1-4. Sales A: `[10, 15, 13, 18]`, Sales B: `[8, 12, 16, 14]`. Add a legend.\n",
    "starter_code": "import matplotlib.pyplot as plt\n\nmonths = [1, 2, 3, 4]\nsales_a = [10, 15, 13, 18]\nsales_b = [8, 12, 16, 14]\n\n# Plot both lines with legend\n",
    "solution_code": "import matplotlib.pyplot as plt\n\nmonths = [1, 2, 3, 4]\nsales_a = [10, 15, 13, 18]\nsales_b = [8, 12, 16, 14]\n\n# Plot both lines with legend\nplt.plot(months, sales_a, label=\"Sales A\")\nplt.plot(months, sales_b, label=\"Sales B\")\nplt.legend()\nplt.show()",
    "expected_output": "[Graph: Two line series with legend]",
    "chapter_id": 11,
    "chapter_title": "Data Visualization"
  },
  "84": {
    "id": 84,
    "title": "Colors and Styles",
    "content": "# üé® Styling Your Charts\n\n## Color Options\n\nMatplotlib supports many color formats:\n\n```python\n# Named colors\nplt.plot(x, y, color='red')\nplt.plot(x, y, color='skyblue')\n\n# Hex codes\nplt.plot(x, y, color='#FF5733')\n\n# RGB tuples (0-1 range)\nplt.plot(x, y, color=(0.2, 0.4, 0.6))\n```\n\n## Line Styles\n\n| Style | Code |\n| --- | --- |\n| Solid | `'-'` |\n| Dashed | `'--'` |\n| Dotted | `':'` |\n| Dash-dot | `'-.'` |\n\n## Markers\n\n| Marker | Code |\n| --- | --- |\n| Circle | `'o'` |\n| Square | `'s'` |\n| Triangle | `'^'` |\n| X | `'x'` |\n| Plus | `'+'` |\n\n## Combining Styles\n\n```python\nplt.plot(x, y, color='red', linestyle='--', marker='o', \n         linewidth=2, markersize=8)\n```\n\n---\n\n## üéØ Your Task\n\nCreate a line plot with red color, dashed line style, and circle markers for x `[1, 2, 3, 4]`, y `[1, 4, 2, 3]`.\n",
    "starter_code": "import matplotlib.pyplot as plt\n\nx = [1, 2, 3, 4]\ny = [1, 4, 2, 3]\n\n# Plot with red, dashed, circles\n",
    "solution_code": "import matplotlib.pyplot as plt\n\nx = [1, 2, 3, 4]\ny = [1, 4, 2, 3]\n\n# Plot with red, dashed, circles\nplt.plot(x, y, color=\"red\", linestyle=\"--\", marker=\"o\")\nplt.show()",
    "expected_output": "[Graph: Red dashed line with circle markers]",
    "chapter_id": 11,
    "chapter_title": "Data Visualization"
  },
  "85": {
    "id": 85,
    "title": "Subplots",
    "content": "# üñºÔ∏è Multiple Plots in One Figure\n\n## Why Subplots?\n\nCombine related visualizations for comparison:\n- Before/after comparisons\n- Different metrics side by side\n- Dashboard-style layouts\n\n## Creating Subplots\n\n```python\nimport matplotlib.pyplot as plt\n\n# Create 1 row, 2 columns of plots\nfig, (ax1, ax2) = plt.subplots(1, 2)\n\nax1.plot([1, 2, 3], [1, 4, 9])\nax1.set_title(\"Line Plot\")\n\nax2.bar([\"A\", \"B\", \"C\"], [10, 20, 15])\nax2.set_title(\"Bar Chart\")\n\nplt.tight_layout()  # Prevent overlap\nplt.show()\n```\n\n## Grid Layouts\n\n```python\n# 2 rows, 2 columns\nfig, axes = plt.subplots(2, 2)\n\naxes[0, 0].plot(x, y1)    # Top left\naxes[0, 1].bar(x, y2)     # Top right\naxes[1, 0].scatter(x, y3) # Bottom left\naxes[1, 1].hist(data)     # Bottom right\n```\n\n## Figure Size\n\n```python\nfig, axes = plt.subplots(1, 2, figsize=(12, 4))\n```\n\n---\n\n## üéØ Your Task\n\nCreate 2 side-by-side subplots: left with a line plot of `[1, 2, 3]`, right with a bar chart of categories `[\"A\", \"B\"]` with values `[5, 8]`.\n",
    "starter_code": "import matplotlib.pyplot as plt\n\n# Create 1x2 subplots\n",
    "solution_code": "import matplotlib.pyplot as plt\n\n# Create 1x2 subplots\nfig, (ax1, ax2) = plt.subplots(1, 2)\nax1.plot([1, 2, 3])\nax2.bar([\"A\", \"B\"], [5, 8])\nplt.show()",
    "expected_output": "[Graph: Two subplots side by side]",
    "chapter_id": 11,
    "chapter_title": "Data Visualization"
  },
  "86": {
    "id": 86,
    "title": "Linear Search",
    "content": "# üîç Linear Search\n\n## What is an Algorithm?\n\nAn **algorithm** is a step-by-step procedure for solving a problem. It's like a recipe - specific instructions to achieve a result.\n\n## Linear Search: The Simplest Search\n\nCheck each element one by one until you find what you're looking for:\n\n```python\ndef linear_search(arr, target):\n    for i, val in enumerate(arr):\n        if val == target:\n            return i  # Found! Return index\n    return -1  # Not found\n```\n\n## How It Works (Step by Step)\n\nSearching for `8` in `[5, 2, 8, 1, 9]`:\n\n| Step | Check | Match? | Action |\n| --- | --- | --- | --- |\n| 1 | 5 | No | Continue |\n| 2 | 2 | No | Continue |\n| 3 | 8 | **Yes!** | Return index 2 |\n\n## Time Complexity\n\n- **Best case**: O(1) - target is first element\n- **Worst case**: O(n) - target is last or not found\n- **Average**: O(n/2) ‚Üí O(n)\n\nLinear search is simple but slow for large datasets.\n\n---\n\n## üéØ Your Task\n\nSearch for `8` in `[5, 2, 8, 1, 9]` and print its index.\n",
    "starter_code": "numbers = [5, 2, 8, 1, 9]\ntarget = 8\n\n# Find index of target\n",
    "solution_code": "numbers = [5, 2, 8, 1, 9]\ntarget = 8\n\n# Find index of target\nfor i, val in enumerate(numbers):\n    if val == target:\n        print(i)\n        break",
    "expected_output": "2",
    "chapter_id": 12,
    "chapter_title": "Algorithms"
  },
  "87": {
    "id": 87,
    "title": "Binary Search",
    "content": "# üîç Binary Search\n\n## The Divide and Conquer Approach\n\nFor **sorted arrays**, binary search is much faster:\n\n1. Look at the middle element\n2. If it's the target, done!\n3. If target is smaller, search left half\n4. If target is larger, search right half\n5. Repeat until found or range is empty\n\n## The Algorithm\n\n```python\ndef binary_search(arr, target):\n    left, right = 0, len(arr) - 1\n    \n    while left <= right:\n        mid = (left + right) // 2\n        \n        if arr[mid] == target:\n            return mid\n        elif arr[mid] < target:\n            left = mid + 1  # Search right half\n        else:\n            right = mid - 1  # Search left half\n    \n    return -1  # Not found\n```\n\n## Example: Finding 7\n\nArray: `[1, 3, 5, 7, 9, 11, 13]`\n\n| Step | Left | Right | Mid | arr[mid] | Action |\n| --- | --- | --- | --- | --- | --- |\n| 1 | 0 | 6 | 3 | 7 | Found! |\n\n## Time Complexity: O(log n)\n\nWith each step, we eliminate half the remaining elements!\n- 1000 items ‚Üí ~10 steps\n- 1,000,000 items ‚Üí ~20 steps\n\n---\n\n## üéØ Your Task\n\nUse binary search to find index of `7` in `[1, 3, 5, 7, 9, 11, 13]`.\n",
    "starter_code": "sorted_nums = [1, 3, 5, 7, 9, 11, 13]\ntarget = 7\n\nleft, right = 0, len(sorted_nums) - 1\nresult = -1\n\n# Binary search\n",
    "solution_code": "sorted_nums = [1, 3, 5, 7, 9, 11, 13]\ntarget = 7\n\nleft, right = 0, len(sorted_nums) - 1\nresult = -1\n\n# Binary search\nwhile left <= right:\n    mid = (left + right) // 2\n    if sorted_nums[mid] == target:\n        result = mid\n        break\n    elif sorted_nums[mid] < target:\n        left = mid + 1\n    else:\n        right = mid - 1\n\nprint(result)",
    "expected_output": "3",
    "chapter_id": 12,
    "chapter_title": "Algorithms"
  },
  "88": {
    "id": 88,
    "title": "Bubble Sort",
    "content": "# ü´ß Bubble Sort\n\n## How Bubble Sort Works\n\nCompare adjacent elements and swap if out of order. Larger values \"bubble up\" to the end.\n\n## The Algorithm\n\n```python\ndef bubble_sort(arr):\n    n = len(arr)\n    for i in range(n):\n        for j in range(n - 1):\n            if arr[j] > arr[j + 1]:\n                arr[j], arr[j + 1] = arr[j + 1], arr[j]\n    return arr\n```\n\n## Visualization\n\nSorting `[64, 34, 25]`:\n\n**Pass 1:**\n- Compare 64, 34 ‚Üí swap ‚Üí `[34, 64, 25]`\n- Compare 64, 25 ‚Üí swap ‚Üí `[34, 25, 64]`\n\n**Pass 2:**\n- Compare 34, 25 ‚Üí swap ‚Üí `[25, 34, 64]`\n- Compare 34, 64 ‚Üí no swap\n\n**Result:** `[25, 34, 64]` ‚úì\n\n## Time Complexity\n\n- **Always**: O(n¬≤) - compares every pair\n- **Not efficient** for large datasets\n- But easy to understand and implement!\n\n## Why \"Bubble\"?\n\nEach pass, the largest unsorted element \"bubbles up\" to its correct position.\n\n---\n\n## üéØ Your Task\n\nSort `[64, 34, 25, 12, 22]` using bubble sort and print the result.\n",
    "starter_code": "arr = [64, 34, 25, 12, 22]\n\n# Bubble sort\n\n\n# Print sorted array\n",
    "solution_code": "arr = [64, 34, 25, 12, 22]\n\n# Bubble sort\nfor i in range(len(arr)):\n    for j in range(len(arr) - 1):\n        if arr[j] > arr[j + 1]:\n            arr[j], arr[j + 1] = arr[j + 1], arr[j]\n\n# Print sorted array\nprint(arr)",
    "expected_output": "[12, 22, 25, 34, 64]",
    "chapter_id": 12,
    "chapter_title": "Algorithms"
  },
  "89": {
    "id": 89,
    "title": "Find Maximum",
    "content": "# üîù Finding the Maximum Value\n\n## The Algorithm\n\nTrack the largest value seen so far:\n\n```python\ndef find_max(arr):\n    max_val = arr[0]  # Assume first is largest\n    \n    for val in arr:\n        if val > max_val:\n            max_val = val  # Found a larger one!\n    \n    return max_val\n```\n\n## Step by Step\n\nFinding max in `[3, 7, 2, 9, 4]`:\n\n| Step | Current | max_val | Action |\n| --- | --- | --- | --- |\n| 1 | 3 | 3 | Initialize |\n| 2 | 7 | 7 | Update (7 > 3) |\n| 3 | 2 | 7 | No change |\n| 4 | 9 | 9 | Update (9 > 7) |\n| 5 | 4 | 9 | No change |\n\n**Result:** 9\n\n## Python's Built-in\n\n```python\nmax([3, 7, 2, 9, 4])  # 9\nmin([3, 7, 2, 9, 4])  # 2\n```\n\n## Time Complexity: O(n)\n\nMust check every element at least once.\n\n---\n\n## üéØ Your Task\n\nFind the maximum value in `[3, 7, 2, 9, 4, 1]` and print it.\n",
    "starter_code": "numbers = [3, 7, 2, 9, 4, 1]\n\n# Find maximum\n",
    "solution_code": "numbers = [3, 7, 2, 9, 4, 1]\n\n# Find maximum\nmax_val = numbers[0]\nfor num in numbers:\n    if num > max_val:\n        max_val = num\n\nprint(max_val)",
    "expected_output": "9",
    "chapter_id": 12,
    "chapter_title": "Algorithms"
  },
  "90": {
    "id": 90,
    "title": "Count Occurrences",
    "content": "# üìä Counting Occurrences\n\n## The Problem\n\nHow many times does a value appear in a list?\n\n## The Algorithm\n\n```python\ndef count_occurrences(arr, target):\n    count = 0\n    for val in arr:\n        if val == target:\n            count += 1\n    return count\n```\n\n## Step by Step Example\n\nCounting `5` in `[5, 3, 5, 1, 5, 2]`:\n\n| Element | Match? | Count |\n| --- | --- | --- |\n| 5 | ‚úì | 1 |\n| 3 | ‚úó | 1 |\n| 5 | ‚úì | 2 |\n| 1 | ‚úó | 2 |\n| 5 | ‚úì | 3 |\n| 2 | ‚úó | 3 |\n\n**Result:** 3\n\n## Python's Built-in\n\n```python\n[5, 3, 5, 1, 5, 2].count(5)  # 3\n```\n\n## Use Cases\n\n- Count word frequency in text\n- Count votes for candidates\n- Find most common element\n\n---\n\n## üéØ Your Task\n\nCount how many times `5` appears in `[5, 3, 5, 1, 5, 2]` and print the count.\n",
    "starter_code": "numbers = [5, 3, 5, 1, 5, 2]\ntarget = 5\n\n# Count occurrences\n",
    "solution_code": "numbers = [5, 3, 5, 1, 5, 2]\ntarget = 5\n\n# Count occurrences\ncount = 0\nfor num in numbers:\n    if num == target:\n        count += 1\n\nprint(count)",
    "expected_output": "3",
    "chapter_id": 12,
    "chapter_title": "Algorithms"
  },
  "91": {
    "id": 91,
    "title": "Reverse Array",
    "content": "# üîÑ Reversing an Array\n\n## Multiple Approaches\n\n### 1. Slicing (Pythonic)\n```python\nreversed_arr = arr[::-1]\n```\n\n### 2. Built-in reverse (in-place)\n```python\narr.reverse()  # Modifies original\n```\n\n### 3. Built-in reversed (new iterator)\n```python\nlist(reversed(arr))\n```\n\n### 4. Manual (two pointers)\n```python\ndef reverse(arr):\n    left, right = 0, len(arr) - 1\n    while left < right:\n        arr[left], arr[right] = arr[right], arr[left]\n        left += 1\n        right -= 1\n```\n\n## Understanding Slicing\n\n`arr[start:stop:step]`\n- `[::-1]` means: start at end, go to beginning, step -1\n\n## Time Complexity\n\nAll methods: O(n) - must touch every element\n\n---\n\n## üéØ Your Task\n\nReverse `[1, 2, 3, 4, 5]` and print the result.\n",
    "starter_code": "arr = [1, 2, 3, 4, 5]\n\n# Reverse and print\n",
    "solution_code": "arr = [1, 2, 3, 4, 5]\n\n# Reverse and print\nprint(arr[::-1])",
    "expected_output": "[5, 4, 3, 2, 1]",
    "chapter_id": 12,
    "chapter_title": "Algorithms"
  },
  "92": {
    "id": 92,
    "title": "Remove Duplicates",
    "content": "# üßπ Removing Duplicates\n\n## Using Set\n\nThe easiest way - sets automatically remove duplicates:\n\n```python\narr = [1, 2, 2, 3, 3, 3, 4]\nunique = list(set(arr))  # [1, 2, 3, 4]\n```\n\n‚ö†Ô∏è **Warning**: Sets don't preserve order!\n\n## Preserving Order\n\n```python\ndef remove_duplicates_ordered(arr):\n    seen = set()\n    result = []\n    for item in arr:\n        if item not in seen:\n            seen.add(item)\n            result.append(item)\n    return result\n```\n\n## Using dict.fromkeys() (Python 3.7+)\n\n```python\nlist(dict.fromkeys([1, 2, 2, 3, 3]))  # [1, 2, 3]\n```\n\n## Use Cases\n\n- Clean user input\n- Prepare data for analysis\n- Remove redundant items\n\n---\n\n## üéØ Your Task\n\nRemove duplicates from `[1, 2, 2, 3, 3, 3, 4]` and print the sorted unique values.\n",
    "starter_code": "arr = [1, 2, 2, 3, 3, 3, 4]\n\n# Remove duplicates and sort\n",
    "solution_code": "arr = [1, 2, 2, 3, 3, 3, 4]\n\n# Remove duplicates and sort\nunique = sorted(set(arr))\nprint(unique)",
    "expected_output": "[1, 2, 3, 4]",
    "chapter_id": 12,
    "chapter_title": "Algorithms"
  },
  "93": {
    "id": 93,
    "title": "Two Sum",
    "content": "# üéØ The Two Sum Problem\n\n## The Problem\n\nFind two numbers in an array that add up to a target sum.\n\n## Brute Force Approach\n\nCheck every pair:\n\n```python\ndef two_sum_brute(nums, target):\n    for i in range(len(nums)):\n        for j in range(i + 1, len(nums)):\n            if nums[i] + nums[j] == target:\n                return [nums[i], nums[j]]\n    return None\n```\n\n**Time Complexity**: O(n¬≤)\n\n## Optimized Approach (Hash Map)\n\n```python\ndef two_sum_fast(nums, target):\n    seen = {}\n    for num in nums:\n        complement = target - num\n        if complement in seen:\n            return [complement, num]\n        seen[num] = True\n    return None\n```\n\n**Time Complexity**: O(n)\n\n## Why This is Famous\n\nThis is **THE** most common coding interview question! It teaches:\n- Hash tables\n- Trade-offs between time and space\n- Problem-solving strategies\n\n---\n\n## üéØ Your Task\n\nFind two numbers in `[2, 7, 11, 15]` that add up to 9 and print them.\n",
    "starter_code": "nums = [2, 7, 11, 15]\ntarget = 9\n\n# Find two numbers that sum to target\n",
    "solution_code": "nums = [2, 7, 11, 15]\ntarget = 9\n\n# Find two numbers that sum to target\nfor i in range(len(nums)):\n    for j in range(i + 1, len(nums)):\n        if nums[i] + nums[j] == target:\n            print(nums[i], nums[j])",
    "expected_output": "2 7",
    "chapter_id": 12,
    "chapter_title": "Algorithms"
  },
  "94": {
    "id": 94,
    "title": "Fibonacci",
    "content": "# üåÄ Fibonacci Sequence\n\n## The Pattern\n\nEach number is the sum of the two before it:\n\n```\n0, 1, 1, 2, 3, 5, 8, 13, 21, 34, ...\n```\n\n- F(0) = 0\n- F(1) = 1\n- F(n) = F(n-1) + F(n-2)\n\n## Iterative Approach\n\n```python\ndef fibonacci(n):\n    fib = [0, 1]\n    for i in range(2, n):\n        fib.append(fib[-1] + fib[-2])\n    return fib[:n]\n```\n\n## Recursive Approach\n\n```python\ndef fib_recursive(n):\n    if n <= 1:\n        return n\n    return fib_recursive(n-1) + fib_recursive(n-2)\n```\n\n‚ö†Ô∏è Recursive is elegant but slow (O(2^n)) without memoization!\n\n## Where Fibonacci Appears\n\n- Nature: flower petals, pinecones, shells\n- Art: golden ratio\n- Computer science: algorithm analysis\n- Finance: Fibonacci retracements\n\n---\n\n## üéØ Your Task\n\nGenerate the first 8 Fibonacci numbers and print them.\n",
    "starter_code": "# Generate first 8 Fibonacci numbers\n",
    "solution_code": "# Generate first 8 Fibonacci numbers\nfib = [0, 1]\nfor i in range(6):\n    fib.append(fib[-1] + fib[-2])\n\nprint(fib)",
    "expected_output": "[0, 1, 1, 2, 3, 5, 8, 13]",
    "chapter_id": 12,
    "chapter_title": "Algorithms"
  },
  "95": {
    "id": 95,
    "title": "Mean (Average)",
    "content": "# üìä Mean (Average): The Center of Your Data\n\n## What is the Mean?\n\nThe **mean** (or average) is the most common way to find the \"center\" of a dataset. It tells you what value you'd expect if all the data were spread evenly.\n\n## Real-World Analogy\n\nImagine you and 4 friends pool your money: $10, $20, $30, $15, $25. The mean ($20) is what each person would have if you divided the total equally.\n\n## How to Calculate\n\n```python\n# Mean = Sum of all values / Number of values\ndata = [10, 20, 30, 15, 25]\nmean = sum(data) / len(data)  # 100 / 5 = 20\n```\n\n## Using NumPy\n\n```python\nimport numpy as np\ndata = np.array([10, 20, 30, 15, 25])\nmean = np.mean(data)  # 20.0\n```\n\n## When to Use the Mean\n\n‚úÖ Data is roughly symmetric (no extreme outliers)\n‚úÖ You want a single representative value\n‚ùå Avoid when you have extreme outliers (use median instead)\n\n## Data Science Application\n\nCalculating average revenue, average test scores, or average customer ratings.\n\n---\n\n## üéØ Your Task\n\nCalculate the mean of the following sales data and print it with 2 decimal places.",
    "starter_code": "import numpy as np\n\n# Weekly sales data\nsales = np.array([1250.50, 1340.75, 980.25, 1560.00, 1420.30, 1180.90, 1650.25])\n\n# Calculate the mean\nmean_sales = None  # Your code here\n\nprint(f\"Average weekly sales: ${mean_sales:.2f}\")",
    "solution_code": "import numpy as np\n\n# Weekly sales data\nsales = np.array([1250.50, 1340.75, 980.25, 1560.00, 1420.30, 1180.90, 1650.25])\n\n# Calculate the mean\nmean_sales = np.mean(sales)\n\nprint(f\"Average weekly sales: ${mean_sales:.2f}\")",
    "expected_output": "Average weekly sales: $1340.42",
    "chapter_id": 13,
    "chapter_title": "Statistics"
  },
  "96": {
    "id": 96,
    "title": "Median",
    "content": "# üìè Median: The Middle Value\n\n## What is the Median?\n\nThe **median** is the middle value when data is sorted. Unlike the mean, it's not affected by extreme values (outliers).\n\n## Real-World Analogy\n\nImagine lining up 5 people by height. The person in the middle represents the median height‚Äîit doesn't matter if the tallest person is a basketball player or an average adult.\n\n## How to Calculate\n\n1. Sort the data\n2. If odd number of values: pick the middle one\n3. If even number: average the two middle values\n\n```python\n# Odd number of values\ndata = [3, 1, 9, 5, 7]\n# Sorted: [1, 3, 5, 7, 9]\n# Median = 5 (middle value)\n\n# Even number of values\ndata = [3, 1, 9, 5]\n# Sorted: [1, 3, 5, 9]\n# Median = (3 + 5) / 2 = 4\n```\n\n## Using NumPy\n\n```python\nimport numpy as np\ndata = np.array([3, 1, 9, 5, 7])\nmedian = np.median(data)  # 5.0\n```\n\n## Mean vs Median\n\n| Scenario | Use Mean | Use Median |\n|----------|----------|------------|\n| Symmetric data | ‚úÖ | ‚úÖ |\n| Outliers present | ‚ùå | ‚úÖ |\n| Income data | ‚ùå | ‚úÖ |\n\n---\n\n## üéØ Your Task\n\nCalculate the median home price from this dataset.",
    "starter_code": "import numpy as np\n\n# Home prices (in thousands)\nprices = np.array([250, 275, 300, 285, 950, 290, 265, 280])\n\n# Calculate median (note the outlier at 950!)\nmedian_price = None  # Your code here\n\nprint(f\"Median home price: ${median_price}K\")",
    "solution_code": "import numpy as np\n\n# Home prices (in thousands)\nprices = np.array([250, 275, 300, 285, 950, 290, 265, 280])\n\n# Calculate median (note the outlier at 950!)\nmedian_price = np.median(prices)\n\nprint(f\"Median home price: ${median_price}K\")",
    "expected_output": "Median home price: $282.5K",
    "chapter_id": 13,
    "chapter_title": "Statistics"
  },
  "97": {
    "id": 97,
    "title": "Mode",
    "content": "# üéØ Mode: The Most Frequent Value\n\n## What is the Mode?\n\nThe **mode** is the value that appears most often in a dataset. A dataset can have:\n- **No mode**: all values appear once\n- **One mode**: one value appears most often\n- **Multiple modes**: several values tie for most frequent\n\n## Real-World Analogy\n\nIn a shoe store, the mode shoe size tells you which size to stock the most of!\n\n## How to Calculate\n\n```python\nfrom collections import Counter\ndata = [1, 2, 2, 3, 3, 3, 4]\n# 3 appears 3 times - it's the mode!\n\ncounter = Counter(data)\nmode = counter.most_common(1)[0][0]  # Returns 3\n```\n\n## Using SciPy\n\n```python\nfrom scipy import stats\ndata = [1, 2, 2, 3, 3, 3, 4]\nmode_result = stats.mode(data, keepdims=True)\nprint(mode_result.mode[0])  # 3\n```\n\n## When to Use Mode\n\n‚úÖ Categorical data (colors, sizes, categories)\n‚úÖ Finding most popular item\n‚úÖ Discrete data with repeated values\n‚ùå Continuous data (use mean/median instead)\n\n---\n\n## üéØ Your Task\n\nFind the most popular product size from sales data.",
    "starter_code": "from collections import Counter\n\n# Product sizes sold today\nsizes = ['M', 'L', 'S', 'M', 'XL', 'M', 'L', 'S', 'M', 'L', 'M', 'S']\n\n# Find the mode (most common size)\ncounter = Counter(sizes)\nmost_common = None  # Get the most common size\n\nprint(f\"Most popular size: {most_common}\")",
    "solution_code": "from collections import Counter\n\n# Product sizes sold today\nsizes = ['M', 'L', 'S', 'M', 'XL', 'M', 'L', 'S', 'M', 'L', 'M', 'S']\n\n# Find the mode (most common size)\ncounter = Counter(sizes)\nmost_common = counter.most_common(1)[0][0]\n\nprint(f\"Most popular size: {most_common}\")",
    "expected_output": "Most popular size: M",
    "chapter_id": 13,
    "chapter_title": "Statistics"
  },
  "98": {
    "id": 98,
    "title": "Range",
    "content": "# üìè Range: Spread of Your Data\n\n## What is the Range?\n\nThe **range** is the simplest measure of spread‚Äîit's just the difference between the largest and smallest values.\n\n```\nRange = Maximum - Minimum\n```\n\n## Real-World Analogy\n\nIf temperatures this week ranged from 60¬∞F to 85¬∞F, the range is 25¬∞F. This tells you how much the temperature varied.\n\n## How to Calculate\n\n```python\ndata = [10, 25, 15, 30, 20]\nrange_value = max(data) - min(data)  # 30 - 10 = 20\n```\n\n## Using NumPy\n\n```python\nimport numpy as np\ndata = np.array([10, 25, 15, 30, 20])\nrange_value = np.ptp(data)  # Peak-to-peak = 20\n# Or: np.max(data) - np.min(data)\n```\n\n## Limitations\n\n‚ö†Ô∏è Range is sensitive to outliers!\n- Data: [10, 15, 20, 25, 30] ‚Üí Range = 20\n- Data: [10, 15, 20, 25, 100] ‚Üí Range = 90 (misleading!)\n\n## Better Alternatives\n\nFor more robust spread measures, consider:\n- **Interquartile Range (IQR)**\n- **Standard Deviation**\n\n---\n\n## üéØ Your Task\n\nCalculate the range of daily temperatures.",
    "starter_code": "import numpy as np\n\n# Daily high temperatures (Fahrenheit)\ntemps = np.array([72, 75, 68, 82, 79, 85, 71, 88, 69, 74])\n\n# Calculate range\ntemp_range = None  # Your code here\n\nprint(f\"Temperature range: {temp_range}¬∞F\")",
    "solution_code": "import numpy as np\n\n# Daily high temperatures (Fahrenheit)\ntemps = np.array([72, 75, 68, 82, 79, 85, 71, 88, 69, 74])\n\n# Calculate range\ntemp_range = np.ptp(temps)  # or np.max(temps) - np.min(temps)\n\nprint(f\"Temperature range: {temp_range}¬∞F\")",
    "expected_output": "Temperature range: 20¬∞F",
    "chapter_id": 13,
    "chapter_title": "Statistics"
  },
  "99": {
    "id": 99,
    "title": "Variance",
    "content": "# üìä Variance: Measuring Data Spread\n\n## What is Variance?\n\n**Variance** measures how spread out data points are from the mean. Higher variance = more spread.\n\n## The Formula\n\n1. Find the mean\n2. Subtract mean from each value (get deviations)\n3. Square each deviation\n4. Take the average of squared deviations\n\n```\nVariance = Œ£(x - mean)¬≤ / n\n```\n\n## Real-World Analogy\n\nTwo basketball players both average 20 points per game. Player A scores 19, 20, 21, 20, 20 (low variance‚Äîconsistent). Player B scores 5, 35, 10, 30, 20 (high variance‚Äîunpredictable).\n\n## Using NumPy\n\n```python\nimport numpy as np\ndata = np.array([10, 12, 23, 23, 16, 23, 21, 16])\n\n# Population variance (default)\nvar_pop = np.var(data)  \n\n# Sample variance (use ddof=1)\nvar_sample = np.var(data, ddof=1)\n```\n\n## Population vs Sample Variance\n\n- **Population**: Use when you have ALL the data\n- **Sample**: Use when you have a subset (use `ddof=1`)\n\n---\n\n## üéØ Your Task\n\nCalculate the variance of test scores to understand consistency.",
    "starter_code": "import numpy as np\n\n# Test scores for two classes\nclass_a = np.array([85, 87, 84, 86, 85, 88, 84, 86])\nclass_b = np.array([70, 95, 60, 100, 75, 90, 65, 85])\n\n# Calculate variance for each class\nvar_a = None  # Your code\nvar_b = None  # Your code\n\nprint(f\"Class A variance: {var_a:.2f}\")\nprint(f\"Class B variance: {var_b:.2f}\")\nprint(f\"More consistent class: {'A' if var_a < var_b else 'B'}\")",
    "solution_code": "import numpy as np\n\n# Test scores for two classes\nclass_a = np.array([85, 87, 84, 86, 85, 88, 84, 86])\nclass_b = np.array([70, 95, 60, 100, 75, 90, 65, 85])\n\n# Calculate variance for each class\nvar_a = np.var(class_a)\nvar_b = np.var(class_b)\n\nprint(f\"Class A variance: {var_a:.2f}\")\nprint(f\"Class B variance: {var_b:.2f}\")\nprint(f\"More consistent class: {'A' if var_a < var_b else 'B'}\")",
    "expected_output": "Class A variance: 1.75\nClass B variance: 200.00\nMore consistent class: A",
    "chapter_id": 13,
    "chapter_title": "Statistics"
  },
  "100": {
    "id": 100,
    "title": "Standard Deviation",
    "content": "# ÔøΩÔøΩ Standard Deviation: Making Variance Useful\n\n## What is Standard Deviation?\n\n**Standard deviation (œÉ or std)** is the square root of variance. It measures spread in the same units as your data, making it more interpretable.\n\n## Why Not Just Use Variance?\n\nVariance is in \"squared units\" which is hard to interpret:\n- Data: test scores (0-100)\n- Variance: 225 \"squared points\" ü§î\n- Std Dev: 15 points ‚úÖ (much clearer!)\n\n## The Formula\n\n```\nStandard Deviation = ‚àöVariance\n```\n\n## Using NumPy\n\n```python\nimport numpy as np\ndata = np.array([10, 12, 23, 23, 16, 23, 21, 16])\n\nstd_dev = np.std(data)  # Population std dev\nstd_sample = np.std(data, ddof=1)  # Sample std dev\n```\n\n## The 68-95-99.7 Rule\n\nFor normal distributions:\n- **68%** of data falls within 1 std dev of mean\n- **95%** of data falls within 2 std devs\n- **99.7%** of data falls within 3 std devs\n\n## Data Science Use Cases\n\n- **Quality Control**: Products outside 2 std devs may be defective\n- **Finance**: Stock volatility measured by std dev\n- **Grading**: Standardizing test scores\n\n---\n\n## üéØ Your Task\n\nCalculate the standard deviation of stock returns to measure volatility.",
    "starter_code": "import numpy as np\n\n# Daily stock returns (%)\nreturns = np.array([1.2, -0.8, 2.1, -1.5, 0.5, 1.8, -0.3, 0.9, -1.2, 1.5])\n\n# Calculate standard deviation (volatility)\nvolatility = None  # Your code here\n\nprint(f\"Stock volatility: {volatility:.2f}%\")",
    "solution_code": "import numpy as np\n\n# Daily stock returns (%)\nreturns = np.array([1.2, -0.8, 2.1, -1.5, 0.5, 1.8, -0.3, 0.9, -1.2, 1.5])\n\n# Calculate standard deviation (volatility)\nvolatility = np.std(returns)\n\nprint(f\"Stock volatility: {volatility:.2f}%\")",
    "expected_output": "Stock volatility: 1.16%",
    "chapter_id": 13,
    "chapter_title": "Statistics"
  },
  "101": {
    "id": 101,
    "title": "Percentiles",
    "content": "# üìä Percentiles: Where Does Your Data Fall?\n\n## What are Percentiles?\n\nA **percentile** tells you what percentage of data falls below a certain value.\n\n- **25th percentile (Q1)**: 25% of data is below this\n- **50th percentile (Q2)**: The median\n- **75th percentile (Q3)**: 75% of data is below this\n\n## Real-World Analogy\n\nIf your test score is in the 90th percentile, you scored higher than 90% of test-takers!\n\n## Using NumPy\n\n```python\nimport numpy as np\ndata = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n\nq1 = np.percentile(data, 25)   # 3.25\nq2 = np.percentile(data, 50)   # 5.5 (median)\nq3 = np.percentile(data, 75)   # 7.75\n```\n\n## Interquartile Range (IQR)\n\n```\nIQR = Q3 - Q1\n```\n\nIQR is useful for detecting outliers:\n- Values below Q1 - 1.5*IQR are outliers\n- Values above Q3 + 1.5*IQR are outliers\n\n## Data Science Applications\n\n- **Salary analysis**: \"You're in the 75th percentile for your role\"\n- **Performance metrics**: \"Response time at 95th percentile\"\n- **Grading curves**: Assigning grades based on percentiles\n\n---\n\n## üéØ Your Task\n\nCalculate Q1, Q2 (median), Q3, and IQR for salary data.",
    "starter_code": "import numpy as np\n\n# Employee salaries (in thousands)\nsalaries = np.array([45, 52, 58, 62, 65, 68, 72, 78, 85, 95, 120])\n\n# Calculate percentiles\nq1 = None  # 25th percentile\nq2 = None  # 50th percentile (median)  \nq3 = None  # 75th percentile\niqr = None  # Interquartile range\n\nprint(f\"Q1: ${q1}K\")\nprint(f\"Median: ${q2}K\")\nprint(f\"Q3: ${q3}K\")\nprint(f\"IQR: ${iqr}K\")",
    "solution_code": "import numpy as np\n\n# Employee salaries (in thousands)\nsalaries = np.array([45, 52, 58, 62, 65, 68, 72, 78, 85, 95, 120])\n\n# Calculate percentiles\nq1 = np.percentile(salaries, 25)\nq2 = np.percentile(salaries, 50)\nq3 = np.percentile(salaries, 75)\niqr = q3 - q1\n\nprint(f\"Q1: ${q1}K\")\nprint(f\"Median: ${q2}K\")\nprint(f\"Q3: ${q3}K\")\nprint(f\"IQR: ${iqr}K\")",
    "expected_output": "Q1: $58.0K\nMedian: $68.0K\nQ3: $85.0K\nIQR: $27.0K",
    "chapter_id": 13,
    "chapter_title": "Statistics"
  },
  "102": {
    "id": 102,
    "title": "Correlation",
    "content": "# üîó Correlation: Relationships Between Variables\n\n## What is Correlation?\n\n**Correlation** measures the strength and direction of the relationship between two variables. It ranges from -1 to +1.\n\n| Value | Meaning |\n|-------|---------|\n| +1 | Perfect positive correlation |\n| 0 | No correlation |\n| -1 | Perfect negative correlation |\n\n## Real-World Examples\n\n- **Positive**: Height and weight (taller people tend to weigh more)\n- **Negative**: Speed and fuel efficiency (faster = less efficient)\n- **None**: Shoe size and IQ (unrelated)\n\n## Using NumPy\n\n```python\nimport numpy as np\n\nx = np.array([1, 2, 3, 4, 5])\ny = np.array([2, 4, 5, 4, 5])\n\n# Correlation matrix\ncorr_matrix = np.corrcoef(x, y)\ncorrelation = corr_matrix[0, 1]  # 0.83\n```\n\n## Interpreting Correlation Strength\n\n| Absolute Value | Strength |\n|----------------|----------|\n| 0.0 - 0.3 | Weak |\n| 0.3 - 0.7 | Moderate |\n| 0.7 - 1.0 | Strong |\n\n## ‚ö†Ô∏è Important Warning\n\n**Correlation ‚â† Causation!**\n\nIce cream sales and drowning deaths are correlated (both increase in summer), but ice cream doesn't cause drowning!\n\n---\n\n## üéØ Your Task\n\nCalculate the correlation between study hours and exam scores.",
    "starter_code": "import numpy as np\n\n# Study data\nhours_studied = np.array([1, 2, 3, 4, 5, 6, 7, 8])\nexam_scores = np.array([52, 58, 65, 70, 78, 82, 88, 95])\n\n# Calculate correlation\ncorrelation = None  # Your code here\n\nprint(f\"Correlation: {correlation:.3f}\")\nprint(f\"Relationship: {'Strong' if abs(correlation) > 0.7 else 'Moderate' if abs(correlation) > 0.3 else 'Weak'}\")",
    "solution_code": "import numpy as np\n\n# Study data\nhours_studied = np.array([1, 2, 3, 4, 5, 6, 7, 8])\nexam_scores = np.array([52, 58, 65, 70, 78, 82, 88, 95])\n\n# Calculate correlation\ncorrelation = np.corrcoef(hours_studied, exam_scores)[0, 1]\n\nprint(f\"Correlation: {correlation:.3f}\")\nprint(f\"Relationship: {'Strong' if abs(correlation) > 0.7 else 'Moderate' if abs(correlation) > 0.3 else 'Weak'}\")",
    "expected_output": "Correlation: 0.994\nRelationship: Strong",
    "chapter_id": 13,
    "chapter_title": "Statistics"
  },
  "103": {
    "id": 103,
    "title": "Z-Score",
    "content": "# üìè Z-Score: Standardizing Your Data\n\n## What is a Z-Score?\n\nA **Z-score** tells you how many standard deviations a value is from the mean. It standardizes data to a common scale.\n\n## The Formula\n\n```\nZ = (X - mean) / std_dev\n```\n\n## Interpreting Z-Scores\n\n| Z-Score | Meaning |\n|---------|---------|\n| 0 | At the mean |\n| +1 | 1 std dev above mean |\n| -1 | 1 std dev below mean |\n| +2 | 2 std devs above (unusual) |\n| ¬±3+ | Very unusual (outlier) |\n\n## Real-World Example\n\nTwo students take different tests:\n- Alice: 80/100 (class mean: 70, std: 10) ‚Üí Z = 1.0\n- Bob: 85/100 (class mean: 75, std: 5) ‚Üí Z = 2.0\n\nBob's score is more impressive relative to his class!\n\n## Using Python\n\n```python\nimport numpy as np\n\ndata = np.array([10, 20, 30, 40, 50])\nmean = np.mean(data)\nstd = np.std(data)\n\nz_scores = (data - mean) / std\n```\n\n## Data Science Applications\n\n- **Comparing**: Scores from different scales\n- **Outlier detection**: |Z| > 3 is often considered an outlier\n- **Feature scaling**: Standardization for ML models\n\n---\n\n## üéØ Your Task\n\nCalculate Z-scores for student test scores and identify any outliers (|Z| > 2).",
    "starter_code": "import numpy as np\n\n# Test scores\nscores = np.array([72, 85, 90, 78, 95, 45, 88, 82, 79, 84])\n\n# Calculate Z-scores\nmean = np.mean(scores)\nstd = np.std(scores)\nz_scores = None  # Calculate (scores - mean) / std\n\n# Find outliers\nprint(f\"Mean: {mean:.1f}, Std: {std:.1f}\")\nprint(\"\\nZ-scores and outlier status:\")\nfor score, z in zip(scores, z_scores):\n    status = \"‚ö†Ô∏è OUTLIER\" if abs(z) > 2 else \"\"\n    print(f\"  Score {score}: Z = {z:.2f} {status}\")",
    "solution_code": "import numpy as np\n\n# Test scores\nscores = np.array([72, 85, 90, 78, 95, 45, 88, 82, 79, 84])\n\n# Calculate Z-scores\nmean = np.mean(scores)\nstd = np.std(scores)\nz_scores = (scores - mean) / std\n\n# Find outliers\nprint(f\"Mean: {mean:.1f}, Std: {std:.1f}\")\nprint(\"\\nZ-scores and outlier status:\")\nfor score, z in zip(scores, z_scores):\n    status = \"‚ö†Ô∏è OUTLIER\" if abs(z) > 2 else \"\"\n    print(f\"  Score {score}: Z = {z:.2f} {status}\")",
    "expected_output": "Mean: 79.8, Std: 13.1\n\nZ-scores and outlier status:",
    "chapter_id": 13,
    "chapter_title": "Statistics"
  },
  "104": {
    "id": 104,
    "title": "Train/Test Split",
    "content": "# üîÄ Train/Test Split: Evaluating ML Models Properly\n\n## Why Split Data?\n\nIf you train AND test on the same data, your model might just \"memorize\" the answers! This is called **overfitting**.\n\n## The Solution: Train/Test Split\n\nSplit your data into two sets:\n- **Training set (80%)**: Model learns patterns\n- **Test set (20%)**: Model is evaluated on unseen data\n\n## Real-World Analogy\n\nImagine studying for an exam:\n- **Training**: You study the practice problems\n- **Testing**: The actual exam has NEW questions\n\nIf the exam had the exact same questions as practice, everyone would get 100%!\n\n## Using scikit-learn\n\n```python\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, \n    test_size=0.2,    # 20% for testing\n    random_state=42   # For reproducibility\n)\n```\n\n## Key Parameters\n\n- **test_size**: Fraction for testing (0.2 = 20%)\n- **random_state**: Seed for reproducibility\n- **stratify**: Maintain class proportions (for classification)\n\n---\n\n## üéØ Your Task\n\nSplit the dataset into training (80%) and testing (20%) sets.",
    "starter_code": "from sklearn.model_selection import train_test_split\nimport numpy as np\n\n# Sample data: features and target\nnp.random.seed(42)\nX = np.random.rand(100, 3)  # 100 samples, 3 features\ny = np.random.randint(0, 2, 100)  # Binary target\n\n# Split into train and test sets\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y,\n    test_size=None,  # Set to 20%\n    random_state=42\n)\n\nprint(f\"Training samples: {len(X_train)}\")\nprint(f\"Testing samples: {len(X_test)}\")",
    "solution_code": "from sklearn.model_selection import train_test_split\nimport numpy as np\n\n# Sample data: features and target\nnp.random.seed(42)\nX = np.random.rand(100, 3)  # 100 samples, 3 features\ny = np.random.randint(0, 2, 100)  # Binary target\n\n# Split into train and test sets\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y,\n    test_size=0.2,  # 20% for testing\n    random_state=42\n)\n\nprint(f\"Training samples: {len(X_train)}\")\nprint(f\"Testing samples: {len(X_test)}\")",
    "expected_output": "Training samples: 80\nTesting samples: 20",
    "chapter_id": 14,
    "chapter_title": "Machine Learning Intro"
  },
  "105": {
    "id": 105,
    "title": "Linear Regression",
    "content": "# üìà Linear Regression: Predicting Continuous Values\n\n## What is Linear Regression?\n\n**Linear regression** finds the best straight line through your data to predict a continuous target variable.\n\n## The Equation\n\n```\ny = mx + b\n```\n- **y**: Predicted value\n- **m**: Slope (how much y changes when x increases by 1)\n- **x**: Input feature\n- **b**: Intercept (y value when x = 0)\n\n## Real-World Example\n\nPredicting house prices based on square footage:\n- Input (x): House size in sq ft\n- Output (y): Predicted price\n\n## Using scikit-learn\n\n```python\nfrom sklearn.linear_model import LinearRegression\n\nmodel = LinearRegression()\nmodel.fit(X_train, y_train)\n\npredictions = model.predict(X_test)\n```\n\n## Evaluating the Model\n\n**R¬≤ Score** (coefficient of determination):\n- 1.0 = Perfect predictions\n- 0.0 = Model is no better than predicting the mean\n- Negative = Worse than the mean!\n\n---\n\n## üéØ Your Task\n\nTrain a linear regression model to predict sales based on advertising spend.",
    "starter_code": "from sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\n\n# Advertising spend (X) and Sales (y)\nnp.random.seed(42)\nX = np.random.rand(50, 1) * 100  # Ad spend $0-100\ny = 2.5 * X.flatten() + 10 + np.random.randn(50) * 5  # Sales with noise\n\n# Split data\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Train model\nmodel = LinearRegression()\nmodel.fit(X_train, y_train)\n\n# Evaluate\nscore = model.score(X_test, y_test)\nprint(f\"R¬≤ Score: {score:.3f}\")\nprint(f\"For every $1 spent on ads, sales increase by ${model.coef_[0]:.2f}\")",
    "solution_code": "from sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\n\n# Advertising spend (X) and Sales (y)\nnp.random.seed(42)\nX = np.random.rand(50, 1) * 100  # Ad spend $0-100\ny = 2.5 * X.flatten() + 10 + np.random.randn(50) * 5  # Sales with noise\n\n# Split data\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Train model\nmodel = LinearRegression()\nmodel.fit(X_train, y_train)\n\n# Evaluate\nscore = model.score(X_test, y_test)\nprint(f\"R¬≤ Score: {score:.3f}\")\nprint(f\"For every $1 spent on ads, sales increase by ${model.coef_[0]:.2f}\")",
    "expected_output": "R¬≤ Score: 0.997\nFor every $1 spent on ads, sales increase by $2.50",
    "chapter_id": 14,
    "chapter_title": "Machine Learning Intro"
  },
  "106": {
    "id": 106,
    "title": "Model Accuracy",
    "content": "# üìä Measuring Model Performance\n\n## Classification Accuracy\n\nFor classification problems, accuracy is the percentage of correct predictions:\n\n$$\\text{accuracy} = \\frac{\\text{correct predictions}}{\\text{total predictions}}$$\n\n```python\nfrom sklearn.metrics import accuracy_score\n\ny_true = [1, 0, 1, 1, 0]\ny_pred = [1, 0, 0, 1, 0]\n\naccuracy = accuracy_score(y_true, y_pred)\nprint(accuracy)  # 0.8 (80% correct)\n```\n\n## Interpreting Accuracy\n\n- **100%**: Perfect (suspicious - might be overfitting!)\n- **90%+**: Generally very good\n- **50%**: No better than random guessing (for binary classification)\n\n## Other Metrics\n\n| Metric | Best For |\n| --- | --- |\n| Accuracy | Balanced classes |\n| Precision | When false positives are costly |\n| Recall | When false negatives are costly |\n| F1-Score | Balance of precision and recall |\n\n## Why Accuracy Isn't Everything\n\nIf 99% of emails are not spam, a model that predicts \"not spam\" for everything gets 99% accuracy but is useless!\n\nAlways consider the **context** of your problem.\n\n---\n\n## üéØ Your Task\n\nCalculate accuracy for true `[1, 0, 1, 1, 0]` vs predicted `[1, 0, 0, 1, 0]` and print it.\n",
    "starter_code": "from sklearn.metrics import accuracy_score\n\ny_true = [1, 0, 1, 1, 0]\ny_pred = [1, 0, 0, 1, 0]\n\n# Calculate accuracy\n",
    "solution_code": "from sklearn.metrics import accuracy_score\n\ny_true = [1, 0, 1, 1, 0]\ny_pred = [1, 0, 0, 1, 0]\n\n# Calculate accuracy\nacc = accuracy_score(y_true, y_pred)\nprint(acc)",
    "expected_output": "0.8",
    "chapter_id": 14,
    "chapter_title": "Machine Learning Intro"
  },
  "107": {
    "id": 107,
    "title": "K-Nearest Neighbors",
    "content": "# üéØ K-Nearest Neighbors (KNN): Classification by Similarity\n\n## What is KNN?\n\n**K-Nearest Neighbors** classifies data points based on their closest neighbors. It's like asking: \"What are most of my neighbors?\"\n\n## Real-World Analogy\n\nMoving to a new neighborhood? KNN is like predicting your political views based on your 5 closest neighbors' views‚Äîyou'll probably vote like your neighbors!\n\n## How It Works\n\n1. Pick K (number of neighbors to consider)\n2. Find the K closest data points\n3. Take a vote‚Äîmajority class wins!\n\n## The Algorithm\n\n```python\nfrom sklearn.neighbors import KNeighborsClassifier\n\nknn = KNeighborsClassifier(n_neighbors=5)\nknn.fit(X_train, y_train)\npredictions = knn.predict(X_test)\n```\n\n## Choosing K\n\n- **Small K (1-3)**: Sensitive to noise, may overfit\n- **Large K (10+)**: Smoother boundaries, may underfit\n- **Rule of thumb**: Start with ‚àön (square root of samples)\n\n## Distance Metrics\n\n- **Euclidean**: Straight-line distance (most common)\n- **Manhattan**: City-block distance\n- **Minkowski**: Generalized distance\n\n---\n\n## ÔøΩÔøΩ Your Task\n\nBuild a KNN classifier to predict flower species from the Iris dataset.",
    "starter_code": "from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.datasets import load_iris\nfrom sklearn.model_selection import train_test_split\n\n# Load data\niris = load_iris()\nX, y = iris.data, iris.target\n\n# Split data\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Create and train KNN model with k=5\nknn = KNeighborsClassifier(n_neighbors=5)\nknn.fit(X_train, y_train)\n\n# Evaluate\naccuracy = knn.score(X_test, y_test)\nprint(f\"Accuracy: {accuracy:.1%}\")",
    "solution_code": "from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.datasets import load_iris\nfrom sklearn.model_selection import train_test_split\n\n# Load data\niris = load_iris()\nX, y = iris.data, iris.target\n\n# Split data\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Create and train KNN model with k=5\nknn = KNeighborsClassifier(n_neighbors=5)\nknn.fit(X_train, y_train)\n\n# Evaluate\naccuracy = knn.score(X_test, y_test)\nprint(f\"Accuracy: {accuracy:.1%}\")",
    "expected_output": "Accuracy: 100.0%",
    "chapter_id": 14,
    "chapter_title": "Machine Learning Intro"
  },
  "108": {
    "id": 108,
    "title": "Decision Tree",
    "content": "# üå≥ Decision Trees: If-Then-Else Machine Learning\n\n## What is a Decision Tree?\n\nA **Decision Tree** makes predictions by learning a series of if-then-else questions about your data‚Äîjust like a flowchart!\n\n## Real-World Analogy\n\n\"Should I play tennis today?\"\n- Is it sunny? (Yes ‚Üí Check humidity)\n  - Is humidity high? (Yes ‚Üí No tennis)\n  - Is humidity normal? (Yes ‚Üí Play tennis!)\n- Is it rainy? (Yes ‚Üí No tennis)\n\n## How It Works\n\nThe tree asks questions that best split the data:\n1. Find the feature that best separates classes\n2. Split data based on that feature\n3. Repeat until all data is pure (or max depth reached)\n\n## Using scikit-learn\n\n```python\nfrom sklearn.tree import DecisionTreeClassifier\n\ntree = DecisionTreeClassifier(max_depth=3)\ntree.fit(X_train, y_train)\npredictions = tree.predict(X_test)\n```\n\n## Key Parameters\n\n- **max_depth**: Limit tree depth (prevents overfitting)\n- **min_samples_split**: Minimum samples to split a node\n- **criterion**: 'gini' or 'entropy' for measuring splits\n\n## Pros & Cons\n\n‚úÖ Easy to understand and visualize\n‚úÖ Handles non-linear relationships\n‚ùå Can overfit easily\n‚ùå Unstable‚Äîsmall data changes = big tree changes\n\n---\n\n## üéØ Your Task\n\nTrain a decision tree classifier on the wine dataset.",
    "starter_code": "from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.datasets import load_wine\nfrom sklearn.model_selection import train_test_split\n\n# Load wine dataset\nwine = load_wine()\nX, y = wine.data, wine.target\n\n# Split data\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Train decision tree (limit depth to prevent overfitting)\ntree = DecisionTreeClassifier(max_depth=3, random_state=42)\ntree.fit(X_train, y_train)\n\n# Evaluate\naccuracy = tree.score(X_test, y_test)\nprint(f\"Accuracy: {accuracy:.1%}\")",
    "solution_code": "from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.datasets import load_wine\nfrom sklearn.model_selection import train_test_split\n\n# Load wine dataset\nwine = load_wine()\nX, y = wine.data, wine.target\n\n# Split data\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Train decision tree (limit depth to prevent overfitting)\ntree = DecisionTreeClassifier(max_depth=3, random_state=42)\ntree.fit(X_train, y_train)\n\n# Evaluate\naccuracy = tree.score(X_test, y_test)\nprint(f\"Accuracy: {accuracy:.1%}\")",
    "expected_output": "Accuracy: 91.7%",
    "chapter_id": 14,
    "chapter_title": "Machine Learning Intro"
  },
  "109": {
    "id": 109,
    "title": "Feature Scaling",
    "content": "# ÔøΩÔøΩ Feature Scaling: Putting Features on Equal Footing\n\n## Why Scale Features?\n\nMany ML algorithms are sensitive to feature scales. If one feature ranges 0-1000 and another 0-1, the algorithm may favor the larger one!\n\n## Two Main Methods\n\n### 1. Standardization (Z-Score Scaling)\nMakes mean=0 and std=1\n```python\nX_scaled = (X - mean) / std\n```\n\n### 2. Min-Max Scaling (Normalization)\nScales to 0-1 range\n```python\nX_scaled = (X - min) / (max - min)\n```\n\n## Using scikit-learn\n\n```python\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\n\n# Standardization\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)  # Use same scaler!\n\n# Min-Max\nminmax = MinMaxScaler()\nX_normalized = minmax.fit_transform(X_train)\n```\n\n## When to Scale\n\n| Algorithm | Needs Scaling? |\n|-----------|---------------|\n| KNN | ‚úÖ Yes |\n| SVM | ‚úÖ Yes |\n| Neural Networks | ‚úÖ Yes |\n| Decision Trees | ‚ùå No |\n| Random Forest | ‚ùå No |\n\n## ‚ö†Ô∏è Common Mistake\n\n**Always fit the scaler on training data only!** Then transform both train and test with the same scaler.\n\n---\n\n## üéØ Your Task\n\nScale features for a KNN classifier and compare accuracy.",
    "starter_code": "from sklearn.preprocessing import StandardScaler\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.datasets import load_wine\nfrom sklearn.model_selection import train_test_split\n\n# Load data\nwine = load_wine()\nX, y = wine.data, wine.target\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Without scaling\nknn = KNeighborsClassifier(n_neighbors=5)\nknn.fit(X_train, y_train)\nacc_unscaled = knn.score(X_test, y_test)\n\n# With scaling\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\nknn_scaled = KNeighborsClassifier(n_neighbors=5)\nknn_scaled.fit(X_train_scaled, y_train)\nacc_scaled = knn_scaled.score(X_test_scaled, y_test)\n\nprint(f\"Without scaling: {acc_unscaled:.1%}\")\nprint(f\"With scaling: {acc_scaled:.1%}\")",
    "solution_code": "from sklearn.preprocessing import StandardScaler\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.datasets import load_wine\nfrom sklearn.model_selection import train_test_split\n\n# Load data\nwine = load_wine()\nX, y = wine.data, wine.target\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Without scaling\nknn = KNeighborsClassifier(n_neighbors=5)\nknn.fit(X_train, y_train)\nacc_unscaled = knn.score(X_test, y_test)\n\n# With scaling\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\nknn_scaled = KNeighborsClassifier(n_neighbors=5)\nknn_scaled.fit(X_train_scaled, y_train)\nacc_scaled = knn_scaled.score(X_test_scaled, y_test)\n\nprint(f\"Without scaling: {acc_unscaled:.1%}\")\nprint(f\"With scaling: {acc_scaled:.1%}\")",
    "expected_output": "Without scaling: 69.4%\nWith scaling: 97.2%",
    "chapter_id": 14,
    "chapter_title": "Machine Learning Intro"
  },
  "110": {
    "id": 110,
    "title": "Cross Validation",
    "content": "# üîÑ Cross-Validation: Robust Model Evaluation\n\n## The Problem with Single Train/Test Split\n\nOne random split might be lucky or unlucky! Your accuracy could vary based on which data ended up in test set.\n\n## The Solution: K-Fold Cross-Validation\n\n1. Split data into K equal parts (folds)\n2. Train on K-1 folds, test on remaining fold\n3. Repeat K times (each fold is test set once)\n4. Average the K scores\n\n## Visual Example (5-Fold)\n\n```\nRound 1: [Test][Train][Train][Train][Train] ‚Üí 85%\nRound 2: [Train][Test][Train][Train][Train] ‚Üí 88%\nRound 3: [Train][Train][Test][Train][Train] ‚Üí 82%\nRound 4: [Train][Train][Train][Test][Train] ‚Üí 86%\nRound 5: [Train][Train][Train][Train][Test] ‚Üí 84%\n\nAverage: 85% ¬± 2.2%\n```\n\n## Using scikit-learn\n\n```python\nfrom sklearn.model_selection import cross_val_score\n\nscores = cross_val_score(model, X, y, cv=5)  # 5-fold CV\nprint(f\"Mean: {scores.mean():.2f} ¬± {scores.std():.2f}\")\n```\n\n## When to Use\n\n‚úÖ Limited data (can't afford to set aside 20% for test)\n‚úÖ Want more reliable accuracy estimates\n‚úÖ Hyperparameter tuning\n\n---\n\n## üéØ Your Task\n\nEvaluate a model using 5-fold cross-validation.",
    "starter_code": "from sklearn.model_selection import cross_val_score\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.datasets import load_iris\n\n# Load data\niris = load_iris()\nX, y = iris.data, iris.target\n\n# Create model\nknn = KNeighborsClassifier(n_neighbors=5)\n\n# Perform 5-fold cross-validation\nscores = cross_val_score(knn, X, y, cv=5)\n\nprint(\"Fold scores:\", [f\"{s:.1%}\" for s in scores])\nprint(f\"Mean accuracy: {scores.mean():.1%} ¬± {scores.std():.1%}\")",
    "solution_code": "from sklearn.model_selection import cross_val_score\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.datasets import load_iris\n\n# Load data\niris = load_iris()\nX, y = iris.data, iris.target\n\n# Create model\nknn = KNeighborsClassifier(n_neighbors=5)\n\n# Perform 5-fold cross-validation\nscores = cross_val_score(knn, X, y, cv=5)\n\nprint(\"Fold scores:\", [f\"{s:.1%}\" for s in scores])\nprint(f\"Mean accuracy: {scores.mean():.1%} ¬± {scores.std():.1%}\")",
    "expected_output": "Fold scores: ['96.7%', '100.0%', '93.3%', '96.7%', '100.0%']\nMean accuracy: 97.3% ¬± 2.5%",
    "chapter_id": 14,
    "chapter_title": "Machine Learning Intro"
  },
  "111": {
    "id": 111,
    "title": "Confusion Matrix",
    "content": "# üìä Confusion Matrix: Understanding Model Errors\n\n## What is a Confusion Matrix?\n\nA **confusion matrix** shows exactly HOW your model made mistakes‚Äînot just overall accuracy.\n\n## The 2x2 Matrix (Binary Classification)\n\n|  | Predicted: No | Predicted: Yes |\n|--|--------------|----------------|\n| **Actual: No** | TN (True Negative) | FP (False Positive) |\n| **Actual: Yes** | FN (False Negative) | TP (True Positive) |\n\n## Key Metrics\n\n- **Accuracy**: (TP + TN) / Total\n- **Precision**: TP / (TP + FP) ‚Äî \"Of predicted positives, how many were right?\"\n- **Recall**: TP / (TP + FN) ‚Äî \"Of actual positives, how many did we find?\"\n- **F1 Score**: Harmonic mean of precision and recall\n\n## Real-World Example\n\nMedical test for a disease:\n- **False Positive**: Healthy person told they're sick (stress, unnecessary treatment)\n- **False Negative**: Sick person told they're healthy (dangerous!)\n\n## Using scikit-learn\n\n```python\nfrom sklearn.metrics import confusion_matrix, classification_report\n\ncm = confusion_matrix(y_true, y_pred)\nprint(classification_report(y_true, y_pred))\n```\n\n---\n\n## üéØ Your Task\n\nGenerate a confusion matrix and classification report for a classifier.",
    "starter_code": "from sklearn.metrics import confusion_matrix, classification_report\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.datasets import load_breast_cancer\nfrom sklearn.model_selection import train_test_split\n\n# Load breast cancer dataset (binary classification)\ncancer = load_breast_cancer()\nX, y = cancer.data, cancer.target\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Train model\nknn = KNeighborsClassifier(n_neighbors=5)\nknn.fit(X_train, y_train)\ny_pred = knn.predict(X_test)\n\n# Confusion matrix\ncm = confusion_matrix(y_test, y_pred)\nprint(\"Confusion Matrix:\")\nprint(cm)\nprint(\"\\nClassification Report:\")\nprint(classification_report(y_test, y_pred, target_names=['Malignant', 'Benign']))",
    "solution_code": "from sklearn.metrics import confusion_matrix, classification_report\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.datasets import load_breast_cancer\nfrom sklearn.model_selection import train_test_split\n\n# Load breast cancer dataset (binary classification)\ncancer = load_breast_cancer()\nX, y = cancer.data, cancer.target\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Train model\nknn = KNeighborsClassifier(n_neighbors=5)\nknn.fit(X_train, y_train)\ny_pred = knn.predict(X_test)\n\n# Confusion matrix\ncm = confusion_matrix(y_test, y_pred)\nprint(\"Confusion Matrix:\")\nprint(cm)\nprint(\"\\nClassification Report:\")\nprint(classification_report(y_test, y_pred, target_names=['Malignant', 'Benign']))",
    "expected_output": "Confusion Matrix:\n[[41  2]\n [ 3 68]]",
    "chapter_id": 14,
    "chapter_title": "Machine Learning Intro"
  },
  "112": {
    "id": 112,
    "title": "Complete ML Pipeline",
    "content": "# üîß Complete ML Pipeline: Putting It All Together\n\n## The ML Pipeline Steps\n\nA complete machine learning pipeline includes all steps from raw data to predictions:\n\n```\nRaw Data ‚Üí Preprocessing ‚Üí Feature Engineering ‚Üí Train/Test Split\n    ‚Üí Model Training ‚Üí Evaluation ‚Üí Deployment\n```\n\n## Step 1: Load and Explore Data\n```python\nimport pandas as pd\ndf = pd.read_csv('data.csv')\nprint(df.head())\nprint(df.describe())\n```\n\n## Step 2: Preprocess and Clean\n```python\n# Handle missing values\ndf = df.dropna()\n\n# Encode categorical variables\ndf['category'] = df['category'].map({'A': 0, 'B': 1, 'C': 2})\n```\n\n## Step 3: Feature Engineering\n```python\n# Create new features\ndf['age_squared'] = df['age'] ** 2\ndf['income_per_age'] = df['income'] / df['age']\n```\n\n## Step 4: Split Data\n```python\nfrom sklearn.model_selection import train_test_split\nX = df.drop('target', axis=1)\ny = df['target']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n```\n\n## Step 5: Scale Features\n```python\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n```\n\n## Step 6: Train and Evaluate\n```python\nfrom sklearn.ensemble import RandomForestClassifier\nmodel = RandomForestClassifier()\nmodel.fit(X_train_scaled, y_train)\naccuracy = model.score(X_test_scaled, y_test)\n```\n\n---\n\n## üéØ Your Task\n\nBuild a complete ML pipeline for customer churn prediction.",
    "starter_code": "from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, classification_report\nimport numpy as np\n\n# Simulated customer data\nnp.random.seed(42)\nn_samples = 500\nX = np.column_stack([\n    np.random.rand(n_samples) * 100,  # tenure\n    np.random.rand(n_samples) * 1000,  # monthly_spend\n    np.random.randint(0, 5, n_samples)  # support_tickets\n])\ny = (X[:, 2] > 2).astype(int)  # Churn if > 2 tickets\n\n# Step 1: Split data\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Step 2: Scale features\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# Step 3: Train model\nmodel = RandomForestClassifier(n_estimators=100, random_state=42)\nmodel.fit(X_train_scaled, y_train)\n\n# Step 4: Evaluate\ny_pred = model.predict(X_test_scaled)\nprint(f\"Accuracy: {accuracy_score(y_test, y_pred):.1%}\")",
    "solution_code": "from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\nimport numpy as np\n\nnp.random.seed(42)\nn_samples = 500\nX = np.column_stack([\n    np.random.rand(n_samples) * 100,\n    np.random.rand(n_samples) * 1000,\n    np.random.randint(0, 5, n_samples)\n])\ny = (X[:, 2] > 2).astype(int)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\nmodel = RandomForestClassifier(n_estimators=100, random_state=42)\nmodel.fit(X_train_scaled, y_train)\ny_pred = model.predict(X_test_scaled)\nprint(f\"Accuracy: {accuracy_score(y_test, y_pred):.1%}\")",
    "expected_output": "Accuracy: 100.0%",
    "chapter_id": 14,
    "chapter_title": "Machine Learning Intro"
  },
  "113": {
    "id": 113,
    "title": "üíÄ FINAL BOSS: Full Stack Data Scientist",
    "content": "# üíÄ FINAL BOSS: The Full Stack Data Scientist\n\nCongratulations on making it this far! You've mastered Python fundamentals, data manipulation, visualization, statistics, and machine learning. Now it's time to prove your skills by building a **complete end-to-end data science pipeline**.\n\n---\n\n## üèÜ The Ultimate Challenge\n\nYou are a data scientist at a real estate company. Your task is to build a **house price prediction model** using the skills you've learned throughout this course.\n\n## üìã Your Mission\n\nComplete ALL of the following steps:\n\n### Step 1: Create the Dataset\nGenerate synthetic house data with:\n- **Features**: House size (square feet)\n- **Target**: House price (with some realistic noise)\n- Use `np.random.seed(42)` for reproducibility\n\n### Step 2: Explore the Data\nCalculate and print basic statistics:\n- Mean and standard deviation of house sizes\n- Mean and standard deviation of house prices\n\n### Step 3: Split the Data\nUse `train_test_split` to create:\n- 80% training data\n- 20% test data\n- Use `random_state=42`\n\n### Step 4: Train a Model\n- Create a `LinearRegression` model\n- Fit it on the training data\n\n### Step 5: Evaluate Performance\n- Make predictions on test data\n- Calculate and print the R¬≤ score\n- Make a price prediction for a 2000 sqft house\n\n### Step 6: Celebrate! üéâ\nPrint a congratulations message!\n\n---\n\n## üìä Expected Output Format\n\nYour output should look like this:\n```\nSize: mean=XXXX, std=XXX\nPrice: mean=XXXXXX, std=XXXXX\n\nModel R¬≤ Score: 0.XXXX\nPrice prediction for 2000 sqft: $XXX,XXX\n\nüéâ CONGRATULATIONS! You've completed the course!\n```\n\n---\n\n## üí° Hints\n\n- Import: `numpy`, `train_test_split`, `LinearRegression`, `r2_score`\n- Use `.reshape(-1, 1)` to make arrays 2D for sklearn\n- Use f-strings with formatting: `f\"{value:.2f}\"` for 2 decimals\n- Use `{value:,.0f}` for comma-separated numbers\n\n---\n\n## üéØ Complete the Pipeline Below\n\n\n> [!TIP]\n> **Verification Tip**: We've set `np.random.seed(42)` so your random dataset matches the answer key perfectly.",
    "starter_code": "np.random.seed(42)  # üîí Fixed seed for verification\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import r2_score\n\n# Step 1: Create the Dataset\n# Generate 100 houses with sizes between 500-3000 sqft\n# Price = size * 100 + random noise\n\n\n# Step 2: Explore the Data\n# Print mean and std for size and price\n\n\n# Step 3: Split the Data (80/20 split)\n\n\n# Step 4: Train a Linear Regression Model\n\n\n# Step 5: Evaluate - Calculate R¬≤ and predict for 2000 sqft\n\n\n# Step 6: Print congratulations message\n",
    "solution_code": "import numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import r2_score\n\n# Step 1: Create the Dataset\nnp.random.seed(42)\nsize = np.random.randint(500, 3000, 100).reshape(-1, 1)\nprice = size * 100 + np.random.normal(0, 10000, (100, 1))\n\n# Step 2: Explore the Data\nprint(f\"Size: mean={size.mean():.0f}, std={size.std():.0f}\")\nprint(f\"Price: mean={price.mean():.0f}, std={price.std():.0f}\")\n\n# Step 3: Split the Data (80/20 split)\nX_train, X_test, y_train, y_test = train_test_split(\n    size, price, test_size=0.2, random_state=42\n)\n\n# Step 4: Train a Linear Regression Model\nmodel = LinearRegression()\nmodel.fit(X_train, y_train)\n\n# Step 5: Evaluate - Calculate R¬≤ and predict for 2000 sqft\ny_pred = model.predict(X_test)\nr2 = r2_score(y_test, y_pred)\nprint(f\"\\nModel R¬≤ Score: {r2:.4f}\")\nprint(f\"Price prediction for 2000 sqft: ${model.predict([[2000]])[0][0]:,.0f}\")\n\n# Step 6: Print congratulations message\nprint(\"\\nüéâ CONGRATULATIONS! You've completed the course!\")",
    "expected_output": "Size: mean=1716, std=712\nPrice: mean=171620, std=71218\n\nModel R¬≤ Score: 0.9808\nPrice prediction for 2000 sqft: $199,917\n\nüéâ CONGRATULATIONS! You've completed the course!",
    "chapter_id": 101,
    "chapter_title": "Final Boss: Data Scientist"
  },
  "114": {
    "id": 114,
    "title": "NumPy Introduction",
    "chapter_id": 95,
    "chapter_title": "NumPy Fundamentals",
    "content": "# üî¢ Introduction to NumPy\n\n## Definition\n**NumPy** (Numerical Python) is a powerful library that provides support for large, multi-dimensional arrays and matrices, along with a collection of mathematical functions to operate on them.\n\n## Why Do We Need NumPy?\n\nImagine you have a list of 1 million numbers and need to multiply each by 2. With regular Python lists, you'd need a loop that runs 1 million times. With NumPy, it's a single operation that runs 50x faster!\n\n## Real-World Analogy\n\nThink of NumPy arrays like a **spreadsheet column**:\n- All values are the same type (all numbers)\n- You can apply formulas to the entire column at once\n- Operations are optimized for speed\n\n## NumPy vs Python Lists\n\n| Feature | Python List | NumPy Array |\n| --- | --- | --- |\n| Speed | Slow (loops required) | **50x faster** |\n| Memory | Uses more RAM | **Efficient storage** |\n| Math Operations | Manual loops | **Vectorized (instant)** |\n| Data Types | Mixed allowed | Same type only |\n\n## How to Create Arrays\n\n```python\nimport numpy as np\n\n# From a Python list\narr = np.array([1, 2, 3, 4, 5])\nprint(arr)  # [1 2 3 4 5]\n\n# Special arrays\nzeros = np.zeros(5)       # [0. 0. 0. 0. 0.]\nones = np.ones(3)         # [1. 1. 1.]\nrange_arr = np.arange(0, 10, 2)  # [0 2 4 6 8]\n```\n\n## Key Vocabulary\n\n| Term | Meaning |\n| --- | --- |\n| **Array** | NumPy's main data structure - a grid of values |\n| **Vectorization** | Applying operations to entire arrays at once |\n| **Dimension** | The number of axes (1D = list, 2D = table) |\n\n---\n\n## üéØ Your Task\n\nCreate a NumPy array containing the numbers `10, 20, 30, 40, 50` and print it.\n\n**Hint**: Use `np.array([...])` with your numbers inside the brackets.\n",
    "starter_code": "import numpy as np\n\n# Create an array with 10, 20, 30, 40, 50\n",
    "solution_code": "import numpy as np\n\n# Create an array with 10, 20, 30, 40, 50\narr = np.array([10, 20, 30, 40, 50])\nprint(arr)",
    "expected_output": "[10 20 30 40 50]",
    "order": 1
  },
  "115": {
    "id": 115,
    "title": "Vectorized Operations",
    "chapter_id": 95,
    "chapter_title": "NumPy Fundamentals",
    "content": "# ‚ö° Vectorized Operations\n\n## Definition\n**Vectorization** means applying an operation to an entire array at once, without writing loops. This is NumPy's superpower!\n\n## Why Vectorization Matters\n\nIn regular Python:\n```python\nnumbers = [1, 2, 3, 4, 5]\ndoubled = []\nfor n in numbers:\n    doubled.append(n * 2)  # Slow loop!\n# doubled = [2, 4, 6, 8, 10]\n```\n\nWith NumPy (vectorized):\n```python\nimport numpy as np\narr = np.array([1, 2, 3, 4, 5])\ndoubled = arr * 2  # Instant! No loop needed!\n# [2 4 6 8 10]\n```\n\n## Real-World Analogy\n\nImagine you're a teacher grading tests:\n- **Loop way**: Grade one test, write score, pick up next test, repeat 100 times\n- **Vectorized way**: Use a grading machine that scores all 100 tests at once!\n\n## All Math Operations Work!\n\n```python\narr = np.array([10, 20, 30])\n\narr + 5    # [15 25 35]  - Add 5 to each\narr - 5    # [ 5 15 25]  - Subtract 5 from each\narr * 2    # [20 40 60]  - Multiply each by 2\narr / 10   # [1. 2. 3.]  - Divide each by 10\narr ** 2   # [100 400 900] - Square each\n```\n\n## Array-to-Array Operations\n\nYou can also operate on two arrays element-by-element:\n\n```python\na = np.array([1, 2, 3])\nb = np.array([4, 5, 6])\n\na + b  # [5, 7, 9]\na * b  # [4, 10, 18]\n```\n\n## Key Vocabulary\n\n| Term | Meaning |\n| --- | --- |\n| **Element-wise** | Operation applied to each element individually |\n| **Broadcasting** | NumPy's ability to work with different-sized arrays |\n| **Scalar** | A single number (like 5 or 2.5) |\n\n---\n\n## üéØ Your Task\n\nCreate an array `[2, 4, 6, 8]` and multiply every element by 3. Print the result.\n\n**Expected output**: `[ 6 12 18 24]`\n",
    "starter_code": "import numpy as np\n\n# Create array and multiply by 3\n",
    "solution_code": "import numpy as np\n\narr = np.array([2, 4, 6, 8])\nresult = arr * 3\nprint(result)",
    "expected_output": "[ 6 12 18 24]",
    "order": 2
  },
  "116": {
    "id": 116,
    "title": "Boolean Indexing",
    "chapter_id": 95,
    "chapter_title": "NumPy Fundamentals",
    "content": "# üéØ Array Indexing & Boolean Filtering\n\n## Definition\n**Indexing** lets you access specific elements. **Boolean filtering** lets you select elements that match a condition‚Äîthis is one of NumPy's most powerful features!\n\n## Basic Indexing (Like Lists)\n\n```python\nimport numpy as np\narr = np.array([10, 20, 30, 40, 50])\n\narr[0]     # 10 (first element)\narr[-1]    # 50 (last element)\narr[1:4]   # [20 30 40] (slice from index 1 to 3)\narr[::2]   # [10 30 50] (every other element)\n```\n\n## Boolean Filtering (The Magic!)\n\nThe real power: select elements that match a condition!\n\n```python\narr = np.array([15, 25, 35, 45, 55])\n\n# Get all elements greater than 30\nbig = arr[arr > 30]  # [35 45 55]\n\n# Get all even elements\narr = np.array([1, 2, 3, 4, 5, 6])\nevens = arr[arr % 2 == 0]  # [2 4 6]\n```\n\n## Real-World Analogy\n\nThink of boolean filtering like a **coffee filter**:\n- You pour in a mix of coffee and water (your array)\n- The filter only lets through what matches the criteria (the coffee!)\n- Everything else stays behind\n\n## How It Works Under the Hood\n\n```python\narr = np.array([10, 20, 30, 40])\n\n# Step 1: Create a boolean mask\nmask = arr > 25  # [False, False, True, True]\n\n# Step 2: Use mask to filter\nresult = arr[mask]  # [30, 40]\n```\n\n## Key Vocabulary\n\n| Term | Meaning |\n| --- | --- |\n| **Index** | Position of an element (starts at 0) |\n| **Slice** | A range of elements (like `arr[1:4]`) |\n| **Boolean Mask** | An array of True/False values used for filtering |\n\n---\n\n## üéØ Your Task\n\nGiven the array `[5, 10, 15, 20, 25, 30]`, use boolean indexing to get only values greater than 15. Print the result.\n\n**Expected output**: `[20 25 30]`\n",
    "starter_code": "import numpy as np\n\narr = np.array([5, 10, 15, 20, 25, 30])\n\n# Get values > 15\n",
    "solution_code": "import numpy as np\n\narr = np.array([5, 10, 15, 20, 25, 30])\nresult = arr[arr > 15]\nprint(result)",
    "expected_output": "[20 25 30]",
    "order": 3
  },
  "117": {
    "id": 117,
    "title": "Broadcasting",
    "chapter_id": 95,
    "chapter_title": "NumPy Fundamentals",
    "content": "# üì° Broadcasting\n\n## Definition\n**Broadcasting** is NumPy's ability to perform operations on arrays of different shapes. It \"broadcasts\" the smaller array across the larger one.\n\n## Why Broadcasting is Powerful\n\nWithout broadcasting, you'd need matching array sizes. With broadcasting, NumPy automatically expands the smaller array:\n\n```python\nimport numpy as np\n\n# Add a scalar to every element (scalar broadcasts)\narr = np.array([1, 2, 3, 4, 5])\nresult = arr + 10  # [11, 12, 13, 14, 15]\n```\n\n## Real-World Analogy\n\nImagine you're giving everyone in a class a $5 bonus:\n- **Without broadcasting**: Write \"$5\" on 30 separate sticky notes\n- **With broadcasting**: Announce \"$5 for everyone!\" once\n\n## Practical Example: Centering Data\n\nA common data science task is \"centering\" data‚Äîsubtracting the mean so the new mean is 0:\n\n```python\ndata = np.array([100, 200, 300, 400, 500])\n\n# Calculate the mean\nmean = np.mean(data)  # 300.0\n\n# Subtract mean from ALL elements (broadcasting!)\ncentered = data - mean\n# [-200. -100.    0.  100.  200.]\n\n# Now the mean is 0!\nprint(np.mean(centered))  # 0.0\n```\n\n## 2D Broadcasting\n\nBroadcasting works with matrices too:\n\n```python\nmatrix = np.array([[1, 2, 3],\n                   [4, 5, 6],\n                   [7, 8, 9]])\n\n# Add 10 to every element\nresult = matrix + 10\n# [[11 12 13]\n#  [14 15 16]\n#  [17 18 19]]\n```\n\n## Key Vocabulary\n\n| Term | Meaning |\n| --- | --- |\n| **Broadcasting** | Automatic expansion of arrays for operations |\n| **Centering** | Subtracting the mean from all values |\n| **Normalization** | Scaling data to a standard range |\n\n---\n\n## üéØ Your Task\n\nGiven `[10, 20, 30, 40, 50]`:\n1. Calculate its mean using `np.mean()`\n2. Subtract the mean from the array (centering it)\n3. Print the centered array\n\n**Expected output**: `[-20. -10.   0.  10.  20.]`\n",
    "starter_code": "import numpy as np\n\ndata = np.array([10, 20, 30, 40, 50])\n\n# Calculate mean and center\n",
    "solution_code": "import numpy as np\n\ndata = np.array([10, 20, 30, 40, 50])\nmean = np.mean(data)\ncentered = data - mean\nprint(centered)",
    "expected_output": "[-20. -10.   0.  10.  20.]",
    "order": 4
  },
  "118": {
    "id": 118,
    "title": "NumPy Statistics",
    "chapter_id": 95,
    "chapter_title": "NumPy Fundamentals",
    "content": "# üìä NumPy Statistical Functions\n\n## Definition\nNumPy provides fast, built-in functions for common statistical calculations‚Äîno loops required!\n\n## Why Use NumPy for Statistics?\n\n| Pure Python | NumPy |\n| --- | --- |\n| `sum(my_list)` | `np.sum(arr)` ‚Üê **10x faster** |\n| Manual loop for mean | `np.mean(arr)` ‚Üê **One line** |\n| No built-in std | `np.std(arr)` ‚Üê **Instant** |\n\n## Common Statistical Functions\n\n```python\nimport numpy as np\narr = np.array([10, 20, 30, 40, 50])\n\nnp.sum(arr)    # 150 - Total of all elements\nnp.mean(arr)   # 30.0 - Average\nnp.std(arr)    # 14.14 - Standard deviation\nnp.min(arr)    # 10 - Minimum value\nnp.max(arr)    # 50 - Maximum value\nnp.median(arr) # 30.0 - Middle value\n```\n\n## Real-World Analogy\n\nThink of NumPy stats like a **calculator with special buttons**:\n- Instead of typing `10 + 20 + 30 + 40 + 50 =` then `√∑ 5 =`\n- Just press the **MEAN** button and it does everything!\n\n## Aggregation on 2D Arrays\n\nFor matrices, you can aggregate along axes:\n\n```python\nmatrix = np.array([[1, 2, 3],\n                   [4, 5, 6]])\n\nnp.sum(matrix)           # 21 (all elements)\nnp.sum(matrix, axis=0)   # [5, 7, 9] (sum each column)\nnp.sum(matrix, axis=1)   # [6, 15] (sum each row)\n```\n\n## Key Vocabulary\n\n| Term | Meaning |\n| --- | --- |\n| **Aggregation** | Combining values into a single result |\n| **Axis** | The direction of operation (0=columns, 1=rows) |\n| **Reduction** | Operations that reduce array size (like sum) |\n\n---\n\n## üéØ Your Task\n\nCreate an array `[100, 200, 300, 400, 500]` and print:\n1. The sum\n2. The mean  \n3. The maximum\n\nPrint each value on a new line.\n",
    "starter_code": "import numpy as np\n\narr = np.array([100, 200, 300, 400, 500])\n\n# Print sum, mean, max\n",
    "solution_code": "import numpy as np\n\narr = np.array([100, 200, 300, 400, 500])\nprint(np.sum(arr))\nprint(np.mean(arr))\nprint(np.max(arr))",
    "expected_output": "1500\n300.0\n500",
    "order": 5
  },
  "119": {
    "id": 119,
    "title": "Handling Missing Data",
    "chapter_id": 96,
    "chapter_title": "Data Cleaning",
    "content": "# üßπ Handling Missing Data with dropna()\n\n## Definition\n**Missing data** appears in real datasets as `NaN` (Not a Number) or `None`. The `dropna()` method removes rows containing missing values.\n\n## Why Missing Data Matters\n\nReal-world data is messy! Surveys have unanswered questions, sensors malfunction, data entry has errors. You must handle missing values before analysis, or your calculations will be wrong.\n\n## Real-World Analogy\n\nThink of a class attendance sheet:\n- Some students forgot to sign in (missing data!)\n- If you count only signed rows, you get accurate attendance\n- `dropna()` is like only counting the complete rows\n\n## Detecting Missing Values\n\n```python\nimport pandas as pd\n\ndf = pd.DataFrame({\n    'name': ['Alice', 'Bob', None],\n    'age': [25, None, 30]\n})\n\n# Check for missing values\nprint(df.isnull())\n#     name    age\n# 0  False  False\n# 1  False   True\n# 2   True  False\n\n# Count missing per column\nprint(df.isnull().sum())\n# name    1\n# age     1\n```\n\n## Using dropna()\n\n```python\n# Drop rows with ANY missing value\ndf_clean = df.dropna()\n\n# Drop rows only if ALL values are missing\ndf_clean = df.dropna(how='all')\n\n# Drop based on specific column\ndf_clean = df.dropna(subset=['age'])\n```\n\n## Key Vocabulary\n\n| Term | Meaning |\n| --- | --- |\n| **NaN** | \"Not a Number\" - represents missing data |\n| **dropna()** | Method to remove rows with missing values |\n| **isnull()** | Method to detect missing values (returns True/False) |\n\n---\n\n## üéØ Your Task\n\nGiven a DataFrame with missing values in 'product' and 'price' columns, use `dropna()` to remove rows with any missing data. Print the cleaned DataFrame.\n",
    "starter_code": "import pandas as pd\n\ndf = pd.DataFrame({\n    'product': ['Apple', 'Banana', None, 'Orange'],\n    'price': [1.0, 0.5, 0.75, None]\n})\n\n# Drop rows with missing values\n",
    "solution_code": "import pandas as pd\n\ndf = pd.DataFrame({\n    'product': ['Apple', 'Banana', None, 'Orange'],\n    'price': [1.0, 0.5, 0.75, None]\n})\nclean_df = df.dropna()\nprint(clean_df)",
    "expected_output": "  product  price\n0   Apple    1.0\n1  Banana    0.5",
    "order": 1
  },
  "120": {
    "id": 120,
    "title": "Filling Missing Values",
    "chapter_id": 96,
    "chapter_title": "Data Cleaning",
    "content": "# üîß Filling Missing Values with fillna()\n\n## Definition\n**fillna()** replaces missing values with a specified value instead of dropping the entire row. This preserves more data!\n\n## Why Fill Instead of Drop?\n\n| Situation | Best Approach |\n| --- | --- |\n| Few missing values | Fill with mean/median |\n| Categorical data | Fill with mode or \"Unknown\" |\n| Time series | Forward/backward fill |\n| Critical analysis | Drop (if you need complete data) |\n\n## Real-World Analogy\n\nImagine a survey where some people skipped the age question:\n- **Drop approach**: Throw away their entire survey (loses data!)\n- **Fill approach**: Estimate their age from the average (preserves other answers)\n\n## Filling Strategies\n\n```python\nimport pandas as pd\n\ndf = pd.DataFrame({\n    'score': [85, None, 90, None, 75]\n})\n\n# Fill with a specific value\ndf['score'].fillna(0)  # Replace None with 0\n\n# Fill with the mean\nmean_score = df['score'].mean()  # 83.33\ndf['score'].fillna(mean_score)\n\n# Fill with the median (good for outliers)\ndf['score'].fillna(df['score'].median())\n\n# Forward fill (use previous value)\ndf['score'].fillna(method='ffill')\n\n# Backward fill (use next value)\ndf['score'].fillna(method='bfill')\n```\n\n## Key Vocabulary\n\n| Term | Meaning |\n| --- | --- |\n| **fillna()** | Method to replace NaN with a value |\n| **Imputation** | The process of replacing missing values |\n| **Forward fill** | Copy the previous valid value |\n\n---\n\n## üéØ Your Task\n\nGiven a DataFrame with missing scores, calculate the mean of existing scores and use `fillna()` to replace missing values with that mean. Print the result.\n",
    "starter_code": "import pandas as pd\n\ndf = pd.DataFrame({\n    'student': ['Alice', 'Bob', 'Carol', 'David'],\n    'score': [80.0, None, 90.0, None]\n})\n\n# Fill missing with mean\n",
    "solution_code": "import pandas as pd\n\ndf = pd.DataFrame({\n    'student': ['Alice', 'Bob', 'Carol', 'David'],\n    'score': [80.0, None, 90.0, None]\n})\nmean_score = df['score'].mean()\ndf['score'] = df['score'].fillna(mean_score)\nprint(df)",
    "expected_output": "  student  score\n0   Alice   80.0\n1     Bob   85.0\n2   Carol   90.0\n3   David   85.0",
    "order": 2
  },
  "121": {
    "id": 121,
    "title": "Removing Duplicates",
    "chapter_id": 96,
    "chapter_title": "Data Cleaning",
    "content": "# üóëÔ∏è Removing Duplicates with drop_duplicates()\n\n## Definition\n**Duplicate rows** are exact copies of other rows. `drop_duplicates()` removes them, keeping only unique rows.\n\n## Why Duplicates Are Dangerous\n\nDuplicates can:\n- **Skew averages**: Count the same person twice = wrong average\n- **Inflate counts**: \"100 customers\" might really be 80 unique people\n- **Waste memory**: Storing the same data multiple times\n\n## Real-World Analogy\n\nImagine a guest list where some people RSVP'd multiple times:\n- Without removing duplicates, you'd order too much food!\n- `drop_duplicates()` ensures you count each guest only once\n\n## Finding Duplicates\n\n```python\nimport pandas as pd\n\ndf = pd.DataFrame({\n    'name': ['Alice', 'Bob', 'Alice', 'Carol'],\n    'age': [25, 30, 25, 28]\n})\n\n# Check for duplicates\nprint(df.duplicated())\n# 0    False\n# 1    False\n# 2     True  <- This row is a duplicate of row 0!\n# 3    False\n\n# Count duplicates\nprint(df.duplicated().sum())  # 1\n```\n\n## Removing Duplicates\n\n```python\n# Remove duplicate rows (keeps first occurrence)\ndf_unique = df.drop_duplicates()\n\n# Keep last occurrence instead\ndf_unique = df.drop_duplicates(keep='last')\n\n# Check for duplicates in specific columns only\ndf_unique = df.drop_duplicates(subset=['name'])\n```\n\n## Key Vocabulary\n\n| Term | Meaning |\n| --- | --- |\n| **Duplicate** | A row that exactly matches another row |\n| **drop_duplicates()** | Method to remove duplicate rows |\n| **keep** | Parameter to choose which duplicate to keep ('first' or 'last') |\n\n---\n\n## üéØ Your Task\n\nGiven a DataFrame with duplicate city/temperature entries, use `drop_duplicates()` to remove the duplicate rows. Print the unique DataFrame.\n",
    "starter_code": "import pandas as pd\n\ndf = pd.DataFrame({\n    'city': ['NYC', 'LA', 'NYC', 'Chicago', 'LA'],\n    'temp': [75, 85, 75, 65, 85]\n})\n\n# Remove duplicates\n",
    "solution_code": "import pandas as pd\n\ndf = pd.DataFrame({\n    'city': ['NYC', 'LA', 'NYC', 'Chicago', 'LA'],\n    'temp': [75, 85, 75, 65, 85]\n})\ndf_unique = df.drop_duplicates()\nprint(df_unique)",
    "expected_output": "      city  temp\n0      NYC    75\n1       LA    85\n3  Chicago    65",
    "order": 3
  },
  "122": {
    "id": 122,
    "title": "String Cleanup",
    "chapter_id": 96,
    "chapter_title": "Data Cleaning",
    "content": "# ‚úÇÔ∏è String Cleanup Methods\n\n## Definition\nReal-world text data is often messy‚Äîextra spaces, inconsistent capitalization, special characters. Pandas provides `.str` methods to clean strings efficiently.\n\n## Why String Cleanup Matters\n\n| Raw Data | Problem | Clean Data |\n| --- | --- | --- |\n| \"  Alice  \" | Extra spaces | \"Alice\" |\n| \"BOB\" + \"bob\" | Won't match! | \"Bob\" + \"Bob\" |\n| \"john DOE\" | Inconsistent | \"John Doe\" |\n\n## Real-World Analogy\n\nThink of string cleanup like a **spell checker**:\n- It finds formatting issues (extra spaces, wrong case)\n- It suggests corrections (strip, lowercase, etc.)\n- You apply the fix to the entire column at once\n\n## Common String Methods\n\n```python\nimport pandas as pd\n\ndf = pd.DataFrame({\n    'name': ['  Alice  ', 'BOB', 'carol  ']\n})\n\n# Strip whitespace from both ends\ndf['name'] = df['name'].str.strip()\n# ['Alice', 'BOB', 'carol']\n\n# Convert to lowercase\ndf['name'] = df['name'].str.lower()\n# ['alice', 'bob', 'carol']\n\n# Convert to uppercase\ndf['name'] = df['name'].str.upper()\n# ['ALICE', 'BOB', 'CAROL']\n\n# Convert to title case (first letter capitalized)\ndf['name'] = df['name'].str.title()\n# ['Alice', 'Bob', 'Carol']\n```\n\n## Chaining Methods\n\nYou can chain multiple string operations:\n\n```python\ndf['name'] = df['name'].str.strip().str.title()\n# ' john DOE ' ‚Üí 'John Doe'\n```\n\n## Key Vocabulary\n\n| Term | Meaning |\n| --- | --- |\n| **.str** | Accessor for string methods on a Series |\n| **strip()** | Remove leading/trailing whitespace |\n| **title()** | Capitalize first letter of each word |\n\n---\n\n## üéØ Your Task\n\nGiven names with extra whitespace and inconsistent capitalization, chain `.str.strip()` and `.str.title()` to clean them up. Print the result.\n",
    "starter_code": "import pandas as pd\n\ndf = pd.DataFrame({\n    'name': ['  john DOE  ', 'JANE smith', '  bob WILSON']\n})\n\n# Clean names\n",
    "solution_code": "import pandas as pd\n\ndf = pd.DataFrame({\n    'name': ['  john DOE  ', 'JANE smith', '  bob WILSON']\n})\ndf['name'] = df['name'].str.strip().str.title()\nprint(df)",
    "expected_output": "          name\n0     John Doe\n1   Jane Smith\n2   Bob Wilson",
    "order": 4
  },
  "123": {
    "id": 123,
    "title": "Type Conversion",
    "chapter_id": 96,
    "chapter_title": "Data Cleaning",
    "content": "# üîÑ Data Type Conversion with astype()\n\n## Definition\n**Data types** determine what operations you can perform. Numbers stored as strings can't be used for math! `astype()` converts columns to the correct type.\n\n## Why Types Matter\n\n| Data | Type | Problem |\n| --- | --- | --- |\n| \"25\" | String | Can't do: \"25\" + \"30\" = \"2530\" (concatenation!) |\n| 25 | Integer | Can do: 25 + 30 = 55 ‚úì |\n| \"2024-01-15\" | String | Can't calculate date differences |\n\n## Real-World Analogy\n\nThink of data types like **plug adapters**:\n- A European plug won't fit a US outlet\n- You need an adapter (type conversion) to make it work\n- `astype()` is your universal adapter!\n\n## Checking Current Types\n\n```python\nimport pandas as pd\n\ndf = pd.DataFrame({\n    'quantity': ['10', '20', '30'],  # Strings!\n    'price': [5.0, 10.0, 15.0]\n})\n\nprint(df.dtypes)\n# quantity    object   <- 'object' usually means string!\n# price       float64  <- Correct numeric type\n```\n\n## Converting Types\n\n```python\n# Convert to integer\ndf['quantity'] = df['quantity'].astype(int)\n\n# Convert to float\ndf['quantity'] = df['quantity'].astype(float)\n\n# Convert to string\ndf['price'] = df['price'].astype(str)\n\n# Now you can do math!\ndf['total'] = df['quantity'] * df['price']\n```\n\n## Key Vocabulary\n\n| Term | Meaning |\n| --- | --- |\n| **dtype** | The data type of a column |\n| **astype()** | Method to convert to a different type |\n| **object** | Pandas type for strings (and mixed types) |\n\n---\n\n## üéØ Your Task\n\nGiven quantities stored as strings, convert them to integers using `astype(int)`, then calculate the total (quantity √ó price) and print the sum.\n",
    "starter_code": "import pandas as pd\n\ndf = pd.DataFrame({\n    'item': ['Apple', 'Banana', 'Orange'],\n    'quantity': ['5', '10', '8'],\n    'price': [1.0, 0.5, 0.75]\n})\n\n# Convert and calculate\n",
    "solution_code": "import pandas as pd\n\ndf = pd.DataFrame({\n    'item': ['Apple', 'Banana', 'Orange'],\n    'quantity': ['5', '10', '8'],\n    'price': [1.0, 0.5, 0.75]\n})\ndf['quantity'] = df['quantity'].astype(int)\ndf['total'] = df['quantity'] * df['price']\nprint(df['total'].sum())",
    "expected_output": "16.0",
    "order": 5
  },
  "124": {
    "id": 124,
    "title": "üîç EDA Capstone",
    "chapter_id": 97,
    "chapter_title": "EDA Mini-Boss",
    "content": "# üö¢ EDA Capstone: Titanic Analysis\n\n## What is EDA?\n**Exploratory Data Analysis (EDA)** is the process of examining a dataset to understand its main characteristics‚Äîbefore building models or drawing conclusions.\n\n## Why This Dataset?\n\nThe Titanic dataset is the \"Hello World\" of data science. Every data scientist has analyzed it. You'll learn to:\n- Summarize data quickly\n- Calculate statistics by groups\n- Draw insights from numbers\n\n## Real-World Analogy\n\nThink of EDA like being a **detective**:\n- You examine the evidence (data)\n- You look for patterns (statistics)\n- You form hypotheses (insights)\n- You present your findings (reports)\n\n## The Dataset\n\nWe'll use a simplified Titanic-style dataset:\n- `survived`: 0 = Did not survive, 1 = Survived\n- `pclass`: Passenger class (1 = First, 2 = Second, 3 = Third)\n\n## Key EDA Techniques\n\n```python\nimport pandas as pd\n\n# 1. Check the size\nlen(df)  # Number of rows\n\n# 2. Calculate overall statistics\ndf['survived'].mean()  # Survival rate (0.0 to 1.0)\n\n# 3. Group by and aggregate\ndf.groupby('pclass')['survived'].mean()\n# Shows survival rate for each class\n```\n\n## What You'll Discover\n\nHistorical fact: **First-class passengers had much higher survival rates** than third-class passengers. Your analysis will reveal this pattern!\n\n## Key Vocabulary\n\n| Term | Meaning |\n| --- | --- |\n| **EDA** | Exploratory Data Analysis |\n| **groupby()** | Split data into groups for analysis |\n| **Aggregation** | Summarizing groups (mean, sum, count) |\n\n---\n\n## üéØ Your Mission\n\n1. Print the total number of passengers\n2. Calculate and print the overall survival rate (as a percentage)\n3. Print the survival rate by passenger class\n\n**Hint**: Use `df.groupby('pclass')['survived'].mean()` for step 3!\n",
    "starter_code": "import pandas as pd\n\ndf = pd.DataFrame({\n    'survived': [1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0],\n    'pclass': [1, 3, 3, 1, 3, 2, 1, 3, 3, 2, 3, 2]\n})\n\n# Analyze!\n",
    "solution_code": "import pandas as pd\n\ndf = pd.DataFrame({\n    'survived': [1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0],\n    'pclass': [1, 3, 3, 1, 3, 2, 1, 3, 3, 2, 3, 2]\n})\nprint(f\"Total passengers: {len(df)}\")\nprint(f\"Survival rate: {df['survived'].mean()*100:.1f}%\")\nprint(\"Survival by class:\")\nfor c, r in df.groupby('pclass')['survived'].mean().items():\n    print(f\"  Class {c}: {r*100:.1f}%\")",
    "expected_output": "Total passengers: 12\nSurvival rate: 41.7%\nSurvival by class:\n  Class 1: 100.0%\n  Class 2: 33.3%\n  Class 3: 0.0%",
    "order": 1
  },
  "125": {
    "id": 125,
    "title": "Creating Special Arrays",
    "chapter_id": 95,
    "chapter_title": "NumPy Fundamentals",
    "content": "# üî¢ Creating Special Arrays\n\n## Definition\nNumPy provides convenient functions to create arrays filled with specific values or patterns‚Äîwithout manually typing each element.\n\n## Why Special Arrays?\n\nWhen working with data science, you often need:\n- Arrays of zeros (for initialization)\n- Arrays of ones (for masks or scaling)\n- Ranges of numbers (for plotting x-axes)\n\n## Real-World Analogy\n\nThink of special arrays like **pre-printed forms**:\n- Instead of drawing 100 blank boxes, use a pre-printed template\n- NumPy's special functions are your templates!\n\n## Special Array Functions\n\n```python\nimport numpy as np\n\n# Array of zeros\nzeros = np.zeros(5)     # [0. 0. 0. 0. 0.]\nzeros_2d = np.zeros((2, 3))  # 2 rows, 3 columns of zeros\n\n# Array of ones\nones = np.ones(4)       # [1. 1. 1. 1.]\n\n# Array of a specific value\nfives = np.full(5, 5)   # [5 5 5 5 5]\n\n# Range of numbers\nrange_arr = np.arange(0, 10, 2)  # [0 2 4 6 8]\n\n# Evenly spaced numbers\nlinspace = np.linspace(0, 1, 5)  # [0. 0.25 0.5 0.75 1.]\n```\n\n## Key Vocabulary\n\n| Term | Meaning |\n| --- | --- |\n| **zeros()** | Create array filled with 0s |\n| **ones()** | Create array filled with 1s |\n| **arange()** | Create array with range (like Python's range) |\n| **linspace()** | Create array with evenly spaced values |\n\n---\n\n## üéØ Your Task\n\nCreate an array of 5 ones using `np.ones()` and print it.\n\n**Expected output**: `[1. 1. 1. 1. 1.]`\n",
    "starter_code": "import numpy as np\n\n# Create an array of 5 ones\n",
    "solution_code": "import numpy as np\n\n# Create an array of 5 ones\narr = np.ones(5)\nprint(arr)",
    "expected_output": "[1. 1. 1. 1. 1.]",
    "order": 2
  },
  "126": {
    "id": 126,
    "title": "Array Shapes and Dimensions",
    "chapter_id": 95,
    "chapter_title": "NumPy Fundamentals",
    "content": "# üìê Array Shapes and Dimensions\n\n## Definition\n**Shape** describes the size of each dimension of an array. **Dimensions** (or axes) are the number of directions in which the array extends.\n\n## Why Shape Matters\n\nUnderstanding shape is crucial for:\n- Debugging errors (\"shapes don't match!\")\n- Reshaping data for machine learning models\n- Understanding what operations are possible\n\n## Real-World Analogy\n\nThink of shape like describing a **box**:\n- 1D array: A line of boxes (just length)\n- 2D array: A grid of boxes (rows √ó columns)\n- 3D array: A cube of boxes (depth √ó rows √ó columns)\n\n## Checking Shape\n\n```python\nimport numpy as np\n\narr_1d = np.array([1, 2, 3, 4, 5])\nprint(arr_1d.shape)  # (5,) - 1D with 5 elements\n\narr_2d = np.array([[1, 2, 3], [4, 5, 6]])\nprint(arr_2d.shape)  # (2, 3) - 2 rows, 3 columns\n\nprint(arr_2d.ndim)   # 2 - number of dimensions\nprint(arr_2d.size)   # 6 - total number of elements\n```\n\n## Key Vocabulary\n\n| Term | Meaning |\n| --- | --- |\n| **shape** | Tuple describing array dimensions |\n| **ndim** | Number of dimensions (axes) |\n| **size** | Total number of elements |\n\n---\n\n## üéØ Your Task\n\nCreate the array `[10, 20, 30, 40]` and print its shape.\n\n**Expected output**: `(4,)`\n",
    "starter_code": "import numpy as np\n\n# Create array and print its shape\n",
    "solution_code": "import numpy as np\n\n# Create array and print its shape\narr = np.array([10, 20, 30, 40])\nprint(arr.shape)",
    "expected_output": "(4,)",
    "order": 3
  },
  "127": {
    "id": 127,
    "title": "Array Arithmetic",
    "chapter_id": 95,
    "chapter_title": "NumPy Fundamentals",
    "content": "# ‚ûï Array Arithmetic\n\n## Definition\nNumPy arrays support all standard arithmetic operations, applied element-by-element automatically.\n\n## Why Array Arithmetic?\n\nInstead of loops:\n```python\n# Slow Python way\nresult = []\nfor i in range(len(a)):\n    result.append(a[i] + b[i])\n```\n\nUse vectorized operations:\n```python\nresult = a + b  # Instant!\n```\n\n## Real-World Analogy\n\nImagine you're adjusting all prices in a store by 10%:\n- **Loop way**: Visit each item, calculate new price, update tag\n- **Vectorized way**: Apply formula to entire inventory at once!\n\n## All Operations\n\n```python\nimport numpy as np\n\na = np.array([10, 20, 30])\nb = np.array([1, 2, 3])\n\na + b   # [11 22 33] - Addition\na - b   # [ 9 18 27] - Subtraction\na * b   # [10 40 90] - Multiplication\na / b   # [10. 10. 10.] - Division\na // b  # [10 10 10] - Floor division\na % b   # [0 0 0] - Modulo\na ** b  # [10 400 27000] - Power\n```\n\n## Key Vocabulary\n\n| Term | Meaning |\n| --- | --- |\n| **Element-wise** | Operation on each corresponding pair |\n| **Operator overloading** | Standard operators work on arrays |\n\n---\n\n## üéØ Your Task\n\nCreate two arrays `[5, 10, 15]` and `[1, 2, 3]`, add them together, and print the result.\n\n**Expected output**: `[ 6 12 18]`\n",
    "starter_code": "import numpy as np\n\n# Create two arrays and add them\n",
    "solution_code": "import numpy as np\n\n# Create two arrays and add them\na = np.array([5, 10, 15])\nb = np.array([1, 2, 3])\nprint(a + b)",
    "expected_output": "[ 6 12 18]",
    "order": 5
  },
  "128": {
    "id": 128,
    "title": "Universal Functions (ufuncs)",
    "chapter_id": 95,
    "chapter_title": "NumPy Fundamentals",
    "content": "# ‚ö° Universal Functions (ufuncs)\n\n## Definition\n**Universal functions (ufuncs)** are NumPy functions that operate element-by-element on arrays, providing fast vectorized operations.\n\n## Why ufuncs?\n\nThey're optimized in C, making them much faster than Python loops for mathematical operations.\n\n## Real-World Analogy\n\nThink of ufuncs like a **parallel processor**:\n- Instead of calculating sin(x) for each value one at a time\n- Calculate sin() for ALL values simultaneously!\n\n## Common ufuncs\n\n```python\nimport numpy as np\n\narr = np.array([0, 30, 45, 60, 90])\nradians = np.radians(arr)  # Convert to radians\n\nnp.sin(radians)   # Sine of each element\nnp.cos(radians)   # Cosine of each element\nnp.sqrt(arr)      # Square root of each\nnp.exp(arr)       # e^x for each\nnp.log(arr + 1)   # Natural log (added 1 to avoid log(0))\nnp.abs(arr)       # Absolute value\n```\n\n## Practical Example\n\n```python\narr = np.array([1, 4, 9, 16, 25])\nsqrt_arr = np.sqrt(arr)  # [1. 2. 3. 4. 5.]\n```\n\n## Key Vocabulary\n\n| Term | Meaning |\n| --- | --- |\n| **ufunc** | Universal function - vectorized operation |\n| **np.sqrt()** | Square root of each element |\n| **np.abs()** | Absolute value of each element |\n\n---\n\n## üéØ Your Task\n\nCreate the array `[1, 4, 9, 16]` and print the square root of each element using `np.sqrt()`.\n\n**Expected output**: `[1. 2. 3. 4.]`\n",
    "starter_code": "import numpy as np\n\n# Create array and calculate square roots\n",
    "solution_code": "import numpy as np\n\n# Create array and calculate square roots\narr = np.array([1, 4, 9, 16])\nprint(np.sqrt(arr))",
    "expected_output": "[1. 2. 3. 4.]",
    "order": 6
  },
  "129": {
    "id": 129,
    "title": "Multiple Conditions",
    "chapter_id": 95,
    "chapter_title": "NumPy Fundamentals",
    "content": "# üîó Filtering with Multiple Conditions\n\n## Definition\nYou can combine multiple boolean conditions using `&` (and), `|` (or), and `~` (not) to create complex filters.\n\n## Why Multiple Conditions?\n\nReal data analysis often requires complex queries:\n- \"Sales greater than $100 AND in California\"\n- \"Age under 18 OR over 65\"\n\n## Important: Use & | ~ NOT and/or/not\n\n```python\nimport numpy as np\n\narr = np.array([5, 15, 25, 35, 45])\n\n# WRONG: and/or don't work with arrays\n# arr[(arr > 10) and (arr < 40)]  # Error!\n\n# CORRECT: Use & | ~\narr[(arr > 10) & (arr < 40)]  # [15 25 35]\narr[(arr < 10) | (arr > 40)]  # [5 45]\narr[~(arr > 20)]              # [5 15] (NOT greater than 20)\n```\n\n## Real-World Analogy\n\nThink of conditions like **layered filters**:\n- First filter: Keep items > 10\n- Second filter: Keep items < 40\n- Combined: Only items passing BOTH filters remain\n\n## Key Vocabulary\n\n| Term | Meaning |\n| --- | --- |\n| **&** | AND - both conditions must be true |\n| **\\|** | OR - at least one condition true |\n| **~** | NOT - inverts the condition |\n\n---\n\n## üéØ Your Task\n\nFrom `[2, 8, 15, 22, 30]`, select values that are greater than 5 AND less than 25. Print the result.\n\n**Expected output**: `[ 8 15 22]`\n",
    "starter_code": "import numpy as np\n\narr = np.array([2, 8, 15, 22, 30])\n\n# Filter: > 5 AND < 25\n",
    "solution_code": "import numpy as np\n\narr = np.array([2, 8, 15, 22, 30])\n\n# Filter: > 5 AND < 25\nresult = arr[(arr > 5) & (arr < 25)]\nprint(result)",
    "expected_output": "[ 8 15 22]",
    "order": 8
  },
  "130": {
    "id": 130,
    "title": "np.where() Conditional Selection",
    "chapter_id": 95,
    "chapter_title": "NumPy Fundamentals",
    "content": "# üîÄ Conditional Selection with np.where()\n\n## Definition\n`np.where()` returns indices where a condition is true, or can replace values based on a condition.\n\n## Why np.where()?\n\nIt's like Excel's IF function for arrays:\n- If condition is true ‚Üí use value A\n- If condition is false ‚Üí use value B\n\n## Real-World Analogy\n\nThink of `np.where()` like a **sorting hat**:\n- Check each student (element)\n- Send to Gryffindor (value A) or Slytherin (value B) based on criteria\n\n## Two Uses of np.where()\n\n```python\nimport numpy as np\n\narr = np.array([10, 25, 30, 15, 40])\n\n# Use 1: Get INDICES where condition is true\nindices = np.where(arr > 20)  # (array([1, 2, 4]),)\n\n# Use 2: Replace values conditionally\nresult = np.where(arr > 20, 'big', 'small')\n# ['small' 'big' 'big' 'small' 'big']\n\n# Use 3: Replace with calculated values\ndoubled = np.where(arr > 20, arr * 2, arr)\n# [10 50 60 15 80] - only values > 20 are doubled\n```\n\n## Key Vocabulary\n\n| Term | Meaning |\n| --- | --- |\n| **np.where(condition)** | Returns indices where True |\n| **np.where(cond, a, b)** | Returns a where True, b where False |\n\n---\n\n## üéØ Your Task\n\nGiven `[10, 20, 30, 40, 50]`, use `np.where()` to replace values > 25 with 100, and keep others unchanged. Print the result.\n\n**Expected output**: `[ 10  20 100 100 100]`\n",
    "starter_code": "import numpy as np\n\narr = np.array([10, 20, 30, 40, 50])\n\n# Replace values > 25 with 100\n",
    "solution_code": "import numpy as np\n\narr = np.array([10, 20, 30, 40, 50])\n\n# Replace values > 25 with 100\nresult = np.where(arr > 25, 100, arr)\nprint(result)",
    "expected_output": "[ 10  20 100 100 100]",
    "order": 9
  },
  "131": {
    "id": 131,
    "title": "Normalizing Data",
    "chapter_id": 95,
    "chapter_title": "NumPy Fundamentals",
    "content": "# üìè Normalizing Data (Min-Max Scaling)\n\n## Definition\n**Normalization** scales data to a specific range (usually 0-1). This is essential for machine learning where features need to be on similar scales.\n\n## Why Normalize?\n\n| Raw Data | Problem |\n| --- | --- |\n| Age: 0-100 | |\n| Income: 0-1,000,000 | Income dominates because of larger values! |\n\nAfter normalization, both range from 0 to 1.\n\n## Real-World Analogy\n\nThink of grading on a curve:\n- Raw scores: 45, 67, 89, 23\n- Normalized: Everyone scaled relative to highest score\n\n## Min-Max Normalization Formula\n\n```\nnormalized = (x - min) / (max - min)\n```\n\n```python\nimport numpy as np\n\ndata = np.array([10, 20, 30, 40, 50])\n\n# Normalize to 0-1 range\ndata_min = np.min(data)  # 10\ndata_max = np.max(data)  # 50\n\nnormalized = (data - data_min) / (data_max - data_min)\n# [0.   0.25 0.5  0.75 1.  ]\n```\n\n## Key Vocabulary\n\n| Term | Meaning |\n| --- | --- |\n| **Normalization** | Scaling to a standard range |\n| **Min-Max Scaling** | Scale to 0-1 based on min/max |\n| **Feature Scaling** | Making features comparable |\n\n---\n\n## üéØ Your Task\n\nNormalize `[0, 25, 50, 75, 100]` to the range 0-1 using min-max scaling. Print the result.\n\n**Expected output**: `[0.   0.25 0.5  0.75 1.  ]`\n",
    "starter_code": "import numpy as np\n\ndata = np.array([0, 25, 50, 75, 100])\n\n# Normalize to 0-1\n",
    "solution_code": "import numpy as np\n\ndata = np.array([0, 25, 50, 75, 100])\n\n# Normalize to 0-1\nnormalized = (data - np.min(data)) / (np.max(data) - np.min(data))\nprint(normalized)",
    "expected_output": "[0.   0.25 0.5  0.75 1.  ]",
    "order": 11
  },
  "132": {
    "id": 132,
    "title": "Standardizing Data (Z-Score)",
    "chapter_id": 95,
    "chapter_title": "NumPy Fundamentals",
    "content": "# üìä Standardizing Data (Z-Score)\n\n## Definition\n**Standardization** transforms data to have mean=0 and standard deviation=1. This is another common preprocessing step.\n\n## Why Standardize?\n\nZ-scores tell you how many standard deviations a value is from the mean:\n- Z = 0 ‚Üí exactly at the mean\n- Z = 1 ‚Üí one std deviation above mean\n- Z = -2 ‚Üí two std deviations below mean\n\n## Real-World Analogy\n\nComparing test scores from different classes:\n- Class A: Mean 70, your score 85 (you're +15 above mean)\n- Class B: Mean 50, your score 65 (you're +15 above mean too)\n- But which is more impressive? Z-scores tell you!\n\n## Z-Score Formula\n\n```\nz = (x - mean) / std\n```\n\n```python\nimport numpy as np\n\ndata = np.array([50, 60, 70, 80, 90])\n\nmean = np.mean(data)  # 70\nstd = np.std(data)    # 14.14\n\nz_scores = (data - mean) / std\n# [-1.41 -0.71  0.    0.71  1.41]\n```\n\n## Key Vocabulary\n\n| Term | Meaning |\n| --- | --- |\n| **Z-score** | How many std deviations from mean |\n| **Standardization** | Transform to mean=0, std=1 |\n| **Standard deviation** | Measure of spread |\n\n---\n\n## üéØ Your Task\n\nCalculate z-scores for `[60, 70, 80, 90, 100]`. Print the result rounded to 2 decimals.\n\n**Hint**: Use `np.round(result, 2)`\n",
    "starter_code": "import numpy as np\n\ndata = np.array([60, 70, 80, 90, 100])\n\n# Calculate z-scores\n",
    "solution_code": "import numpy as np\n\ndata = np.array([60, 70, 80, 90, 100])\n\n# Calculate z-scores\nmean = np.mean(data)\nstd = np.std(data)\nz_scores = (data - mean) / std\nprint(np.round(z_scores, 2))",
    "expected_output": "[-1.41 -0.71  0.    0.71  1.41]",
    "order": 12
  },
  "133": {
    "id": 133,
    "title": "Percentiles and Quartiles",
    "chapter_id": 95,
    "chapter_title": "NumPy Fundamentals",
    "content": "# üìà Percentiles and Quartiles\n\n## Definition\n**Percentiles** divide data into 100 equal parts. The p-th percentile is the value below which p% of data falls.\n\n## Why Percentiles?\n\n- \"You scored in the 90th percentile\" = You beat 90% of test takers\n- Quartiles (25th, 50th, 75th) are used in box plots\n- Detect outliers (values beyond 1.5√ó IQR)\n\n## Real-World Analogy\n\nImagine ranking all students by height:\n- 50th percentile = Median height (half are shorter)\n- 75th percentile = Taller than 75% of students\n- 25th percentile = Taller than only 25%\n\n## Using np.percentile()\n\n```python\nimport numpy as np\n\ndata = np.array([10, 20, 30, 40, 50, 60, 70, 80, 90, 100])\n\nnp.percentile(data, 50)  # 55.0 (median)\nnp.percentile(data, 25)  # 32.5 (Q1)\nnp.percentile(data, 75)  # 77.5 (Q3)\nnp.percentile(data, 90)  # 91.0 (90th percentile)\n```\n\n## Key Vocabulary\n\n| Term | Meaning |\n| --- | --- |\n| **Percentile** | Value below which X% of data falls |\n| **Quartile** | 25th (Q1), 50th (Q2/median), 75th (Q3) |\n| **IQR** | Interquartile Range = Q3 - Q1 |\n\n---\n\n## üéØ Your Task\n\nFind the 50th percentile (median) of `[10, 20, 30, 40, 50]` using `np.percentile()`. Print the result.\n\n**Expected output**: `30.0`\n",
    "starter_code": "import numpy as np\n\ndata = np.array([10, 20, 30, 40, 50])\n\n# Find 50th percentile\n",
    "solution_code": "import numpy as np\n\ndata = np.array([10, 20, 30, 40, 50])\n\n# Find 50th percentile\nresult = np.percentile(data, 50)\nprint(result)",
    "expected_output": "30.0",
    "order": 14
  },
  "134": {
    "id": 134,
    "title": "Variance and Standard Deviation",
    "chapter_id": 95,
    "chapter_title": "NumPy Fundamentals",
    "content": "# üìâ Variance and Standard Deviation\n\n## Definition\n**Variance** measures how spread out data is from the mean. **Standard deviation** is the square root of variance.\n\n## Why Measure Spread?\n\nTwo datasets can have the same mean but very different spreads:\n- Dataset A: [50, 50, 50, 50, 50] ‚Üí Mean=50, Std=0 (no spread)\n- Dataset B: [0, 25, 50, 75, 100] ‚Üí Mean=50, Std=35.4 (high spread)\n\n## Real-World Analogy\n\nImagine two pizza delivery services:\n- Both average 30 minutes delivery time\n- Service A: Always exactly 30 min (low std)\n- Service B: Sometimes 10 min, sometimes 50 min (high std)\n\nWhich is more reliable?\n\n## Calculating in NumPy\n\n```python\nimport numpy as np\n\ndata = np.array([2, 4, 6, 8, 10])\n\nvariance = np.var(data)  # 8.0\nstd_dev = np.std(data)   # 2.83\n\n# Verify: std = sqrt(variance)\nprint(np.sqrt(variance))  # 2.83\n```\n\n## Key Vocabulary\n\n| Term | Meaning |\n| --- | --- |\n| **Variance** | Average of squared deviations from mean |\n| **Std Deviation** | Square root of variance (same units as data) |\n| **Spread** | How dispersed the data is |\n\n---\n\n## üéØ Your Task\n\nCalculate the standard deviation of `[20, 40, 60, 80, 100]` using `np.std()`. Print the result.\n\n**Expected output**: `28.284271247461902`\n",
    "starter_code": "import numpy as np\n\ndata = np.array([20, 40, 60, 80, 100])\n\n# Calculate standard deviation\n",
    "solution_code": "import numpy as np\n\ndata = np.array([20, 40, 60, 80, 100])\n\n# Calculate standard deviation\nresult = np.std(data)\nprint(result)",
    "expected_output": "28.284271247461902",
    "order": 15
  },
  "135": {
    "id": 135,
    "title": "Counting Missing Values",
    "chapter_id": 96,
    "chapter_title": "Data Cleaning",
    "content": "# üî¢ Counting Missing Values\n\n## Definition\nBefore cleaning, you need to know HOW MUCH data is missing. `isnull().sum()` counts missing values per column.\n\n## Why Count First?\n\n- If 1% missing ‚Üí probably safe to drop\n- If 50% missing ‚Üí dropping loses too much data, consider filling\n- If a column is 90% missing ‚Üí maybe drop the column entirely!\n\n## Real-World Analogy\n\nBefore deciding how to fix a survey:\n- Check: How many questions were skipped?\n- Few skips ‚Üí remove incomplete surveys\n- Many skips on one question ‚Üí maybe that question was confusing\n\n## Counting Techniques\n\n```python\nimport pandas as pd\n\ndf = pd.DataFrame({\n    'A': [1, None, 3, None],\n    'B': [None, 2, 3, 4],\n    'C': [1, 2, 3, 4]\n})\n\n# Count missing per column\nprint(df.isnull().sum())\n# A    2\n# B    1\n# C    0\n\n# Total missing in entire DataFrame\nprint(df.isnull().sum().sum())  # 3\n\n# Percentage missing per column\nprint(df.isnull().mean() * 100)\n# A    50.0\n# B    25.0\n# C     0.0\n```\n\n## Key Vocabulary\n\n| Term | Meaning |\n| --- | --- |\n| **isnull()** | Returns True for each missing value |\n| **sum()** | Counts True values (missing count) |\n| **mean()** | Proportion of missing values |\n\n---\n\n## üéØ Your Task\n\nCount the total number of missing values in the DataFrame. Print the count.\n",
    "starter_code": "import pandas as pd\n\ndf = pd.DataFrame({\n    'name': ['Alice', None, 'Carol'],\n    'age': [25, 30, None],\n    'city': [None, 'NYC', 'LA']\n})\n\n# Count total missing values\n",
    "solution_code": "import pandas as pd\n\ndf = pd.DataFrame({\n    'name': ['Alice', None, 'Carol'],\n    'age': [25, 30, None],\n    'city': [None, 'NYC', 'LA']\n})\n\n# Count total missing values\ntotal_missing = df.isnull().sum().sum()\nprint(total_missing)",
    "expected_output": "3",
    "order": 2
  },
  "136": {
    "id": 136,
    "title": "Dropping Columns with Missing Data",
    "chapter_id": 96,
    "chapter_title": "Data Cleaning",
    "content": "# üóëÔ∏è Dropping Columns with Missing Data\n\n## Definition\nSometimes it's better to drop an entire COLUMN rather than rows‚Äîespecially if a column has too many missing values.\n\n## When to Drop Columns?\n\n| Scenario | Action |\n| --- | --- |\n| Column 80%+ missing | Drop the column |\n| Column has few unique values | Consider dropping |\n| Column not needed for analysis | Drop it |\n\n## Real-World Analogy\n\nImagine a form with an optional \"Comments\" field:\n- If 90% of people skip it, that column isn't useful\n- Better to remove it than lose 90% of your data!\n\n## How to Drop Columns\n\n```python\nimport pandas as pd\n\ndf = pd.DataFrame({\n    'A': [1, 2, 3],\n    'B': [None, None, 3],  # Mostly missing!\n    'C': [1, 2, 3]\n})\n\n# Drop columns with ANY missing values\ndf_clean = df.dropna(axis=1)\n# Only columns A and C remain\n\n# Drop columns where > 50% is missing\nthreshold = len(df) * 0.5\ndf_clean = df.dropna(axis=1, thresh=threshold)\n```\n\n## Key Vocabulary\n\n| Term | Meaning |\n| --- | --- |\n| **axis=0** | Operate on rows (default) |\n| **axis=1** | Operate on columns |\n| **thresh** | Minimum non-NA values required |\n\n---\n\n## üéØ Your Task\n\nDrop any columns that have ANY missing values and print the result.\n",
    "starter_code": "import pandas as pd\n\ndf = pd.DataFrame({\n    'product': ['Apple', 'Banana', 'Cherry'],\n    'price': [1.0, None, 1.5],\n    'quantity': [10, 20, 30]\n})\n\n# Drop columns with missing values\n",
    "solution_code": "import pandas as pd\n\ndf = pd.DataFrame({\n    'product': ['Apple', 'Banana', 'Cherry'],\n    'price': [1.0, None, 1.5],\n    'quantity': [10, 20, 30]\n})\n\n# Drop columns with missing values\ndf_clean = df.dropna(axis=1)\nprint(df_clean)",
    "expected_output": "  product  quantity\n0   Apple        10\n1  Banana        20\n2  Cherry        30",
    "order": 3
  },
  "137": {
    "id": 137,
    "title": "Filling with Mode (Most Common)",
    "chapter_id": 96,
    "chapter_title": "Data Cleaning",
    "content": "# üî§ Filling with Mode\n\n## Definition\nFor **categorical data** (like colors, cities, categories), use the **mode** (most frequent value) to fill missing values.\n\n## Why Mode for Categories?\n\n- Mean doesn't work: What's the average of \"Red\", \"Blue\", \"Green\"?\n- Mode = most common value = reasonable guess\n\n## Real-World Analogy\n\nFilling in a missing survey answer about favorite color:\n- If 60% said \"Blue\", 30% said \"Red\", 10% said \"Green\"\n- Best guess for missing answer: \"Blue\" (the mode)\n\n## Using Mode\n\n```python\nimport pandas as pd\n\ndf = pd.DataFrame({\n    'color': ['Red', 'Blue', 'Blue', None, 'Blue', None]\n})\n\n# Find the mode (most common value)\nmode_color = df['color'].mode()[0]  # 'Blue'\n\n# Fill missing with mode\ndf['color'] = df['color'].fillna(mode_color)\n# Now all None become 'Blue'\n```\n\n## Key Vocabulary\n\n| Term | Meaning |\n| --- | --- |\n| **Mode** | Most frequently occurring value |\n| **Categorical** | Data with discrete categories |\n| **mode()[0]** | First mode (in case of ties) |\n\n---\n\n## üéØ Your Task\n\nFill missing cities with the mode (most common city). Print the result.\n",
    "starter_code": "import pandas as pd\n\ndf = pd.DataFrame({\n    'name': ['Alice', 'Bob', 'Carol', 'David'],\n    'city': ['NYC', 'NYC', None, 'LA']\n})\n\n# Fill missing cities with mode\n",
    "solution_code": "import pandas as pd\n\ndf = pd.DataFrame({\n    'name': ['Alice', 'Bob', 'Carol', 'David'],\n    'city': ['NYC', 'NYC', None, 'LA']\n})\n\n# Fill missing cities with mode\nmode_city = df['city'].mode()[0]\ndf['city'] = df['city'].fillna(mode_city)\nprint(df)",
    "expected_output": "    name city\n0  Alice  NYC\n1    Bob  NYC\n2  Carol  NYC\n3  David   LA",
    "order": 5
  },
  "138": {
    "id": 138,
    "title": "Filling with Median",
    "chapter_id": 96,
    "chapter_title": "Data Cleaning",
    "content": "# üìä Filling with Median\n\n## Definition\nFor **numeric data with outliers**, use the **median** (middle value) instead of mean‚Äîit's more robust!\n\n## Why Median Over Mean?\n\n| Data | Mean | Median |\n| --- | --- | --- |\n| [10, 20, 30, 40, 50] | 30 | 30 |\n| [10, 20, 30, 40, 500] | 120 | 30 |\n\nThe outlier (500) skews the mean but not the median!\n\n## Real-World Analogy\n\nHouse prices in a neighborhood:\n- Most houses: $300K-$400K\n- One mansion: $10 million\n- Mean price: ~$1.2 million (misleading!)\n- Median price: ~$350K (realistic)\n\n## Using Median\n\n```python\nimport pandas as pd\n\ndf = pd.DataFrame({\n    'salary': [50000, 55000, None, 60000, 500000]  # Has outlier!\n})\n\n# Compare mean vs median\nprint(df['salary'].mean())    # 166250 (skewed by outlier)\nprint(df['salary'].median())  # 57500 (robust)\n\n# Fill with median\ndf['salary'] = df['salary'].fillna(df['salary'].median())\n```\n\n## Key Vocabulary\n\n| Term | Meaning |\n| --- | --- |\n| **Median** | Middle value when sorted |\n| **Robust** | Not affected by outliers |\n| **Outlier** | Extreme value far from others |\n\n---\n\n## üéØ Your Task\n\nFill the missing salary with the median (not mean). Print the DataFrame.\n",
    "starter_code": "import pandas as pd\n\ndf = pd.DataFrame({\n    'employee': ['Alice', 'Bob', 'Carol'],\n    'salary': [50000.0, None, 70000.0]\n})\n\n# Fill with median\n",
    "solution_code": "import pandas as pd\n\ndf = pd.DataFrame({\n    'employee': ['Alice', 'Bob', 'Carol'],\n    'salary': [50000.0, None, 70000.0]\n})\n\n# Fill with median\nmedian_salary = df['salary'].median()\ndf['salary'] = df['salary'].fillna(median_salary)\nprint(df)",
    "expected_output": "  employee   salary\n0    Alice  50000.0\n1      Bob  60000.0\n2    Carol  70000.0",
    "order": 6
  },
  "139": {
    "id": 139,
    "title": "Finding Duplicate Rows",
    "chapter_id": 96,
    "chapter_title": "Data Cleaning",
    "content": "# üîç Finding Duplicate Rows\n\n## Definition\n`duplicated()` returns True for each row that is a duplicate of a previous row.\n\n## Why Find Before Removing?\n\n- Understand how many duplicates exist\n- Investigate WHY there are duplicates (data entry error? intentional?)\n- Decide which copy to keep\n\n## Real-World Analogy\n\nBefore deleting duplicate contacts:\n- First, find them: \"You have 5 duplicate contacts\"\n- Review them: Are they really duplicates or different people?\n- Then decide: Keep the most recent version\n\n## Finding Duplicates\n\n```python\nimport pandas as pd\n\ndf = pd.DataFrame({\n    'name': ['Alice', 'Bob', 'Alice', 'Carol'],\n    'age': [25, 30, 25, 28]\n})\n\n# Mark duplicates\nprint(df.duplicated())\n# 0    False\n# 1    False\n# 2     True  <- duplicate!\n# 3    False\n\n# View the duplicate rows\nprint(df[df.duplicated()])\n#     name  age\n# 2  Alice   25\n\n# Count duplicates\nprint(df.duplicated().sum())  # 1\n```\n\n## Key Vocabulary\n\n| Term | Meaning |\n| --- | --- |\n| **duplicated()** | Returns True for duplicate rows |\n| **keep='first'** | First occurrence is NOT a duplicate |\n| **keep='last'** | Last occurrence is NOT a duplicate |\n\n---\n\n## üéØ Your Task\n\nCount the number of duplicate rows in the DataFrame. Print the count.\n",
    "starter_code": "import pandas as pd\n\ndf = pd.DataFrame({\n    'item': ['Apple', 'Banana', 'Apple', 'Orange', 'Banana'],\n    'price': [1.0, 0.5, 1.0, 0.75, 0.5]\n})\n\n# Count duplicates\n",
    "solution_code": "import pandas as pd\n\ndf = pd.DataFrame({\n    'item': ['Apple', 'Banana', 'Apple', 'Orange', 'Banana'],\n    'price': [1.0, 0.5, 1.0, 0.75, 0.5]\n})\n\n# Count duplicates\ncount = df.duplicated().sum()\nprint(count)",
    "expected_output": "2",
    "order": 8
  },
  "140": {
    "id": 140,
    "title": "Duplicates in Specific Columns",
    "chapter_id": 96,
    "chapter_title": "Data Cleaning",
    "content": "# üéØ Duplicates in Specific Columns\n\n## Definition\nSometimes you want to find duplicates based on only CERTAIN columns, not all columns.\n\n## When to Use Subset?\n\n| Scenario | Approach |\n| --- | --- |\n| Same person, different info | Check 'email' only |\n| Same product, different dates | Check 'product_id' only |\n| Exact duplicate rows | Check all columns |\n\n## Real-World Analogy\n\nCustomer database with email duplicates:\n- Same email might have different addresses (they moved!)\n- We want unique CUSTOMERS (by email), not unique rows\n\n## Using subset Parameter\n\n```python\nimport pandas as pd\n\ndf = pd.DataFrame({\n    'email': ['a@b.com', 'c@d.com', 'a@b.com'],\n    'name': ['Alice', 'Bob', 'Alice Smith'],  # Names differ!\n    'city': ['NYC', 'LA', 'Boston']\n})\n\n# Duplicates considering ALL columns ‚Üí None (rows differ)\nprint(df.duplicated().sum())  # 0\n\n# Duplicates considering only email\nprint(df.duplicated(subset=['email']).sum())  # 1\n\n# Keep only unique emails\ndf_unique = df.drop_duplicates(subset=['email'])\n```\n\n## Key Vocabulary\n\n| Term | Meaning |\n| --- | --- |\n| **subset** | List of columns to check for duplicates |\n| **keep='first'** | Keep first occurrence of duplicate |\n\n---\n\n## üéØ Your Task\n\nRemove duplicates based only on the 'product' column (keep first). Print the result.\n",
    "starter_code": "import pandas as pd\n\ndf = pd.DataFrame({\n    'product': ['Apple', 'Banana', 'Apple'],\n    'price': [1.00, 0.50, 1.25],\n    'store': ['A', 'B', 'C']\n})\n\n# Remove duplicates by product only\n",
    "solution_code": "import pandas as pd\n\ndf = pd.DataFrame({\n    'product': ['Apple', 'Banana', 'Apple'],\n    'price': [1.00, 0.50, 1.25],\n    'store': ['A', 'B', 'C']\n})\n\n# Remove duplicates by product only\ndf_unique = df.drop_duplicates(subset=['product'])\nprint(df_unique)",
    "expected_output": "  product  price store\n0   Apple   1.00     A\n1  Banana   0.50     B",
    "order": 9
  },
  "141": {
    "id": 141,
    "title": "String Replace and Contains",
    "chapter_id": 96,
    "chapter_title": "Data Cleaning",
    "content": "# üîÑ String Replace and Contains\n\n## Definition\n`str.replace()` replaces text patterns. `str.contains()` checks if a pattern exists in strings.\n\n## Why These Methods?\n\n- Clean up inconsistent formatting (\"$100\" ‚Üí \"100\")\n- Find rows matching a pattern (\"Find all Gmail users\")\n- Standardize data (\"USA\", \"U.S.A.\", \"United States\" ‚Üí \"USA\")\n\n## Real-World Analogy\n\nFind-and-replace in a word processor:\n- Find all instances of \"colour\" and replace with \"color\"\n- Or find all lines containing \"ERROR\" in a log file\n\n## Using str.replace()\n\n```python\nimport pandas as pd\n\ndf = pd.DataFrame({\n    'price': ['$10', '$25', '$50']\n})\n\n# Remove the $ symbol\ndf['price'] = df['price'].str.replace('$', '', regex=False)\n# ['10', '25', '50']\n\n# For patterns, use regex=True\ndf['text'] = df['text'].str.replace(r'\\d+', 'NUM', regex=True)\n```\n\n## Using str.contains()\n\n```python\ndf = pd.DataFrame({\n    'email': ['alice@gmail.com', 'bob@yahoo.com', 'carol@gmail.com']\n})\n\n# Find Gmail users\ngmail_mask = df['email'].str.contains('gmail')\ngmail_users = df[gmail_mask]\n```\n\n## Key Vocabulary\n\n| Term | Meaning |\n| --- | --- |\n| **str.replace()** | Replace substring with another |\n| **str.contains()** | Check if substring exists |\n| **regex** | Regular expression pattern matching |\n\n---\n\n## üéØ Your Task\n\nRemove the \"$\" from all prices and print the DataFrame.\n",
    "starter_code": "import pandas as pd\n\ndf = pd.DataFrame({\n    'item': ['Apple', 'Banana', 'Orange'],\n    'price': ['$1.00', '$0.50', '$0.75']\n})\n\n# Remove $ from prices\n",
    "solution_code": "import pandas as pd\n\ndf = pd.DataFrame({\n    'item': ['Apple', 'Banana', 'Orange'],\n    'price': ['$1.00', '$0.50', '$0.75']\n})\n\n# Remove $ from prices\ndf['price'] = df['price'].str.replace('$', '', regex=False)\nprint(df)",
    "expected_output": "     item price\n0   Apple  1.00\n1  Banana  0.50\n2  Orange  0.75",
    "order": 11
  },
  "142": {
    "id": 142,
    "title": "Splitting Strings",
    "chapter_id": 96,
    "chapter_title": "Data Cleaning",
    "content": "# ‚úÇÔ∏è Splitting Strings\n\n## Definition\n`str.split()` breaks strings into parts. Combined with `expand=True`, it creates new columns.\n\n## Why Split Strings?\n\n- Names: \"John Doe\" ‚Üí \"John\" + \"Doe\"\n- Addresses: \"123 Main St, NYC\" ‚Üí Street + City\n- Dates: \"2024-01-15\" ‚Üí Year + Month + Day\n\n## Real-World Analogy\n\nImagine a phone number \"555-123-4567\":\n- Split by \"-\" to get: area code, exchange, number\n- Now you can analyze by area code!\n\n## Splitting into New Columns\n\n```python\nimport pandas as pd\n\ndf = pd.DataFrame({\n    'full_name': ['Alice Smith', 'Bob Jones', 'Carol White']\n})\n\n# Split and create new columns\ndf[['first', 'last']] = df['full_name'].str.split(' ', expand=True)\n#   full_name   first   last\n# 0  Alice Smith  Alice  Smith\n# 1   Bob Jones    Bob  Jones\n# 2  Carol White  Carol  White\n```\n\n## Extracting Specific Parts\n\n```python\n# Get just the first part (index 0)\ndf['first'] = df['full_name'].str.split(' ').str[0]\n\n# Get just the last part (index -1)\ndf['last'] = df['full_name'].str.split(' ').str[-1]\n```\n\n## Key Vocabulary\n\n| Term | Meaning |\n| --- | --- |\n| **str.split()** | Split string by delimiter |\n| **expand=True** | Return DataFrame instead of Series |\n| **.str[n]** | Get n-th element after splitting |\n\n---\n\n## üéØ Your Task\n\nSplit full names into first and last names. Print only the first names.\n",
    "starter_code": "import pandas as pd\n\ndf = pd.DataFrame({\n    'name': ['John Doe', 'Jane Smith', 'Bob Wilson']\n})\n\n# Extract first names\n",
    "solution_code": "import pandas as pd\n\ndf = pd.DataFrame({\n    'name': ['John Doe', 'Jane Smith', 'Bob Wilson']\n})\n\n# Extract first names\ndf['first_name'] = df['name'].str.split(' ').str[0]\nprint(df['first_name'])",
    "expected_output": "0    John\n1    Jane\n2     Bob\nName: first_name, dtype: object",
    "order": 12
  },
  "143": {
    "id": 143,
    "title": "Converting Dates",
    "chapter_id": 96,
    "chapter_title": "Data Cleaning",
    "content": "# üìÖ Converting Date Strings\n\n## Definition\n`pd.to_datetime()` converts strings to datetime objects, enabling date calculations.\n\n## Why Convert Dates?\n\n| As String | As Datetime |\n| --- | --- |\n| Can't calculate difference | \"2024-01-15\" - \"2024-01-01\" = 14 days |\n| Can't extract year/month | .dt.year extracts 2024 |\n| Sorting is alphabetical | Sorting is chronological |\n\n## Real-World Analogy\n\nA calendar app can't schedule events from text \"January 15\":\n- It needs to understand it's a DATE\n- Then it can calculate \"3 days until event\"\n\n## Using to_datetime()\n\n```python\nimport pandas as pd\n\ndf = pd.DataFrame({\n    'date_str': ['2024-01-15', '2024-02-20', '2024-03-10']\n})\n\n# Convert to datetime\ndf['date'] = pd.to_datetime(df['date_str'])\n\n# Now you can use .dt accessor\ndf['year'] = df['date'].dt.year      # 2024, 2024, 2024\ndf['month'] = df['date'].dt.month    # 1, 2, 3\ndf['day'] = df['date'].dt.day        # 15, 20, 10\ndf['weekday'] = df['date'].dt.day_name()  # Monday, Tuesday, etc.\n```\n\n## Key Vocabulary\n\n| Term | Meaning |\n| --- | --- |\n| **to_datetime()** | Convert strings to datetime |\n| **.dt** | Accessor for datetime properties |\n| **datetime64** | NumPy/Pandas date type |\n\n---\n\n## üéØ Your Task\n\nConvert the date strings to datetime and extract just the month. Print the months.\n",
    "starter_code": "import pandas as pd\n\ndf = pd.DataFrame({\n    'date': ['2024-03-15', '2024-06-20', '2024-09-01']\n})\n\n# Convert to datetime and extract month\n",
    "solution_code": "import pandas as pd\n\ndf = pd.DataFrame({\n    'date': ['2024-03-15', '2024-06-20', '2024-09-01']\n})\n\n# Convert to datetime and extract month\ndf['date'] = pd.to_datetime(df['date'])\nprint(df['date'].dt.month)",
    "expected_output": "0    3\n1    6\n2    9\nName: date, dtype: int32",
    "order": 14
  },
  "144": {
    "id": 144,
    "title": "Handling Conversion Errors",
    "chapter_id": 96,
    "chapter_title": "Data Cleaning",
    "content": "# ‚ö†Ô∏è Handling Conversion Errors\n\n## Definition\nWhen converting types, some values might fail (e.g., \"N/A\" can't become a number). Use `errors` parameter to handle gracefully.\n\n## Why Handle Errors?\n\nReal data has messy values:\n- \"12.5\" ‚Üí fine\n- \"N/A\" ‚Üí can't convert to float!\n- \"unknown\" ‚Üí can't convert!\n\nWithout error handling, your code crashes.\n\n## Real-World Analogy\n\nA calculator that crashes on invalid input is useless:\n- Better: Show \"Error\" for that entry\n- Or: Skip that row and continue\n\n## Error Handling Options\n\n```python\nimport pandas as pd\n\ndf = pd.DataFrame({\n    'value': ['10', '20', 'N/A', '40']\n})\n\n# errors='raise' (default) - crashes on bad data\n# df['value'].astype(float)  # Error!\n\n# errors='coerce' - bad values become NaN\ndf['value'] = pd.to_numeric(df['value'], errors='coerce')\n# [10.0, 20.0, NaN, 40.0]\n\n# errors='ignore' - leave bad values as-is\ndf['value'] = pd.to_numeric(df['value'], errors='ignore')\n```\n\n## Key Vocabulary\n\n| Term | Meaning |\n| --- | --- |\n| **errors='raise'** | Raise exception on bad data |\n| **errors='coerce'** | Convert bad data to NaN |\n| **errors='ignore'** | Leave bad data unchanged |\n\n---\n\n## üéØ Your Task\n\nConvert the values to numeric, using `errors='coerce'` to handle non-numeric values. Print the result.\n",
    "starter_code": "import pandas as pd\n\ndf = pd.DataFrame({\n    'quantity': ['10', '20', 'unknown', '30']\n})\n\n# Convert to numeric with error handling\n",
    "solution_code": "import pandas as pd\n\ndf = pd.DataFrame({\n    'quantity': ['10', '20', 'unknown', '30']\n})\n\n# Convert to numeric with error handling\ndf['quantity'] = pd.to_numeric(df['quantity'], errors='coerce')\nprint(df['quantity'])",
    "expected_output": "0    10.0\n1    20.0\n2     NaN\n3    30.0\nName: quantity, dtype: float64",
    "order": 15
  },
  "1001": {
    "id": 1001,
    "title": "What is a Database?",
    "content": "# üóÉÔ∏è What is a Database?\n\n## Definition\n\nA **database** is an organized collection of data stored electronically. Think of it as a digital filing cabinet where information is stored in a structured way so you can easily find, update, and manage it.\n\n## Why Do We Need Databases?\n\n| Without Database | With Database |\n| --- | --- |\n| Data in scattered files | Data in one organized place |\n| Hard to find information | Fast searching |\n| Duplicate data everywhere | Single source of truth |\n| Multiple people can't edit | Concurrent access |\n\n## Real-World Examples\n\n- **E-commerce**: Products, orders, customers\n- **Social Media**: Users, posts, likes, comments\n- **Banking**: Accounts, transactions, balances\n- **Healthcare**: Patients, appointments, records\n\n## Types of Databases\n\n| Type | Description | Example |\n| --- | --- | --- |\n| **Relational (SQL)** | Data in tables with relationships | PostgreSQL, MySQL |\n| **NoSQL** | Flexible structure | MongoDB, Redis |\n| **Data Warehouse** | Optimized for analytics | Snowflake, BigQuery |\n\nIn this course, we focus on **SQL databases** - the most common type for business data.\n\n---\n\n## üéØ Your Task\n\nWrite a SELECT statement that returns the text 'Hello, SQL!'.\n",
    "starter_code": "-- Your first SQL query!\n-- SELECT is used to retrieve data\n\nSELECT 'Hello, SQL!';",
    "solution_code": "SELECT 'Hello, SQL!';",
    "expected_output": "Hello, SQL!",
    "chapter_id": 200,
    "chapter_title": "Setup & Mental Model"
  },
  "1002": {
    "id": 1002,
    "title": "Tables, Rows, and Columns",
    "content": "# üìä Tables, Rows, and Columns\n\n## The Building Blocks\n\nSQL databases organize data into **tables**:\n\n```\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ              employees                   ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ id   ‚îÇ name       ‚îÇ role    ‚îÇ salary    ‚îÇ  ‚Üê Column names\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ 1    ‚îÇ Alice      ‚îÇ Analyst ‚îÇ 75000     ‚îÇ  ‚Üê Row 1\n‚îÇ 2    ‚îÇ Bob        ‚îÇ Manager ‚îÇ 90000     ‚îÇ  ‚Üê Row 2\n‚îÇ 3    ‚îÇ Charlie    ‚îÇ Analyst ‚îÇ 72000     ‚îÇ  ‚Üê Row 3\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n```\n\n## Key Terminology\n\n| Term | Also Called | Definition |\n| --- | --- | --- |\n| **Table** | Relation | A collection of related data |\n| **Row** | Record, Tuple | One complete entry |\n| **Column** | Field, Attribute | A specific piece of data |\n\n## Important Rules\n\n1. Each column has a **data type** (text, number, date)\n2. Each row should be **unique** (identified by a key)\n3. Column names should be **descriptive**\n4. Tables should represent **one concept** (employees, orders, products)\n\n---\n\n## üéØ Your Task\n\nSelect all columns from the employees table using SELECT *.\n",
    "starter_code": "-- The employees table has: id, name, department, salary\n-- Use SELECT * to get all columns\n\n",
    "solution_code": "SELECT * FROM employees;",
    "expected_output": "id | name    | department | salary\n1  | Alice   | Sales      | 75000\n2  | Bob     | Marketing  | 90000\n3  | Charlie | Sales      | 72000",
    "chapter_id": 200,
    "chapter_title": "Setup & Mental Model"
  },
  "1003": {
    "id": 1003,
    "title": "Primary Keys",
    "content": "# üîë Primary Keys\n\n## What is a Primary Key?\n\nA **primary key** is a column (or combination of columns) that uniquely identifies each row in a table. No two rows can have the same primary key value.\n\n## Why Are Primary Keys Essential?\n\n```\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ id   ‚îÇ name       ‚îÇ email       ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ 1    ‚îÇ Alice      ‚îÇ a@mail.com  ‚îÇ  ‚Üê id=1 is unique!\n‚îÇ 2    ‚îÇ Alice      ‚îÇ b@mail.com  ‚îÇ  ‚Üê Same name, different id\n‚îÇ 3    ‚îÇ Bob        ‚îÇ c@mail.com  ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n  ‚Üë\n  Primary Key (PK)\n```\n\n## Primary Key Rules\n\n1. **Unique**: No duplicate values allowed\n2. **Not NULL**: Must always have a value\n3. **Immutable**: Should rarely change\n4. **Simple**: Often an auto-incrementing integer\n\n## Common Primary Key Patterns\n\n| Pattern | Example | Use Case |\n| --- | --- | --- |\n| Auto-increment | 1, 2, 3, 4... | Most common |\n| UUID | 'a1b2c3d4-...' | Distributed systems |\n| Natural key | 'USA', 'CAN' | Country codes |\n\n---\n\n## üéØ Your Task\n\nSelect the id and name columns from customers table.\n",
    "starter_code": "-- customers table has: id (primary key), name, email, city\n-- Select just id and name\n\n",
    "solution_code": "SELECT id, name FROM customers;",
    "expected_output": "id | name\n1  | Alice\n2  | Bob\n3  | Charlie",
    "chapter_id": 200,
    "chapter_title": "Setup & Mental Model"
  },
  "1004": {
    "id": 1004,
    "title": "Foreign Keys & Relationships",
    "content": "# üîó Foreign Keys & Relationships\n\n## Connecting Tables Together\n\nA **foreign key** is a column that references the primary key of another table. This creates a **relationship** between tables.\n\n```\n‚îå‚îÄ customers ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê       ‚îå‚îÄ orders ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ id ‚îÇ name          ‚îÇ       ‚îÇ id ‚îÇ customer_id ‚îÇ amount  ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§       ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ 1  ‚îÇ Alice         ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ 1  ‚îÇ 1           ‚îÇ 99.99   ‚îÇ\n‚îÇ 2  ‚îÇ Bob           ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ 2  ‚îÇ 1           ‚îÇ 149.99  ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ 3  ‚îÇ 2           ‚îÇ 49.99   ‚îÇ\n  PK                    ‚îÇ    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n                        ‚îÇ              FK\n                        ‚îî‚îÄ‚îÄ References customers.id\n```\n\n## Why Use Foreign Keys?\n\n1. **Avoid duplication**: Store customer info once, reference it many times\n2. **Data integrity**: Can't create an order for a non-existent customer\n3. **Enable JOINs**: Combine data from multiple tables\n\n## Relationship Types\n\n| Type | Example |\n| --- | --- |\n| **One-to-Many** | One customer has many orders |\n| **One-to-One** | One user has one profile |\n| **Many-to-Many** | Students enrolled in courses |\n\n---\n\n## üéØ Your Task\n\nSelect order_id and customer_id from the orders table.\n",
    "starter_code": "-- orders table has: order_id, customer_id (FK), product, amount\n-- Select order_id and customer_id\n\n",
    "solution_code": "SELECT order_id, customer_id FROM orders;",
    "expected_output": "order_id | customer_id\n1        | 101\n2        | 101\n3        | 102",
    "chapter_id": 200,
    "chapter_title": "Setup & Mental Model"
  },
  "1005": {
    "id": 1005,
    "title": "SQL is Declarative",
    "content": "# üí° SQL is Declarative\n\n## Declarative vs Imperative\n\n| Imperative (How) | Declarative (What) |\n| --- | --- |\n| Step-by-step instructions | Describe desired result |\n| Python, Java, JavaScript | SQL, HTML, CSS |\n| You control the loop | Database figures it out |\n\n## Example Comparison\n\n**Imperative (Python):**\n```python\nresults = []\nfor row in table:\n    if row['salary'] > 50000:\n        results.append(row['name'])\n```\n\n**Declarative (SQL):**\n```sql\nSELECT name FROM employees WHERE salary > 50000;\n```\n\nIn SQL, you say WHAT you want, and the database engine figures out HOW to get it!\n\n## Why This Matters\n\n1. **Simpler code**: Less boilerplate\n2. **Optimized execution**: Database chooses the best approach\n3. **Portable**: Same query works across databases\n4. **Focus on logic**: Not on implementation details\n\n---\n\n## üéØ Your Task\n\nWrite a declarative SQL query to get names where salary > 60000.\n",
    "starter_code": "-- Get employee names with salary above 60000\n-- Remember: SQL is declarative - say WHAT you want!\n\n",
    "solution_code": "SELECT name FROM employees WHERE salary > 60000;",
    "expected_output": "name\nAlice\nBob",
    "chapter_id": 200,
    "chapter_title": "Setup & Mental Model"
  },
  "1006": {
    "id": 1006,
    "title": "Result Sets",
    "content": "# üìã Result Sets\n\n## What is a Result Set?\n\nWhen you run a SELECT query, the database returns a **result set** - a temporary table containing your requested data.\n\n```sql\nSELECT name, salary FROM employees WHERE department = 'Sales';\n```\n\nReturns:\n```\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ name    ‚îÇ salary ‚îÇ  ‚Üê Result Set\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ Alice   ‚îÇ 75000  ‚îÇ\n‚îÇ Charlie ‚îÇ 72000  ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n```\n\n## Result Set Properties\n\n- **Temporary**: Only exists while query runs\n- **Read-only**: You can't directly edit it\n- **Ordered**: Can be sorted with ORDER BY\n- **Subset**: Can be limited with LIMIT\n\n## Empty Result Sets\n\nIf no rows match your criteria:\n```sql\nSELECT * FROM employees WHERE salary > 1000000;\n-- Returns 0 rows (an empty result set)\n```\n\nThis is NOT an error - it's a valid result meaning \"no matches found.\"\n\n---\n\n## üéØ Your Task\n\nSelect name and department from employees.\n",
    "starter_code": "-- Get name and department columns\n\n",
    "solution_code": "SELECT name, department FROM employees;",
    "expected_output": "name    | department\nAlice   | Sales\nBob     | Marketing\nCharlie | Sales",
    "chapter_id": 200,
    "chapter_title": "Setup & Mental Model"
  },
  "1007": {
    "id": 1007,
    "title": "NULL Basics",
    "content": "# ‚ùì NULL Basics\n\n## What is NULL?\n\n**NULL** represents missing or unknown data. It is NOT:\n- Zero (0)\n- An empty string ('')\n- The word 'null'\n\nIt literally means \"we don't know this value.\"\n\n## Examples of NULL\n\n```\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ id ‚îÇ name    ‚îÇ phone     ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ 1  ‚îÇ Alice   ‚îÇ 555-1234  ‚îÇ\n‚îÇ 2  ‚îÇ Bob     ‚îÇ NULL      ‚îÇ  ‚Üê Bob hasn't provided a phone\n‚îÇ 3  ‚îÇ Charlie ‚îÇ 555-5678  ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n```\n\n## NULL Behavior\n\n- `NULL = NULL` is **not TRUE** (it's NULL!)\n- Any math with NULL gives NULL: `5 + NULL = NULL`\n- Use `IS NULL` to check for NULL values\n\n## Why NULL Matters for Data Science\n\n- Missing data is common in real datasets\n- Ignoring NULL can lead to wrong calculations\n- Different aggregations handle NULL differently\n\n---\n\n## üéØ Your Task\n\nSelect all columns from products where price IS NULL.\n",
    "starter_code": "-- Find products with missing prices\n-- Use IS NULL (not = NULL)\n\n",
    "solution_code": "SELECT * FROM products WHERE price IS NULL;",
    "expected_output": "id | name       | price\n3  | Widget C   | NULL",
    "chapter_id": 200,
    "chapter_title": "Setup & Mental Model"
  },
  "1008": {
    "id": 1008,
    "title": "Schema Organization",
    "content": "# üèõÔ∏è Schema Organization\n\n## What is a Schema?\n\nA **schema** is a logical container that groups related tables together. Think of it like folders organizing files.\n\n```\nDatabase: company_db\n‚îú‚îÄ‚îÄ public (schema)\n‚îÇ   ‚îú‚îÄ‚îÄ employees\n‚îÇ   ‚îî‚îÄ‚îÄ departments\n‚îú‚îÄ‚îÄ sales (schema)\n‚îÇ   ‚îú‚îÄ‚îÄ orders\n‚îÇ   ‚îî‚îÄ‚îÄ customers\n‚îî‚îÄ‚îÄ analytics (schema)\n    ‚îú‚îÄ‚îÄ daily_metrics\n    ‚îî‚îÄ‚îÄ user_events\n```\n\n## Referencing Tables with Schemas\n\n```sql\n-- Without schema (uses default)\nSELECT * FROM employees;\n\n-- With schema prefix\nSELECT * FROM public.employees;\nSELECT * FROM sales.orders;\n```\n\n## Common Schema Patterns\n\n| Schema | Purpose |\n| --- | --- |\n| **public** | Default tables |\n| **raw** | Unprocessed source data |\n| **staging** | Cleaned intermediate data |\n| **analytics** | Final reporting tables |\n\n---\n\n## üéØ Your Task\n\nSelect all from the sales.orders table using schema prefix.\n",
    "starter_code": "-- Select from sales schema, orders table\n\n",
    "solution_code": "SELECT * FROM sales.orders;",
    "expected_output": "order_id | customer_id | total\n1        | 101         | 99.99\n2        | 102         | 149.99",
    "chapter_id": 200,
    "chapter_title": "Setup & Mental Model"
  },
  "1009": {
    "id": 1009,
    "title": "Query Execution Order",
    "content": "# üîÑ Query Execution Order\n\n## SQL Doesn't Run Top-to-Bottom!\n\nThe order you WRITE a query differs from how it EXECUTES:\n\n**Writing Order:**\n```sql\nSELECT name, SUM(amount)    -- 1st written\nFROM orders                  -- 2nd written\nWHERE status = 'completed'   -- 3rd written\nGROUP BY name                -- 4th written\nHAVING SUM(amount) > 100     -- 5th written\nORDER BY SUM(amount) DESC    -- 6th written\nLIMIT 10;                    -- 7th written\n```\n\n**Execution Order:**\n1. **FROM** - Which table?\n2. **WHERE** - Filter rows\n3. **GROUP BY** - Group rows\n4. **HAVING** - Filter groups\n5. **SELECT** - Choose columns\n6. **ORDER BY** - Sort results\n7. **LIMIT** - Limit rows\n\n## Why This Matters\n\n- You can't use a SELECT alias in WHERE\n- HAVING filters AFTER grouping\n- ORDER BY runs almost last\n\n---\n\n## üéØ Your Task\n\nWrite a query with FROM, WHERE, and SELECT in correct syntax order.\n",
    "starter_code": "-- Get name from employees where department = 'Sales'\n-- Remember: SELECT comes first in syntax\n\n",
    "solution_code": "SELECT name FROM employees WHERE department = 'Sales';",
    "expected_output": "name\nAlice\nCharlie",
    "chapter_id": 200,
    "chapter_title": "Setup & Mental Model"
  },
  "1010": {
    "id": 1010,
    "title": "Your First SELECT",
    "content": "# üìã Your First SELECT\n\n## The SELECT Statement\n\nSELECT is the most fundamental SQL command. It retrieves data from a table.\n\n```sql\nSELECT column_name FROM table_name;\n```\n\n## Breaking It Down\n\n| Part | Purpose |\n| --- | --- |\n| `SELECT` | Keyword to start retrieving data |\n| `column_name` | Which column(s) you want |\n| `FROM` | Keyword indicating the source |\n| `table_name` | Which table to query |\n\n## Simple Examples\n\n```sql\n-- Get one column\nSELECT name FROM employees;\n\n-- Get multiple columns\nSELECT name, salary FROM employees;\n\n-- Get all columns\nSELECT * FROM employees;\n```\n\n## Semicolon\n\nSQL statements end with a semicolon (`;`). This tells the database the command is complete.\n\n---\n\n## üéØ Your Task\n\nSelect only the 'email' column from the users table.\n",
    "starter_code": "-- Select the email column from users\n\n",
    "solution_code": "SELECT email FROM users;",
    "expected_output": "email\nalice@example.com\nbob@example.com\ncharlie@example.com",
    "chapter_id": 201,
    "chapter_title": "SELECT Basics"
  },
  "1011": {
    "id": 1011,
    "title": "Selecting Multiple Columns",
    "content": "# üìä Selecting Multiple Columns\n\n## Comma-Separated Columns\n\nTo select more than one column, separate them with commas:\n\n```sql\nSELECT column1, column2, column3 FROM table_name;\n```\n\n## Example\n\n```sql\nSELECT name, email, city FROM customers;\n```\n\nReturns:\n```\nname  | email        | city\nAlice | a@mail.com   | NYC\nBob   | b@mail.com   | LA\n```\n\n## Column Order\n\nColumns appear in the result in the order you list them:\n\n```sql\nSELECT city, name FROM customers;  -- city first!\n```\n\n## Tips\n\n- List columns in logical order\n- Only select columns you need (better performance)\n- Group related columns together\n\n---\n\n## üéØ Your Task\n\nSelect name, department, and salary from employees (in that order).\n",
    "starter_code": "-- Select name, department, and salary\n\n",
    "solution_code": "SELECT name, department, salary FROM employees;",
    "expected_output": "name    | department | salary\nAlice   | Sales      | 75000\nBob     | Marketing  | 90000\nCharlie | Sales      | 72000",
    "chapter_id": 201,
    "chapter_title": "SELECT Basics"
  },
  "1012": {
    "id": 1012,
    "title": "SELECT All Columns",
    "content": "# ‚≠ê SELECT All Columns\n\n## The Asterisk (*)\n\nUse `*` to select ALL columns from a table:\n\n```sql\nSELECT * FROM employees;\n```\n\n## When to Use *\n\n‚úÖ **Good for:**\n- Quick exploration of data\n- Ad-hoc queries\n- When you genuinely need all columns\n\n‚ùå **Avoid for:**\n- Production code (breaks if columns change)\n- Large tables (fetches unnecessary data)\n- Joins (can cause column name conflicts)\n\n## Best Practice\n\n```sql\n-- Instead of this in production:\nSELECT * FROM orders;\n\n-- Be explicit:\nSELECT order_id, customer_id, amount, status FROM orders;\n```\n\nExplicit column lists are self-documenting and more maintainable.\n\n---\n\n## üéØ Your Task\n\nSelect all columns from the products table.\n",
    "starter_code": "-- Select all columns from products\n\n",
    "solution_code": "SELECT * FROM products;",
    "expected_output": "id | name     | price | category\n1  | Widget A | 29.99 | Tools\n2  | Widget B | 49.99 | Tools\n3  | Gadget C | 99.99 | Electronics",
    "chapter_id": 201,
    "chapter_title": "SELECT Basics"
  },
  "1013": {
    "id": 1013,
    "title": "Column Aliases with AS",
    "content": "# üè∑Ô∏è Column Aliases with AS\n\n## Renaming Columns in Output\n\nUse `AS` to give columns friendlier names in your result:\n\n```sql\nSELECT employee_name AS name FROM employees;\n```\n\n## Why Use Aliases?\n\n1. **Readability**: `first_name` ‚Üí `First Name`\n2. **Calculations**: Name computed values\n3. **Joins**: Distinguish duplicate column names\n\n## Examples\n\n```sql\n-- Simple rename\nSELECT email AS contact_email FROM users;\n\n-- With calculations\nSELECT price, price * 0.9 AS discounted_price FROM products;\n\n-- Spaces in alias (use quotes)\nSELECT name AS \"Employee Name\" FROM employees;\n```\n\n## AS is Optional\n\n```sql\n-- These are equivalent:\nSELECT name AS employee_name FROM employees;\nSELECT name employee_name FROM employees;\n```\n\nBut using `AS` is clearer!\n\n---\n\n## üéØ Your Task\n\nSelect name as 'employee_name' and salary as 'annual_salary'.\n",
    "starter_code": "-- Select with aliases\n\n",
    "solution_code": "SELECT name AS employee_name, salary AS annual_salary FROM employees;",
    "expected_output": "employee_name | annual_salary\nAlice         | 75000\nBob           | 90000\nCharlie       | 72000",
    "chapter_id": 201,
    "chapter_title": "SELECT Basics"
  },
  "1014": {
    "id": 1014,
    "title": "Table Aliases",
    "content": "# üìù Table Aliases\n\n## Shortening Table Names\n\nIn complex queries, give tables short aliases:\n\n```sql\nSELECT e.name, e.salary\nFROM employees AS e;\n```\n\n## Why Table Aliases?\n\n1. **Less typing**: `employees` ‚Üí `e`\n2. **Required for self-joins**: Same table used twice\n3. **Clarity in JOINs**: `e.name` vs `o.name`\n\n## Common Conventions\n\n```sql\n-- First letter(s) of table name\nSELECT c.name, o.amount\nFROM customers AS c\nJOIN orders AS o ON c.id = o.customer_id;\n```\n\n| Table | Common Alias |\n| --- | --- |\n| employees | e, emp |\n| customers | c, cust |\n| orders | o, ord |\n| products | p, prod |\n\n---\n\n## üéØ Your Task\n\nSelect name and department from employees using alias 'e'.\n",
    "starter_code": "-- Use table alias 'e' for employees\n\n",
    "solution_code": "SELECT e.name, e.department FROM employees AS e;",
    "expected_output": "name    | department\nAlice   | Sales\nBob     | Marketing\nCharlie | Sales",
    "chapter_id": 201,
    "chapter_title": "SELECT Basics"
  },
  "1015": {
    "id": 1015,
    "title": "LIMIT Clause",
    "content": "# üî¢ LIMIT Clause\n\n## Restricting Result Size\n\nLIMIT returns only the first N rows:\n\n```sql\nSELECT * FROM products LIMIT 5;\n```\n\n## Why Use LIMIT?\n\n1. **Previewing data**: See first few rows\n2. **Performance**: Don't fetch millions of rows\n3. **Top N queries**: Combined with ORDER BY\n\n## Examples\n\n```sql\n-- First 10 rows\nSELECT * FROM orders LIMIT 10;\n\n-- Top 5 highest salaries\nSELECT name, salary\nFROM employees\nORDER BY salary DESC\nLIMIT 5;\n\n-- With OFFSET (skip rows)\nSELECT * FROM products LIMIT 10 OFFSET 20;  -- Skip 20, get next 10\n```\n\n## Database Differences\n\n| Database | Syntax |\n| --- | --- |\n| PostgreSQL, MySQL | LIMIT 10 |\n| SQL Server | TOP 10 |\n| Oracle | FETCH FIRST 10 ROWS ONLY |\n\n---\n\n## üéØ Your Task\n\nSelect all columns from orders, but only the first 3 rows.\n",
    "starter_code": "-- Get first 3 orders\n\n",
    "solution_code": "SELECT * FROM orders LIMIT 3;",
    "expected_output": "order_id | customer_id | amount\n1        | 101         | 99.99\n2        | 101         | 149.99\n3        | 102         | 49.99",
    "chapter_id": 201,
    "chapter_title": "SELECT Basics"
  },
  "1016": {
    "id": 1016,
    "title": "WHERE Basics",
    "content": "# üîç WHERE Basics\n\n## Filtering Rows\n\nWHERE filters which rows are returned:\n\n```sql\nSELECT * FROM employees WHERE department = 'Sales';\n```\n\n## Basic Syntax\n\n```sql\nSELECT columns\nFROM table\nWHERE condition;\n```\n\n## Common Conditions\n\n```sql\n-- Equals\nWHERE status = 'active'\n\n-- Not equals\nWHERE status != 'cancelled'\nWHERE status <> 'cancelled'  -- Alternative syntax\n\n-- Numbers\nWHERE price > 100\nWHERE quantity <= 50\n```\n\n## Text Values Need Quotes\n\n```sql\n-- Correct: strings in single quotes\nWHERE name = 'Alice'\n\n-- Wrong: unquoted\nWHERE name = Alice  -- Error!\n```\n\n---\n\n## üéØ Your Task\n\nSelect name and salary from employees where salary > 70000.\n",
    "starter_code": "-- Filter employees with salary > 70000\n\n",
    "solution_code": "SELECT name, salary FROM employees WHERE salary > 70000;",
    "expected_output": "name  | salary\nAlice | 75000\nBob   | 90000",
    "chapter_id": 201,
    "chapter_title": "SELECT Basics"
  },
  "1017": {
    "id": 1017,
    "title": "Comparison Operators",
    "content": "# ‚öñÔ∏è Comparison Operators\n\n## All Comparison Operators\n\n| Operator | Meaning | Example |\n| --- | --- | --- |\n| `=` | Equal | `price = 100` |\n| `<>` or `!=` | Not equal | `status <> 'done'` |\n| `<` | Less than | `age < 18` |\n| `>` | Greater than | `score > 90` |\n| `<=` | Less than or equal | `qty <= 10` |\n| `>=` | Greater than or equal | `rating >= 4` |\n\n## Multiple Conditions\n\nCombine with AND / OR:\n\n```sql\n-- Both must be true\nWHERE salary > 50000 AND department = 'Sales'\n\n-- Either can be true\nWHERE department = 'Sales' OR department = 'Marketing'\n\n-- Use parentheses for complex logic\nWHERE (age > 21 OR has_permission = true) AND status = 'active'\n```\n\n## NOT Operator\n\n```sql\nWHERE NOT status = 'cancelled'\nWHERE NOT (price > 100 AND qty < 5)\n```\n\n---\n\n## üéØ Your Task\n\nFind employees in Sales department with salary >= 75000.\n",
    "starter_code": "-- Use AND to combine two conditions\n\n",
    "solution_code": "SELECT * FROM employees WHERE department = 'Sales' AND salary >= 75000;",
    "expected_output": "id | name  | department | salary\n1  | Alice | Sales      | 75000",
    "chapter_id": 201,
    "chapter_title": "SELECT Basics"
  },
  "1018": {
    "id": 1018,
    "title": "IN Operator",
    "content": "# üìã IN Operator\n\n## Check Against a List\n\nIN checks if a value matches ANY value in a list:\n\n```sql\nSELECT * FROM employees\nWHERE department IN ('Sales', 'Marketing', 'Engineering');\n```\n\n## IN vs Multiple ORs\n\n```sql\n-- These are equivalent:\nWHERE department IN ('Sales', 'Marketing')\n\nWHERE department = 'Sales' OR department = 'Marketing'\n```\n\nIN is cleaner when checking many values!\n\n## NOT IN\n\nExclude values with NOT IN:\n\n```sql\nSELECT * FROM orders\nWHERE status NOT IN ('cancelled', 'refunded');\n```\n\n## ‚ö†Ô∏è NULL Warning\n\n```sql\n-- If any value is NULL, NOT IN behaves unexpectedly!\nWHERE id NOT IN (1, 2, NULL)  -- Returns no rows!\n```\n\nBe careful with NULL in NOT IN lists.\n\n---\n\n## üéØ Your Task\n\nSelect products where category is in ('Electronics', 'Tools').\n",
    "starter_code": "-- Use IN to match multiple categories\n\n",
    "solution_code": "SELECT * FROM products WHERE category IN ('Electronics', 'Tools');",
    "expected_output": "id | name     | price | category\n1  | Widget A | 29.99 | Tools\n2  | Widget B | 49.99 | Tools\n3  | Gadget C | 99.99 | Electronics",
    "chapter_id": 201,
    "chapter_title": "SELECT Basics"
  },
  "1019": {
    "id": 1019,
    "title": "BETWEEN Operator",
    "content": "# üìè BETWEEN Operator\n\n## Range Checking\n\nBETWEEN checks if a value falls within a range (inclusive):\n\n```sql\nSELECT * FROM products\nWHERE price BETWEEN 10 AND 50;\n```\n\nThis includes 10 AND 50!\n\n## Equivalent to\n\n```sql\n-- These are the same:\nWHERE price BETWEEN 10 AND 50\nWHERE price >= 10 AND price <= 50\n```\n\n## Works with Dates Too\n\n```sql\nSELECT * FROM orders\nWHERE order_date BETWEEN '2024-01-01' AND '2024-12-31';\n```\n\n## NOT BETWEEN\n\n```sql\n-- Outside the range\nWHERE price NOT BETWEEN 10 AND 50\n```\n\n---\n\n## üéØ Your Task\n\nSelect employees with salary between 70000 and 80000.\n",
    "starter_code": "-- Find salaries in range 70000-80000\n\n",
    "solution_code": "SELECT * FROM employees WHERE salary BETWEEN 70000 AND 80000;",
    "expected_output": "id | name    | department | salary\n1  | Alice   | Sales      | 75000\n3  | Charlie | Sales      | 72000",
    "chapter_id": 201,
    "chapter_title": "SELECT Basics"
  },
  "1020": {
    "id": 1020,
    "title": "LIKE Pattern Matching",
    "content": "# üîé LIKE Pattern Matching\n\n## Wildcards for Text Search\n\nLIKE searches for patterns using wildcards:\n\n| Wildcard | Meaning | Example |\n| --- | --- | --- |\n| `%` | Any characters (0 or more) | `'%son'` matches 'Johnson' |\n| `_` | Exactly one character | `'_at'` matches 'Cat', 'Bat' |\n\n## Common Patterns\n\n```sql\n-- Starts with 'A'\nWHERE name LIKE 'A%'\n\n-- Ends with 'son'\nWHERE name LIKE '%son'\n\n-- Contains 'data'\nWHERE description LIKE '%data%'\n\n-- Second letter is 'a'\nWHERE name LIKE '_a%'\n```\n\n## Case Sensitivity\n\n```sql\n-- PostgreSQL: ILIKE for case-insensitive\nWHERE name ILIKE '%alice%'  -- Matches 'Alice', 'ALICE', 'alice'\n\n-- MySQL: LIKE is case-insensitive by default\n```\n\n---\n\n## üéØ Your Task\n\nFind employees whose name starts with 'A'.\n",
    "starter_code": "-- Select names starting with 'A'\n\n",
    "solution_code": "SELECT * FROM employees WHERE name LIKE 'A%';",
    "expected_output": "id | name  | department | salary\n1  | Alice | Sales      | 75000",
    "chapter_id": 201,
    "chapter_title": "SELECT Basics"
  },
  "1021": {
    "id": 1021,
    "title": "ORDER BY Sorting",
    "content": "# üîÑ ORDER BY Sorting\n\n## Sorting Results\n\nORDER BY arranges rows in a specific order:\n\n```sql\nSELECT * FROM employees ORDER BY salary;\n```\n\n## ASC and DESC\n\n| Direction | Meaning | Default? |\n| --- | --- | --- |\n| `ASC` | Ascending (A‚ÜíZ, 1‚Üí9) | Yes |\n| `DESC` | Descending (Z‚ÜíA, 9‚Üí1) | No |\n\n```sql\n-- Highest salary first\nSELECT * FROM employees ORDER BY salary DESC;\n\n-- Alphabetically\nSELECT * FROM employees ORDER BY name ASC;\n```\n\n## Multiple Columns\n\n```sql\n-- Sort by department, then by salary within each dept\nSELECT * FROM employees\nORDER BY department ASC, salary DESC;\n```\n\n## NULL Sorting\n\nNULLs typically sort to the end (depends on database).\n\n```sql\n-- Control NULL position\nORDER BY column NULLS FIRST\nORDER BY column NULLS LAST\n```\n\n---\n\n## üéØ Your Task\n\nSelect all employees ordered by salary descending.\n",
    "starter_code": "-- Order by salary from highest to lowest\n\n",
    "solution_code": "SELECT * FROM employees ORDER BY salary DESC;",
    "expected_output": "id | name    | department | salary\n2  | Bob     | Marketing  | 90000\n1  | Alice   | Sales      | 75000\n3  | Charlie | Sales      | 72000",
    "chapter_id": 201,
    "chapter_title": "SELECT Basics"
  },
  "1022": {
    "id": 1022,
    "title": "Integer Types",
    "content": "# üî¢ Integer Types\n\n## Whole Number Storage\n\nSQL provides several integer types for storing whole numbers:\n\n| Type | Storage | Range |\n| --- | --- | --- |\n| `SMALLINT` | 2 bytes | -32,768 to 32,767 |\n| `INTEGER` / `INT` | 4 bytes | -2.1 billion to 2.1 billion |\n| `BIGINT` | 8 bytes | Huge numbers |\n\n## Choosing the Right Type\n\n```sql\n-- Age: SMALLINT is plenty\nage SMALLINT\n\n-- User IDs: INTEGER for most apps\nuser_id INTEGER\n\n-- Large sequences: BIGINT for billions\npage_views BIGINT\n```\n\n## Auto-Incrementing IDs\n\n```sql\n-- PostgreSQL\nid SERIAL PRIMARY KEY  -- Auto-incrementing 1, 2, 3...\nid BIGSERIAL PRIMARY KEY  -- For large tables\n\n-- MySQL\nid INT AUTO_INCREMENT PRIMARY KEY\n```\n\n---\n\n## üéØ Your Task\n\nSelect id and quantity from the inventory table where quantity > 100.\n",
    "starter_code": "-- inventory has: id (INT), product_name, quantity (INT)\n\n",
    "solution_code": "SELECT id, quantity FROM inventory WHERE quantity > 100;",
    "expected_output": "id | quantity\n1  | 150\n3  | 200",
    "chapter_id": 202,
    "chapter_title": "Data Types, NULLs & Calculations"
  },
  "1023": {
    "id": 1023,
    "title": "Numeric and Decimal Types",
    "content": "# üí∞ Numeric and Decimal Types\n\n## Precise Decimal Numbers\n\nFor money and precise calculations, use exact numeric types:\n\n```sql\n-- NUMERIC(precision, scale)\n-- precision = total digits\n-- scale = digits after decimal\n\nprice NUMERIC(10, 2)  -- 12345678.99\ntax_rate NUMERIC(5, 4)  -- 0.0825\n```\n\n## Floating Point vs Numeric\n\n| Type | Use Case | Precision |\n| --- | --- | --- |\n| `NUMERIC` / `DECIMAL` | Money, exact values | Exact |\n| `REAL` / `FLOAT` | Scientific data | Approximate |\n\n## ‚ö†Ô∏è Why This Matters\n\n```sql\n-- Floating point can have rounding errors!\n0.1 + 0.2 = 0.30000000000000004  -- Float\n0.1 + 0.2 = 0.30  -- NUMERIC\n```\n\n**Always use NUMERIC for money!**\n\n---\n\n## üéØ Your Task\n\nSelect product_name and price from products where price > 50.00.\n",
    "starter_code": "-- products has: id, product_name, price (NUMERIC)\n\n",
    "solution_code": "SELECT product_name, price FROM products WHERE price > 50.00;",
    "expected_output": "product_name | price\nWidget Pro   | 99.99\nGadget Plus  | 149.50",
    "chapter_id": 202,
    "chapter_title": "Data Types, NULLs & Calculations"
  },
  "1024": {
    "id": 1024,
    "title": "Text Types",
    "content": "# üìù Text Types\n\n## Storing Text Data\n\n| Type | Description | Example |\n| --- | --- | --- |\n| `CHAR(n)` | Fixed length, padded | Country codes |\n| `VARCHAR(n)` | Variable length, max n | Names, emails |\n| `TEXT` | Unlimited length | Descriptions, content |\n\n## When to Use Each\n\n```sql\n-- Fixed length codes\ncountry_code CHAR(2)  -- 'US', 'UK'\n\n-- Variable text with limit\nname VARCHAR(100)\nemail VARCHAR(255)\n\n-- Long content\nbio TEXT\narticle_body TEXT\n```\n\n## String Comparison\n\n```sql\n-- Case-sensitive by default in PostgreSQL\nWHERE name = 'Alice'  -- Won't match 'alice'\n\n-- Use LOWER() for case-insensitive\nWHERE LOWER(name) = 'alice'\n```\n\n---\n\n## üéØ Your Task\n\nSelect name and email from users where email ends with '@gmail.com'.\n",
    "starter_code": "-- Find Gmail users\n\n",
    "solution_code": "SELECT name, email FROM users WHERE email LIKE '%@gmail.com';",
    "expected_output": "name  | email\nAlice | alice@gmail.com\nBob   | bob@gmail.com",
    "chapter_id": 202,
    "chapter_title": "Data Types, NULLs & Calculations"
  },
  "1025": {
    "id": 1025,
    "title": "Date and Timestamp Types",
    "content": "# üìÖ Date and Timestamp Types\n\n## Time-Related Types\n\n| Type | Stores | Example |\n| --- | --- | --- |\n| `DATE` | Date only | '2024-01-15' |\n| `TIME` | Time only | '14:30:00' |\n| `TIMESTAMP` | Date + time | '2024-01-15 14:30:00' |\n| `TIMESTAMPTZ` | With timezone | (PostgreSQL) |\n\n## Creating Date Values\n\n```sql\n-- String literals\nWHERE order_date = '2024-01-15'\nWHERE created_at > '2024-01-01 00:00:00'\n\n-- Current date/time\nSELECT CURRENT_DATE;  -- Today\nSELECT CURRENT_TIMESTAMP;  -- Now\nSELECT NOW();  -- PostgreSQL\n```\n\n## Date Formatting\n\n```sql\n-- Format for display (PostgreSQL)\nSELECT TO_CHAR(order_date, 'Month DD, YYYY');\n-- Output: January 15, 2024\n```\n\n---\n\n## üéØ Your Task\n\nSelect order_id and order_date from orders where order_date > '2024-01-01'.\n",
    "starter_code": "-- Find orders after January 1, 2024\n\n",
    "solution_code": "SELECT order_id, order_date FROM orders WHERE order_date > '2024-01-01';",
    "expected_output": "order_id | order_date\n5        | 2024-01-15\n6        | 2024-02-01\n7        | 2024-03-10",
    "chapter_id": 202,
    "chapter_title": "Data Types, NULLs & Calculations"
  },
  "1026": {
    "id": 1026,
    "title": "Boolean Type",
    "content": "# ‚úÖ Boolean Type\n\n## True or False Values\n\nBOOLEAN stores true/false values:\n\n```sql\nis_active BOOLEAN\nis_verified BOOLEAN\nhas_paid BOOLEAN\n```\n\n## Boolean Literals\n\n```sql\n-- These all work:\nWHERE is_active = TRUE\nWHERE is_active = true\nWHERE is_active = 't'\nWHERE is_active = 1\n\n-- Shorthand (preferred)\nWHERE is_active  -- Same as = TRUE\nWHERE NOT is_active  -- Same as = FALSE\n```\n\n## Common Patterns\n\n```sql\n-- Find active premium users\nSELECT * FROM users\nWHERE is_active AND is_premium;\n\n-- Find unverified users\nSELECT * FROM users\nWHERE NOT is_verified;\n```\n\n---\n\n## üéØ Your Task\n\nSelect name from users where is_active is true.\n",
    "starter_code": "-- Find active users\n\n",
    "solution_code": "SELECT name FROM users WHERE is_active;",
    "expected_output": "name\nAlice\nCharlie",
    "chapter_id": 202,
    "chapter_title": "Data Types, NULLs & Calculations"
  },
  "1027": {
    "id": 1027,
    "title": "Understanding NULL",
    "content": "# ‚ùì Understanding NULL\n\n## NULL is Not a Value\n\nNULL means \"unknown\" or \"missing.\" It's NOT the same as:\n- Empty string ('')\n- Zero (0)\n- The word 'null'\n\n## The NULL Trap\n\n```sql\n-- This returns NO rows, even if phone IS null!\nSELECT * FROM users WHERE phone = NULL;  -- WRONG!\n\n-- This is correct:\nSELECT * FROM users WHERE phone IS NULL;  -- RIGHT!\n```\n\n## Why = NULL Doesn't Work\n\nNULL represents \"unknown\". Is unknown equal to unknown? We don't know! So the result is... NULL (neither true nor false).\n\n## NULL in Expressions\n\n```sql\n-- Any operation with NULL returns NULL\n5 + NULL = NULL\n'Hello' || NULL = NULL\nNULL = NULL  -- NULL (not TRUE!)\nNULL <> NULL  -- NULL (not TRUE!)\n```\n\n---\n\n## üéØ Your Task\n\nSelect name from employees where manager_id IS NULL (no manager).\n",
    "starter_code": "-- Find employees with no manager\n\n",
    "solution_code": "SELECT name FROM employees WHERE manager_id IS NULL;",
    "expected_output": "name\nSarah",
    "chapter_id": 202,
    "chapter_title": "Data Types, NULLs & Calculations"
  },
  "1028": {
    "id": 1028,
    "title": "IS NULL and IS NOT NULL",
    "content": "# üîç IS NULL and IS NOT NULL\n\n## Checking for NULL Values\n\n```sql\n-- Find rows WITH missing data\nSELECT * FROM customers WHERE phone IS NULL;\n\n-- Find rows WITHOUT missing data\nSELECT * FROM customers WHERE phone IS NOT NULL;\n```\n\n## Common Use Cases\n\n```sql\n-- Data quality: Find incomplete profiles\nSELECT * FROM users\nWHERE email IS NULL OR phone IS NULL;\n\n-- Only process complete records\nSELECT * FROM orders\nWHERE shipped_date IS NOT NULL;\n\n-- Count missing values\nSELECT COUNT(*) - COUNT(phone) AS missing_phones\nFROM customers;\n```\n\n## Combining Conditions\n\n```sql\n-- Active users with verified emails\nSELECT * FROM users\nWHERE is_active = true\nAND email IS NOT NULL\nAND verified_at IS NOT NULL;\n```\n\n---\n\n## üéØ Your Task\n\nSelect product_name from products where description IS NOT NULL.\n",
    "starter_code": "-- Find products that have descriptions\n\n",
    "solution_code": "SELECT product_name FROM products WHERE description IS NOT NULL;",
    "expected_output": "product_name\nWidget A\nGadget Pro",
    "chapter_id": 202,
    "chapter_title": "Data Types, NULLs & Calculations"
  },
  "1029": {
    "id": 1029,
    "title": "Three-Valued Logic",
    "content": "# üß† Three-Valued Logic\n\n## TRUE, FALSE, and NULL\n\nSQL uses **three-valued logic** because of NULL:\n\n| Expression | Result |\n| --- | --- |\n| `TRUE AND TRUE` | TRUE |\n| `TRUE AND FALSE` | FALSE |\n| `TRUE AND NULL` | NULL |\n| `FALSE AND NULL` | FALSE |\n| `TRUE OR NULL` | TRUE |\n| `FALSE OR NULL` | NULL |\n\n## Practical Impact\n\n```sql\n-- If age might be NULL:\nWHERE age > 21  -- NULL ages are NOT included\nWHERE NOT (age > 21)  -- NULL ages still NOT included!\n\n-- To include NULLs explicitly:\nWHERE age > 21 OR age IS NULL\n```\n\n## NOT and NULL\n\n```sql\nNOT TRUE = FALSE\nNOT FALSE = TRUE\nNOT NULL = NULL  -- Still unknown!\n```\n\n---\n\n## üéØ Your Task\n\nSelect name from users where age > 18 OR age IS NULL.\n",
    "starter_code": "-- Find adults or users with unknown age\n\n",
    "solution_code": "SELECT name FROM users WHERE age > 18 OR age IS NULL;",
    "expected_output": "name\nAlice\nBob\nDiana",
    "chapter_id": 202,
    "chapter_title": "Data Types, NULLs & Calculations"
  },
  "1030": {
    "id": 1030,
    "title": "COALESCE Function",
    "content": "# üîÑ COALESCE Function\n\n## Replace NULL with a Default\n\nCOALESCE returns the first non-NULL value:\n\n```sql\nSELECT COALESCE(phone, 'No phone') FROM customers;\n```\n\n## How It Works\n\n```sql\nCOALESCE(value1, value2, value3, ...)\n\n-- Returns first non-NULL:\nCOALESCE(NULL, NULL, 'default')  -- 'default'\nCOALESCE('hello', 'default')      -- 'hello'\nCOALESCE(NULL, 0)                 -- 0\n```\n\n## Common Use Cases\n\n```sql\n-- Display friendly message\nSELECT name, COALESCE(bio, 'No bio provided') AS bio\nFROM users;\n\n-- Default values in calculations\nSELECT price * COALESCE(quantity, 1) AS total\nFROM cart_items;\n\n-- Fallback chain\nSELECT COALESCE(nickname, first_name, email) AS display_name\nFROM users;\n```\n\n---\n\n## üéØ Your Task\n\nSelect name and COALESCE(phone, 'N/A') as phone from contacts.\n",
    "starter_code": "-- Show 'N/A' for missing phone numbers\n\n",
    "solution_code": "SELECT name, COALESCE(phone, 'N/A') AS phone FROM contacts;",
    "expected_output": "name    | phone\nAlice   | 555-1234\nBob     | N/A\nCharlie | 555-5678",
    "chapter_id": 202,
    "chapter_title": "Data Types, NULLs & Calculations"
  },
  "1031": {
    "id": 1031,
    "title": "NULLIF Function",
    "content": "# ‚ö° NULLIF Function\n\n## Turn a Value into NULL\n\nNULLIF returns NULL if two values are equal:\n\n```sql\nNULLIF(value1, value2)\n\n-- Returns NULL if equal, otherwise returns value1\nNULLIF(5, 5)     -- NULL\nNULLIF(5, 0)     -- 5\nNULLIF('', '')   -- NULL\n```\n\n## Why Is This Useful?\n\n**Avoiding division by zero:**\n\n```sql\n-- This crashes if quantity = 0:\nSELECT price / quantity AS unit_price FROM items;\n\n-- This is safe:\nSELECT price / NULLIF(quantity, 0) AS unit_price FROM items;\n-- Returns NULL instead of error when quantity = 0\n```\n\n## Treating Empty Strings as NULL\n\n```sql\n-- Some data has '' instead of NULL\nSELECT name, NULLIF(phone, '') AS phone FROM users;\n-- Now empty strings become NULL\n```\n\n---\n\n## üéØ Your Task\n\nSelect total / NULLIF(count, 0) AS average from stats.\n",
    "starter_code": "-- Calculate average, avoid divide by zero\n\n",
    "solution_code": "SELECT total / NULLIF(count, 0) AS average FROM stats;",
    "expected_output": "average\n25.5\nNULL\n30.0",
    "chapter_id": 202,
    "chapter_title": "Data Types, NULLs & Calculations"
  },
  "1032": {
    "id": 1032,
    "title": "CAST and Type Conversion",
    "content": "# üîÑ CAST and Type Conversion\n\n## Converting Between Types\n\nUse CAST to convert data types:\n\n```sql\n-- CAST syntax\nCAST(expression AS target_type)\n\n-- PostgreSQL shorthand\nexpression::target_type\n```\n\n## Common Conversions\n\n```sql\n-- String to integer\nCAST('123' AS INTEGER)  -- 123\n'123'::INTEGER          -- PostgreSQL\n\n-- Number to string\nCAST(123 AS VARCHAR)    -- '123'\n\n-- String to date\nCAST('2024-01-15' AS DATE)\n\n-- Decimal precision\nCAST(price AS NUMERIC(10,2))\n```\n\n## When Conversion Fails\n\n```sql\n-- This will error:\nCAST('hello' AS INTEGER)  -- Error!\n\n-- Handle with TRY_CAST (SQL Server) or careful validation\n```\n\n---\n\n## üéØ Your Task\n\nSelect product_id, CAST(price AS INTEGER) as price_rounded from products.\n",
    "starter_code": "-- Convert price to integer (truncates decimals)\n\n",
    "solution_code": "SELECT product_id, CAST(price AS INTEGER) AS price_rounded FROM products;",
    "expected_output": "product_id | price_rounded\n1          | 29\n2          | 49\n3          | 99",
    "chapter_id": 202,
    "chapter_title": "Data Types, NULLs & Calculations"
  },
  "1033": {
    "id": 1033,
    "title": "Safe Division with NULLIF",
    "content": "# üõ°Ô∏è Safe Division with NULLIF\n\n## The Division by Zero Problem\n\nDivision by zero causes errors in SQL:\n\n```sql\nSELECT 100 / 0;  -- ERROR: division by zero\n```\n\n## The NULLIF Solution\n\nCombine division with NULLIF:\n\n```sql\nSELECT revenue / NULLIF(users, 0) AS revenue_per_user\nFROM metrics;\n```\n\nIf `users = 0`, NULLIF returns NULL, and `revenue / NULL = NULL`.\n\n## Complete Pattern\n\n```sql\n-- Calculate percentage safely\nSELECT \n  category,\n  sales,\n  ROUND(\n    100.0 * sales / NULLIF(total_sales, 0), \n    2\n  ) AS pct_of_total\nFROM sales_data;\n```\n\n## With COALESCE for Default\n\n```sql\n-- Return 0 instead of NULL\nSELECT \n  COALESCE(revenue / NULLIF(users, 0), 0) AS arpu\nFROM metrics;\n```\n\n---\n\n## üéØ Your Task\n\nSelect category and sales / NULLIF(orders, 0) as avg_order from sales.\n",
    "starter_code": "-- Calculate average order value safely\n\n",
    "solution_code": "SELECT category, sales / NULLIF(orders, 0) AS avg_order FROM sales;",
    "expected_output": "category  | avg_order\nBooks     | 25.50\nGames     | NULL\nToys      | 15.00",
    "chapter_id": 202,
    "chapter_title": "Data Types, NULLs & Calculations"
  },
  "1034": {
    "id": 1034,
    "title": "COUNT Function",
    "content": "# üìä COUNT Function\n\n## Counting Rows\n\nCOUNT tells you how many rows match your criteria:\n\n```sql\n-- Count all rows\nSELECT COUNT(*) FROM orders;\n\n-- Count non-NULL values in a column\nSELECT COUNT(email) FROM users;\n```\n\n## COUNT(*) vs COUNT(column)\n\n| Syntax | Counts |\n| --- | --- |\n| `COUNT(*)` | All rows, including NULLs |\n| `COUNT(column)` | Non-NULL values only |\n\n```sql\n-- If 3 users, 1 has NULL phone:\nSELECT COUNT(*) FROM users;       -- 3\nSELECT COUNT(phone) FROM users;   -- 2\n```\n\n## With WHERE\n\n```sql\nSELECT COUNT(*) FROM orders\nWHERE status = 'completed';\n```\n\n---\n\n## üéØ Your Task\n\nCount all rows in the customers table.\n",
    "starter_code": "-- Count all customers\n\n",
    "solution_code": "SELECT COUNT(*) FROM customers;",
    "expected_output": "count\n25",
    "chapter_id": 203,
    "chapter_title": "Aggregations & Grouping"
  },
  "1035": {
    "id": 1035,
    "title": "COUNT DISTINCT",
    "content": "# üî¢ COUNT DISTINCT\n\n## Counting Unique Values\n\nCOUNT DISTINCT counts unique (non-duplicate) values:\n\n```sql\nSELECT COUNT(DISTINCT category) FROM products;\n```\n\n## Why Use DISTINCT?\n\n```sql\n-- Orders table with repeated customer_ids:\nSELECT COUNT(customer_id) FROM orders;          -- 100 (all orders)\nSELECT COUNT(DISTINCT customer_id) FROM orders; -- 45 (unique customers)\n```\n\n## Common Use Cases\n\n```sql\n-- How many unique products sold?\nSELECT COUNT(DISTINCT product_id) FROM order_items;\n\n-- How many countries do customers come from?\nSELECT COUNT(DISTINCT country) FROM customers;\n\n-- Daily active users\nSELECT date, COUNT(DISTINCT user_id) as dau\nFROM events\nGROUP BY date;\n```\n\n---\n\n## üéØ Your Task\n\nCount the number of distinct categories in the products table.\n",
    "starter_code": "-- Count unique categories\n\n",
    "solution_code": "SELECT COUNT(DISTINCT category) FROM products;",
    "expected_output": "count\n5",
    "chapter_id": 203,
    "chapter_title": "Aggregations & Grouping"
  },
  "1036": {
    "id": 1036,
    "title": "SUM Function",
    "content": "# ‚ûï SUM Function\n\n## Adding Up Values\n\nSUM calculates the total of numeric values:\n\n```sql\nSELECT SUM(amount) FROM orders;\nSELECT SUM(quantity) FROM inventory;\n```\n\n## SUM Ignores NULL\n\n```sql\n-- Values: 100, 200, NULL, 300\nSELECT SUM(amount) FROM orders;  -- 600 (NULL ignored)\n```\n\n## With WHERE\n\n```sql\n-- Total revenue from completed orders\nSELECT SUM(amount) FROM orders\nWHERE status = 'completed';\n\n-- Total sales this year\nSELECT SUM(sales) FROM revenue\nWHERE year = 2024;\n```\n\n## Common Patterns\n\n```sql\n-- Sales by category\nSELECT category, SUM(sales) as total_sales\nFROM products\nGROUP BY category;\n```\n\n---\n\n## üéØ Your Task\n\nCalculate the total amount from all orders.\n",
    "starter_code": "-- Sum all order amounts\n\n",
    "solution_code": "SELECT SUM(amount) FROM orders;",
    "expected_output": "sum\n15750.00",
    "chapter_id": 203,
    "chapter_title": "Aggregations & Grouping"
  },
  "1037": {
    "id": 1037,
    "title": "AVG Function",
    "content": "# üìà AVG Function\n\n## Calculating Averages\n\nAVG returns the arithmetic mean:\n\n```sql\nSELECT AVG(salary) FROM employees;\nSELECT AVG(price) FROM products;\n```\n\n## AVG Ignores NULL\n\n```sql\n-- Values: 100, 200, NULL\nSELECT AVG(amount) FROM sales;  -- 150 (only 2 values counted)\n```\n\n‚ö†Ô∏è This might not be what you want! To treat NULL as 0:\n\n```sql\nSELECT AVG(COALESCE(amount, 0)) FROM sales;  -- 100\n```\n\n## Rounding Results\n\n```sql\nSELECT ROUND(AVG(salary), 2) AS avg_salary\nFROM employees;\n```\n\n## Weighted Average\n\n```sql\nSELECT SUM(price * quantity) / SUM(quantity) AS weighted_avg\nFROM orders;\n```\n\n---\n\n## üéØ Your Task\n\nCalculate the average price from the products table.\n",
    "starter_code": "-- Get average product price\n\n",
    "solution_code": "SELECT AVG(price) FROM products;",
    "expected_output": "avg\n45.99",
    "chapter_id": 203,
    "chapter_title": "Aggregations & Grouping"
  },
  "1038": {
    "id": 1038,
    "title": "MIN and MAX",
    "content": "# ‚¨ÜÔ∏è MIN and MAX\n\n## Finding Extremes\n\nMIN and MAX find the smallest and largest values:\n\n```sql\nSELECT MIN(price), MAX(price) FROM products;\nSELECT MIN(order_date), MAX(order_date) FROM orders;\n```\n\n## Works with Different Types\n\n| Type | MIN | MAX |\n| --- | --- | --- |\n| Numbers | Smallest | Largest |\n| Dates | Earliest | Latest |\n| Text | First alphabetically | Last alphabetically |\n\n## Common Patterns\n\n```sql\n-- Price range\nSELECT \n  MIN(price) as cheapest,\n  MAX(price) as most_expensive\nFROM products;\n\n-- Date range\nSELECT \n  MIN(created_at) as first_user,\n  MAX(created_at) as newest_user\nFROM users;\n```\n\n---\n\n## üéØ Your Task\n\nFind the minimum and maximum salary from employees.\n",
    "starter_code": "-- Get salary range\n\n",
    "solution_code": "SELECT MIN(salary), MAX(salary) FROM employees;",
    "expected_output": "min   | max\n45000 | 150000",
    "chapter_id": 203,
    "chapter_title": "Aggregations & Grouping"
  },
  "1039": {
    "id": 1039,
    "title": "GROUP BY Basics",
    "content": "# üìä GROUP BY Basics\n\n## Grouping Data\n\nGROUP BY divides rows into groups and applies aggregates to each:\n\n```sql\nSELECT department, COUNT(*)\nFROM employees\nGROUP BY department;\n```\n\nOutput:\n```\ndepartment | count\nSales      | 15\nMarketing  | 10\nEngineering| 25\n```\n\n## How GROUP BY Works\n\n1. Rows are grouped by the GROUP BY column(s)\n2. Aggregate functions (COUNT, SUM, etc.) run on each group\n3. One row per group is returned\n\n## Rules\n\nEvery non-aggregated column in SELECT must be in GROUP BY:\n\n```sql\n-- ‚úÖ Correct\nSELECT department, COUNT(*) FROM employees\nGROUP BY department;\n\n-- ‚ùå Error: name not in GROUP BY\nSELECT department, name, COUNT(*) FROM employees\nGROUP BY department;\n```\n\n---\n\n## üéØ Your Task\n\nCount orders per status.\n",
    "starter_code": "-- Group orders by status\n\n",
    "solution_code": "SELECT status, COUNT(*) FROM orders GROUP BY status;",
    "expected_output": "status    | count\ncompleted | 45\npending   | 12\ncancelled | 3",
    "chapter_id": 203,
    "chapter_title": "Aggregations & Grouping"
  },
  "1040": {
    "id": 1040,
    "title": "GROUP BY Multiple Columns",
    "content": "# üìà GROUP BY Multiple Columns\n\n## Grouping by Several Fields\n\nGroup by multiple columns for finer granularity:\n\n```sql\nSELECT year, month, SUM(sales)\nFROM revenue\nGROUP BY year, month;\n```\n\n## How It Works\n\nEach unique combination of values becomes a group:\n\n```sql\nSELECT department, job_title, AVG(salary)\nFROM employees\nGROUP BY department, job_title;\n```\n\nOutput:\n```\ndepartment | job_title | avg\nSales      | Manager   | 85000\nSales      | Rep       | 55000\nEngineering| Senior    | 120000\nEngineering| Junior    | 75000\n```\n\n## Order Matters (for readability)\n\n```sql\n-- Usually go from broad to specific\nGROUP BY country, state, city\nGROUP BY year, quarter, month\n```\n\n---\n\n## üéØ Your Task\n\nGet total sales grouped by category and year.\n",
    "starter_code": "-- Sales by category and year\n\n",
    "solution_code": "SELECT category, year, SUM(sales) FROM products GROUP BY category, year;",
    "expected_output": "category | year | sum\nBooks    | 2023 | 5000\nBooks    | 2024 | 7500\nGames    | 2023 | 3200",
    "chapter_id": 203,
    "chapter_title": "Aggregations & Grouping"
  },
  "1041": {
    "id": 1041,
    "title": "HAVING Clause",
    "content": "# üîç HAVING Clause\n\n## Filtering Groups\n\nHAVING filters groups AFTER aggregation:\n\n```sql\nSELECT department, COUNT(*)\nFROM employees\nGROUP BY department\nHAVING COUNT(*) > 10;\n```\n\n## Why Not WHERE?\n\nWHERE filters rows BEFORE grouping. HAVING filters AFTER:\n\n```sql\n-- WHERE: filter individual rows first\nSELECT department, COUNT(*)\nFROM employees\nWHERE salary > 50000  -- Filter rows\nGROUP BY department\nHAVING COUNT(*) > 5;  -- Then filter groups\n```\n\n## Execution Order\n\n1. FROM - get table\n2. WHERE - filter rows\n3. GROUP BY - create groups\n4. HAVING - filter groups\n5. SELECT - return results\n\n---\n\n## üéØ Your Task\n\nFind categories with more than 5 products.\n",
    "starter_code": "-- Categories with count > 5\n\n",
    "solution_code": "SELECT category, COUNT(*) FROM products GROUP BY category HAVING COUNT(*) > 5;",
    "expected_output": "category    | count\nElectronics | 12\nClothing    | 8",
    "chapter_id": 203,
    "chapter_title": "Aggregations & Grouping"
  },
  "1042": {
    "id": 1042,
    "title": "WHERE vs HAVING",
    "content": "# ‚öñÔ∏è WHERE vs HAVING\n\n## Key Difference\n\n| Clause | Filters | When |\n| --- | --- | --- |\n| WHERE | Individual rows | Before grouping |\n| HAVING | Groups | After grouping |\n\n## Example\n\n```sql\n-- Find departments where active employees average > $60k\nSELECT department, AVG(salary)\nFROM employees\nWHERE is_active = true     -- Filter rows first\nGROUP BY department\nHAVING AVG(salary) > 60000; -- Then filter groups\n```\n\n## Performance Tip\n\nFilter with WHERE whenever possible - it reduces data before grouping:\n\n```sql\n-- ‚úÖ More efficient: filter early\nWHERE status = 'active'\nGROUP BY category\n\n-- ‚ùå Less efficient: group all, filter late\nGROUP BY category\nHAVING status = 'active'  -- This doesn't even work!\n```\n\n---\n\n## üéØ Your Task\n\nFind customers with total orders > 1000, only counting completed orders.\n",
    "starter_code": "-- Filter completed orders first, then group\n\n",
    "solution_code": "SELECT customer_id, SUM(amount) FROM orders WHERE status = 'completed' GROUP BY customer_id HAVING SUM(amount) > 1000;",
    "expected_output": "customer_id | sum\n101         | 2500\n103         | 1200",
    "chapter_id": 203,
    "chapter_title": "Aggregations & Grouping"
  },
  "1043": {
    "id": 1043,
    "title": "Why We Need Joins",
    "content": "# üîó Why We Need Joins\n\n## Data Lives in Multiple Tables\n\nReal databases split data across tables to avoid duplication:\n\n```\n‚îå‚îÄ orders ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ customers ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ id ‚îÇ customer_id ‚îÇ     ‚îÇ id ‚îÇ name       ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§     ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ 1  ‚îÇ 101         ‚îÇ     ‚îÇ101 ‚îÇ Alice      ‚îÇ\n‚îÇ 2  ‚îÇ 102         ‚îÇ     ‚îÇ102 ‚îÇ Bob        ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n```\n\nTo see order with customer name, we need to JOIN!\n\n## What Joins Do\n\nJoins combine rows from two tables based on a related column:\n\n```sql\nSELECT orders.id, customers.name\nFROM orders\nJOIN customers ON orders.customer_id = customers.id;\n```\n\nResult:\n```\nid | name\n1  | Alice\n2  | Bob\n```\n\n---\n\n## üéØ Your Task\n\nSelect order_id and customer name by joining orders and customers tables.\n",
    "starter_code": "-- Join orders with customers\n\n",
    "solution_code": "SELECT orders.order_id, customers.name FROM orders JOIN customers ON orders.customer_id = customers.id;",
    "expected_output": "order_id | name\n1        | Alice\n2        | Alice\n3        | Bob",
    "chapter_id": 204,
    "chapter_title": "Joins Like a Pro"
  },
  "1044": {
    "id": 1044,
    "title": "INNER JOIN Basics",
    "content": "# üîó INNER JOIN Basics\n\n## The Default Join\n\nINNER JOIN returns only matching rows from both tables:\n\n```sql\nSELECT *\nFROM orders\nINNER JOIN customers ON orders.customer_id = customers.id;\n```\n\n## How INNER JOIN Works\n\n```\norders:     customers:       Result:\nid|cust_id  id|name          order_id|cust_id|name\n1 | 101     101|Alice   ‚Üí    1      |101    |Alice\n2 | 102     102|Bob          2      |102    |Bob\n3 | 999     103|Charlie      (order 3 excluded - no match!)\n```\n\nOrder 3 has no matching customer (999), so it's excluded.\n\n## Using Aliases\n\n```sql\nSELECT o.id, c.name\nFROM orders AS o\nINNER JOIN customers AS c ON o.customer_id = c.id;\n```\n\n---\n\n## üéØ Your Task\n\nJoin products and categories to show product_name with category_name.\n",
    "starter_code": "-- Inner join products with categories\n\n",
    "solution_code": "SELECT p.product_name, c.category_name FROM products p INNER JOIN categories c ON p.category_id = c.id;",
    "expected_output": "product_name | category_name\nWidget A     | Electronics\nWidget B     | Electronics\nGadget C     | Tools",
    "chapter_id": 204,
    "chapter_title": "Joins Like a Pro"
  },
  "1045": {
    "id": 1045,
    "title": "INNER JOIN Multiple Tables",
    "content": "# üîó INNER JOIN Multiple Tables\n\n## Chaining Joins\n\nJoin more than two tables by chaining:\n\n```sql\nSELECT o.id, c.name, p.product_name\nFROM orders o\nJOIN customers c ON o.customer_id = c.id\nJOIN products p ON o.product_id = p.id;\n```\n\n## Execution Order\n\nJoins execute left to right:\n1. orders JOIN customers ‚Üí creates temporary result\n2. temporary result JOIN products ‚Üí final result\n\n## Practical Example\n\n```sql\n-- Order details with customer and product info\nSELECT \n  o.order_date,\n  c.name AS customer,\n  p.name AS product,\n  oi.quantity,\n  oi.price\nFROM orders o\nJOIN customers c ON o.customer_id = c.id\nJOIN order_items oi ON o.id = oi.order_id\nJOIN products p ON oi.product_id = p.id;\n```\n\n---\n\n## üéØ Your Task\n\nJoin orders, customers, and products to get order_id, customer name, and product name.\n",
    "starter_code": "-- Three-table join\n\n",
    "solution_code": "SELECT o.order_id, c.name, p.product_name FROM orders o JOIN customers c ON o.customer_id = c.id JOIN products p ON o.product_id = p.id;",
    "expected_output": "order_id | name  | product_name\n1        | Alice | Widget A\n2        | Bob   | Gadget B",
    "chapter_id": 204,
    "chapter_title": "Joins Like a Pro"
  },
  "1046": {
    "id": 1046,
    "title": "LEFT JOIN Basics",
    "content": "# ‚¨ÖÔ∏è LEFT JOIN Basics\n\n## Keep All Left Rows\n\nLEFT JOIN returns all rows from the left table, even if no match:\n\n```sql\nSELECT c.name, o.id AS order_id\nFROM customers c\nLEFT JOIN orders o ON c.id = o.customer_id;\n```\n\n## How LEFT JOIN Works\n\n```\ncustomers:   orders:          Result:\nid|name      id|cust_id       name   |order_id\n1 |Alice     1 | 1       ‚Üí    Alice  | 1\n2 |Bob       2 | 1            Alice  | 2\n3 |Charlie                    Bob    | NULL\n                              Charlie| NULL\n```\n\nBob and Charlie have no orders, but they're still included with NULL.\n\n## Use Cases\n\n- Find customers who haven't ordered\n- Include all products, even unsold ones\n- Show all employees, even without assignments\n\n---\n\n## üéØ Your Task\n\nLeft join customers with orders to show all customers (even those without orders).\n",
    "starter_code": "-- Show all customers with their orders (or NULL)\n\n",
    "solution_code": "SELECT c.name, o.order_id FROM customers c LEFT JOIN orders o ON c.id = o.customer_id;",
    "expected_output": "name    | order_id\nAlice   | 1\nAlice   | 2\nBob     | 3\nCharlie | NULL",
    "chapter_id": 204,
    "chapter_title": "Joins Like a Pro"
  },
  "1047": {
    "id": 1047,
    "title": "LEFT JOIN for Missing Data",
    "content": "# üîç LEFT JOIN for Missing Data\n\n## Finding Rows Without Matches\n\nCombine LEFT JOIN with IS NULL to find missing relationships:\n\n```sql\n-- Customers who have never ordered\nSELECT c.name\nFROM customers c\nLEFT JOIN orders o ON c.id = o.customer_id\nWHERE o.id IS NULL;\n```\n\n## How It Works\n\n1. LEFT JOIN includes all customers\n2. Those without orders have NULL in order columns\n3. WHERE filters for only those NULLs\n\n## Common Patterns\n\n```sql\n-- Products never sold\nSELECT p.*\nFROM products p\nLEFT JOIN order_items oi ON p.id = oi.product_id\nWHERE oi.id IS NULL;\n\n-- Employees without managers\nSELECT e.name\nFROM employees e\nLEFT JOIN employees m ON e.manager_id = m.id\nWHERE m.id IS NULL;\n```\n\n---\n\n## üéØ Your Task\n\nFind customers who have no orders using LEFT JOIN.\n",
    "starter_code": "-- Find customers without any orders\n\n",
    "solution_code": "SELECT c.name FROM customers c LEFT JOIN orders o ON c.id = o.customer_id WHERE o.order_id IS NULL;",
    "expected_output": "name\nCharlie\nDiana",
    "chapter_id": 204,
    "chapter_title": "Joins Like a Pro"
  },
  "1048": {
    "id": 1048,
    "title": "RIGHT JOIN",
    "content": "# ‚û°Ô∏è RIGHT JOIN\n\n## Keep All Right Rows\n\nRIGHT JOIN is the opposite of LEFT JOIN - keeps all rows from the RIGHT table:\n\n```sql\nSELECT o.id, c.name\nFROM orders o\nRIGHT JOIN customers c ON o.customer_id = c.id;\n```\n\n## LEFT JOIN vs RIGHT JOIN\n\nThey're equivalent if you swap table order:\n\n```sql\n-- These produce the same results:\nFROM customers c LEFT JOIN orders o\nFROM orders o RIGHT JOIN customers c\n```\n\n## Best Practice\n\nMost developers prefer LEFT JOIN for consistency:\n\n```sql\n-- ‚úÖ Always LEFT JOIN (preferred)\nFROM main_table LEFT JOIN secondary_table\n\n-- ‚ùå Mixing LEFT and RIGHT is confusing\n```\n\n---\n\n## üéØ Your Task\n\nUse RIGHT JOIN to get all departments with their employees.\n",
    "starter_code": "-- Right join employees with departments\n\n",
    "solution_code": "SELECT e.name, d.department_name FROM employees e RIGHT JOIN departments d ON e.department_id = d.id;",
    "expected_output": "name  | department_name\nAlice | Sales\nBob   | Sales\nNULL  | Research",
    "chapter_id": 204,
    "chapter_title": "Joins Like a Pro"
  },
  "1049": {
    "id": 1049,
    "title": "FULL OUTER JOIN",
    "content": "# ‚ÜîÔ∏è FULL OUTER JOIN\n\n## Keep Everything\n\nFULL OUTER JOIN keeps all rows from BOTH tables:\n\n```sql\nSELECT c.name, o.id\nFROM customers c\nFULL OUTER JOIN orders o ON c.id = o.customer_id;\n```\n\n## Result\n\n```\ncustomers:   orders:          Result:\nid|name      id|cust_id       name   |order_id\n1 |Alice     1 | 1       ‚Üí    Alice  | 1\n2 |Bob       2 | 999          Bob    | NULL\n                              NULL   | 2 (orphan order)\n```\n\n## Use Cases\n\n- Data reconciliation between systems\n- Finding mismatches in both directions\n- Complete data comparison\n\n## Not Supported Everywhere\n\nMySQL doesn't have FULL OUTER JOIN - simulate with UNION.\n\n---\n\n## üéØ Your Task\n\nFull outer join customers and orders to see all customers and all orders.\n",
    "starter_code": "-- Full outer join\n\n",
    "solution_code": "SELECT c.name, o.order_id FROM customers c FULL OUTER JOIN orders o ON c.id = o.customer_id;",
    "expected_output": "name    | order_id\nAlice   | 1\nBob     | 2\nNULL    | 3\nCharlie | NULL",
    "chapter_id": 204,
    "chapter_title": "Joins Like a Pro"
  },
  "1050": {
    "id": 1050,
    "title": "CROSS JOIN",
    "content": "# ‚úñÔ∏è CROSS JOIN\n\n## Cartesian Product\n\nCROSS JOIN produces every combination of rows:\n\n```sql\nSELECT * FROM colors CROSS JOIN sizes;\n```\n\n## Result\n\n```\ncolors:    sizes:         Result:\ncolor      size           color|size\nRed        S         ‚Üí    Red  | S\nBlue       M              Red  | M\n           L              Blue | S\n                          Blue | M\n                          ... (6 rows total)\n```\n\n## Use Cases\n\n```sql\n-- Generate all date/product combinations for reports\nSELECT d.date, p.product_id\nFROM dates d\nCROSS JOIN products p;\n\n-- Create a multiplication table\nSELECT a.num, b.num, a.num * b.num AS product\nFROM numbers a CROSS JOIN numbers b;\n```\n\n## ‚ö†Ô∏è Warning: Row Explosion!\n\n100 rows √ó 100 rows = 10,000 result rows!\n\n---\n\n## üéØ Your Task\n\nCross join colors and sizes tables to get all combinations.\n",
    "starter_code": "-- All color/size combinations\n\n",
    "solution_code": "SELECT colors.color, sizes.size FROM colors CROSS JOIN sizes;",
    "expected_output": "color | size\nRed   | S\nRed   | M\nBlue  | S\nBlue  | M",
    "chapter_id": 204,
    "chapter_title": "Joins Like a Pro"
  },
  "1051": {
    "id": 1051,
    "title": "Join Cardinality",
    "content": "# üìä Join Cardinality\n\n## Understanding Relationships\n\n**Cardinality** describes how many rows match between tables:\n\n| Type | Description | Example |\n| --- | --- | --- |\n| 1:1 | One matches one | User ‚Üí Profile |\n| 1:N | One matches many | Customer ‚Üí Orders |\n| N:N | Many match many | Students ‚Üî Courses |\n\n## Why This Matters\n\nCardinality affects your result row count!\n\n```sql\n-- 1:N join may increase rows:\n-- 1 customer with 3 orders = 3 result rows\nSELECT c.name, o.id\nFROM customers c\nJOIN orders o ON c.id = o.customer_id;\n```\n\n## Checking Cardinality\n\n```sql\n-- Find if 1:N relationship exists\nSELECT customer_id, COUNT(*)\nFROM orders\nGROUP BY customer_id\nHAVING COUNT(*) > 1;\n```\n\n---\n\n## üéØ Your Task\n\nFind customers with more than 2 orders.\n",
    "starter_code": "-- Customers with multiple orders\n\n",
    "solution_code": "SELECT customer_id, COUNT(*) as order_count FROM orders GROUP BY customer_id HAVING COUNT(*) > 2;",
    "expected_output": "customer_id | order_count\n101         | 5\n103         | 3",
    "chapter_id": 204,
    "chapter_title": "Joins Like a Pro"
  },
  "1052": {
    "id": 1052,
    "title": "Duplicate Rows in Joins",
    "content": "# ‚ö†Ô∏è Duplicate Rows in Joins\n\n## The Fanout Problem\n\nJoins can multiply your rows unexpectedly:\n\n```sql\n-- If customer 1 has 3 orders:\n-- Customer row appears 3 times in result!\nSELECT c.*, o.*\nFROM customers c\nJOIN orders o ON c.id = o.customer_id;\n```\n\n## Aggregation Errors\n\nThis breaks aggregations:\n\n```sql\n-- WRONG: Customer revenue counted 3 times!\nSELECT SUM(c.lifetime_value)\nFROM customers c\nJOIN orders o ON c.id = o.customer_id;\n\n-- RIGHT: Aggregate before joining\nWITH order_totals AS (\n  SELECT customer_id, SUM(amount) AS total\n  FROM orders GROUP BY customer_id\n)\nSELECT c.name, ot.total\nFROM customers c\nJOIN order_totals ot ON c.id = ot.customer_id;\n```\n\n---\n\n## üéØ Your Task\n\nJoin customers with orders and count distinct order IDs per customer.\n",
    "starter_code": "-- Count orders per customer using join\n\n",
    "solution_code": "SELECT c.name, COUNT(DISTINCT o.order_id) as orders FROM customers c JOIN orders o ON c.id = o.customer_id GROUP BY c.name;",
    "expected_output": "name  | orders\nAlice | 3\nBob   | 2",
    "chapter_id": 204,
    "chapter_title": "Joins Like a Pro"
  },
  "1053": {
    "id": 1053,
    "title": "Self Joins",
    "content": "# üîÑ Self Joins\n\n## Joining a Table to Itself\n\nSelf joins compare rows within the same table:\n\n```sql\nSELECT e.name AS employee, m.name AS manager\nFROM employees e\nJOIN employees m ON e.manager_id = m.id;\n```\n\n## Use Cases\n\n**Hierarchies (employee ‚Üí manager):**\n```sql\nSELECT e.name, m.name AS reports_to\nFROM employees e\nLEFT JOIN employees m ON e.manager_id = m.id;\n```\n\n**Comparing rows:**\n```sql\n-- Find products with same price\nSELECT a.name, b.name, a.price\nFROM products a\nJOIN products b ON a.price = b.price AND a.id < b.id;\n```\n\n## Aliases are Required\n\nMust use different aliases for the same table:\n\n```sql\nFROM employees e  -- First reference\nJOIN employees m  -- Second reference\n```\n\n---\n\n## üéØ Your Task\n\nSelf join employees to show each employee with their manager's name.\n",
    "starter_code": "-- Employee and their manager\n\n",
    "solution_code": "SELECT e.name AS employee, m.name AS manager FROM employees e LEFT JOIN employees m ON e.manager_id = m.id;",
    "expected_output": "employee | manager\nAlice    | NULL\nBob      | Alice\nCharlie  | Alice",
    "chapter_id": 204,
    "chapter_title": "Joins Like a Pro"
  },
  "1054": {
    "id": 1054,
    "title": "Join Best Practices",
    "content": "# ‚úÖ Join Best Practices\n\n## 1. Use Explicit JOIN Syntax\n\n```sql\n-- ‚úÖ Explicit (clear and modern)\nSELECT * FROM orders o\nJOIN customers c ON o.customer_id = c.id;\n\n-- ‚ùå Implicit (old style, harder to read)\nSELECT * FROM orders o, customers c\nWHERE o.customer_id = c.id;\n```\n\n## 2. Always Qualify Column Names\n\n```sql\n-- ‚úÖ Clear which table each column comes from\nSELECT o.id, c.name, o.amount\n\n-- ‚ùå Ambiguous when both tables have 'id'\nSELECT id, name, amount\n```\n\n## 3. Use Consistent Alias Conventions\n\n```sql\nFROM customers c      -- First letter\nJOIN orders o\nJOIN order_items oi   -- Two letters for longer names\n```\n\n## 4. Filter Early\n\n```sql\n-- ‚úÖ Filter before join (faster)\nFROM orders o\nJOIN customers c ON o.customer_id = c.id\nWHERE o.status = 'completed'\n```\n\n---\n\n## üéØ Your Task\n\nWrite a clean join query for orders and customers using proper aliases and explicit syntax.\n",
    "starter_code": "-- Clean, readable join\n\n",
    "solution_code": "SELECT o.order_id, o.amount, c.name AS customer_name FROM orders o INNER JOIN customers c ON o.customer_id = c.id WHERE o.status = 'completed';",
    "expected_output": "order_id | amount | customer_name\n1        | 99.99  | Alice\n3        | 149.99 | Bob",
    "chapter_id": 204,
    "chapter_title": "Joins Like a Pro"
  },
  "1055": {
    "id": 1055,
    "title": "üèõÔ∏è Query Architect Challenge",
    "content": "# üèõÔ∏è BOSS BATTLE: The Query Architect\n\nThe Query Architect tests your mastery of SQL fundamentals. Prove your skills to advance!\n\n## The Challenge\n\nCombine everything from Chapters 0-4:\n- SELECT with filtering and sorting\n- Aggregations and GROUP BY\n- JOIN operations\n- NULL handling\n\n## Your Mission\n\nWrite a query that shows:\n1. Customer name\n2. Number of orders they've placed\n3. Total amount spent\n4. Average order value\n\nOnly include customers who have spent more than $200 total.\nSort by total spent descending.\n\n---\n\n## üéØ Complete the Challenge\n\nJoin customers and orders, group by customer, filter totals > 200, order by total descending.\n",
    "starter_code": "-- The Query Architect Challenge\n-- Show customer name, order count, total spent, and average\n-- Only customers with total > 200\n-- Sort by total descending\n\n",
    "solution_code": "SELECT \n  c.name,\n  COUNT(o.order_id) AS order_count,\n  SUM(o.amount) AS total_spent,\n  ROUND(AVG(o.amount), 2) AS avg_order\nFROM customers c\nJOIN orders o ON c.id = o.customer_id\nGROUP BY c.name\nHAVING SUM(o.amount) > 200\nORDER BY total_spent DESC;",
    "expected_output": "name  | order_count | total_spent | avg_order\nBob   | 5           | 750.00      | 150.00\nAlice | 3           | 450.00      | 150.00",
    "chapter_id": 250,
    "chapter_title": "Query Architect Boss"
  },
  "1056": {
    "id": 1056,
    "title": "Subquery in WHERE",
    "content": "# üéØ Subquery in WHERE\n\n## What is a Subquery?\n\nA **subquery** is a query inside another query. The inner query runs first, then its result is used by the outer query.\n\n```sql\nSELECT * FROM employees\nWHERE salary > (SELECT AVG(salary) FROM employees);\n```\n\n## How It Works\n\n1. Inner query runs: `SELECT AVG(salary)` ‚Üí 75000\n2. Outer query becomes: `WHERE salary > 75000`\n3. Returns employees above average salary\n\n## Subqueries Return Different Things\n\n| Type | Returns | Use With |\n| --- | --- | --- |\n| Scalar | Single value | =, >, <, etc. |\n| List | Multiple values | IN, NOT IN |\n| Table | Rows & columns | FROM, JOIN |\n\n---\n\n## üéØ Your Task\n\nFind products priced above the average price.\n",
    "starter_code": "-- Products above average price\n\n",
    "solution_code": "SELECT * FROM products WHERE price > (SELECT AVG(price) FROM products);",
    "expected_output": "id | name     | price\n2  | Widget B | 99.99\n4  | Premium  | 149.99",
    "chapter_id": 205,
    "chapter_title": "Subqueries & Set Operations"
  },
  "1057": {
    "id": 1057,
    "title": "IN with Subquery",
    "content": "# üìã IN with Subquery\n\n## Matching Against a List of Values\n\nUse IN with a subquery to check if a value exists in another table's results:\n\n```sql\nSELECT * FROM customers\nWHERE id IN (SELECT customer_id FROM orders);\n```\n\nThis finds customers who have placed at least one order.\n\n## How It Works\n\n1. Subquery returns list: (101, 102, 105)\n2. Outer query becomes: `WHERE id IN (101, 102, 105)`\n\n## NOT IN\n\n```sql\n-- Customers who have NEVER ordered\nSELECT * FROM customers\nWHERE id NOT IN (SELECT customer_id FROM orders);\n```\n\n‚ö†Ô∏è Warning: NOT IN with NULLs can return no rows!\n\n---\n\n## üéØ Your Task\n\nFind customers who have placed orders using IN with a subquery.\n",
    "starter_code": "-- Customers with orders\n\n",
    "solution_code": "SELECT * FROM customers WHERE id IN (SELECT customer_id FROM orders);",
    "expected_output": "id  | name  | email\n101 | Alice | a@mail.com\n102 | Bob   | b@mail.com",
    "chapter_id": 205,
    "chapter_title": "Subqueries & Set Operations"
  },
  "1058": {
    "id": 1058,
    "title": "EXISTS Operator",
    "content": "# ‚úÖ EXISTS Operator\n\n## Checking for Row Existence\n\nEXISTS returns TRUE if the subquery returns any rows:\n\n```sql\nSELECT * FROM customers c\nWHERE EXISTS (\n  SELECT 1 FROM orders o\n  WHERE o.customer_id = c.id\n);\n```\n\n## EXISTS vs IN\n\n| Feature | EXISTS | IN |\n| --- | --- | --- |\n| Returns | TRUE/FALSE | Matches value |\n| With NULLs | Handles well | Problematic |\n| Performance | Often faster | Depends |\n| Correlated | Usually yes | No |\n\n## The Pattern\n\n```sql\n-- EXISTS typically uses correlation\nSELECT * FROM table1 t1\nWHERE EXISTS (\n  SELECT 1 FROM table2 t2\n  WHERE t2.foreign_key = t1.id  -- Correlated!\n);\n```\n\n---\n\n## üéØ Your Task\n\nFind departments that have at least one employee using EXISTS.\n",
    "starter_code": "-- Departments with employees\n\n",
    "solution_code": "SELECT * FROM departments d WHERE EXISTS (SELECT 1 FROM employees e WHERE e.department_id = d.id);",
    "expected_output": "id | name\n1  | Sales\n2  | Engineering",
    "chapter_id": 205,
    "chapter_title": "Subqueries & Set Operations"
  },
  "1059": {
    "id": 1059,
    "title": "NOT EXISTS",
    "content": "# ‚ùå NOT EXISTS\n\n## Finding Missing Relationships\n\nNOT EXISTS returns TRUE when the subquery returns NO rows:\n\n```sql\n-- Customers without orders\nSELECT * FROM customers c\nWHERE NOT EXISTS (\n  SELECT 1 FROM orders o\n  WHERE o.customer_id = c.id\n);\n```\n\n## NOT EXISTS vs LEFT JOIN + NULL\n\nBoth achieve the same result:\n\n```sql\n-- NOT EXISTS version\nSELECT * FROM customers c\nWHERE NOT EXISTS (SELECT 1 FROM orders WHERE customer_id = c.id);\n\n-- LEFT JOIN version\nSELECT c.* FROM customers c\nLEFT JOIN orders o ON c.id = o.customer_id\nWHERE o.id IS NULL;\n```\n\n## NOT EXISTS is NULL-safe\n\nUnlike NOT IN, NOT EXISTS handles NULLs correctly!\n\n---\n\n## üéØ Your Task\n\nFind products that have never been ordered using NOT EXISTS.\n",
    "starter_code": "-- Products never ordered\n\n",
    "solution_code": "SELECT * FROM products p WHERE NOT EXISTS (SELECT 1 FROM order_items oi WHERE oi.product_id = p.id);",
    "expected_output": "id | name     | price\n5  | Widget E | 29.99",
    "chapter_id": 205,
    "chapter_title": "Subqueries & Set Operations"
  },
  "1060": {
    "id": 1060,
    "title": "Scalar Subqueries",
    "content": "# üî¢ Scalar Subqueries\n\n## Returning a Single Value\n\nA **scalar subquery** returns exactly one value (one row, one column):\n\n```sql\nSELECT \n  name,\n  salary,\n  salary - (SELECT AVG(salary) FROM employees) AS diff_from_avg\nFROM employees;\n```\n\n## Where to Use Scalar Subqueries\n\n```sql\n-- In SELECT\nSELECT name, (SELECT MAX(salary) FROM employees) AS max_salary\n\n-- In WHERE\nWHERE price = (SELECT MAX(price) FROM products)\n\n-- In calculations\nSELECT salary / (SELECT AVG(salary) FROM employees) AS salary_ratio\n```\n\n## ‚ö†Ô∏è Error If Not Scalar\n\nIf subquery returns multiple rows, you get an error!\n\n```sql\n-- ERROR: subquery returned more than one row\nWHERE id = (SELECT id FROM users WHERE active = true)\n```\n\n---\n\n## üéØ Your Task\n\nShow each product with its price and the max price across all products.\n",
    "starter_code": "-- Product with max price comparison\n\n",
    "solution_code": "SELECT name, price, (SELECT MAX(price) FROM products) AS max_price FROM products;",
    "expected_output": "name     | price | max_price\nWidget A | 29.99 | 149.99\nWidget B | 99.99 | 149.99\nPremium  | 149.99| 149.99",
    "chapter_id": 205,
    "chapter_title": "Subqueries & Set Operations"
  },
  "1061": {
    "id": 1061,
    "title": "Correlated Subqueries",
    "content": "# üîó Correlated Subqueries\n\n## Subqueries That Reference the Outer Query\n\nA **correlated subquery** uses values from the outer query:\n\n```sql\n-- Employees earning above their department's average\nSELECT * FROM employees e\nWHERE salary > (\n  SELECT AVG(salary) FROM employees\n  WHERE department_id = e.department_id  -- References outer e!\n);\n```\n\n## How It Works\n\nFor EACH outer row:\n1. Run subquery using that row's values\n2. Evaluate WHERE condition\n3. Include or exclude the row\n\n## Performance Consideration\n\nCorrelated subqueries run once per outer row - can be slow on large tables!\n\n```sql\n-- Consider rewriting with JOINs or Window functions\n-- for better performance\n```\n\n---\n\n## üéØ Your Task\n\nFind employees earning more than their department's average salary.\n",
    "starter_code": "-- Above department average\n\n",
    "solution_code": "SELECT * FROM employees e WHERE salary > (SELECT AVG(salary) FROM employees WHERE department_id = e.department_id);",
    "expected_output": "id | name  | department_id | salary\n1  | Alice | 1             | 90000\n4  | Diana | 2             | 85000",
    "chapter_id": 205,
    "chapter_title": "Subqueries & Set Operations"
  },
  "1062": {
    "id": 1062,
    "title": "UNION Operator",
    "content": "# üîÄ UNION Operator\n\n## Combining Result Sets\n\nUNION combines rows from multiple queries into one result:\n\n```sql\nSELECT name FROM employees\nUNION\nSELECT name FROM contractors;\n```\n\n## UNION Rules\n\n1. Same number of columns\n2. Compatible data types\n3. Column names come from first query\n4. **Duplicates are removed** (by default)\n\n## Example\n\n```sql\n-- All people (employees + contractors)\nSELECT name, 'Employee' AS type FROM employees\nUNION\nSELECT name, 'Contractor' AS type FROM contractors;\n```\n\n---\n\n## üéØ Your Task\n\nCombine names from customers and suppliers tables.\n",
    "starter_code": "-- All names from both tables\n\n",
    "solution_code": "SELECT name FROM customers UNION SELECT name FROM suppliers;",
    "expected_output": "name\nAlice\nBob\nAcme Corp\nGlobal Inc",
    "chapter_id": 205,
    "chapter_title": "Subqueries & Set Operations"
  },
  "1063": {
    "id": 1063,
    "title": "UNION ALL",
    "content": "# üìã UNION ALL\n\n## Keep All Rows (Including Duplicates)\n\nUNION ALL combines results WITHOUT removing duplicates:\n\n```sql\nSELECT name FROM employees\nUNION ALL\nSELECT name FROM contractors;\n```\n\n## UNION vs UNION ALL\n\n| Operation | Duplicates | Performance |\n| --- | --- | --- |\n| UNION | Removed | Slower (sorts) |\n| UNION ALL | Kept | Faster |\n\n## When to Use Each\n\n```sql\n-- UNION: When you need unique values\n-- Customer names across regions (no duplicates)\n\n-- UNION ALL: When duplicates are okay/needed\n-- All transactions from multiple sources (keep all)\n```\n\n## Performance Tip\n\nUse UNION ALL unless you specifically need duplicates removed.\n\n---\n\n## üéØ Your Task\n\nCombine all orders from 2023 and 2024 using UNION ALL.\n",
    "starter_code": "-- All orders from both years\n\n",
    "solution_code": "SELECT * FROM orders WHERE EXTRACT(YEAR FROM order_date) = 2023 UNION ALL SELECT * FROM orders WHERE EXTRACT(YEAR FROM order_date) = 2024;",
    "expected_output": "order_id | amount | order_date\n1        | 100.00 | 2023-03-15\n2        | 150.00 | 2023-06-20\n3        | 200.00 | 2024-01-10",
    "chapter_id": 205,
    "chapter_title": "Subqueries & Set Operations"
  },
  "1064": {
    "id": 1064,
    "title": "INTERSECT and EXCEPT",
    "content": "# ‚ö° INTERSECT and EXCEPT\n\n## Set Theory in SQL\n\n**INTERSECT**: Rows in BOTH queries\n```sql\nSELECT name FROM customers\nINTERSECT\nSELECT name FROM premium_members;\n-- Names that are in BOTH tables\n```\n\n**EXCEPT**: Rows in first but NOT in second\n```sql\nSELECT name FROM customers\nEXCEPT\nSELECT name FROM churned_customers;\n-- Active customers (not churned)\n```\n\n## Visual Representation\n\n```\nINTERSECT:    EXCEPT:\n  ‚îå‚îÄ‚îÄ‚îÄ‚îê        ‚îå‚îÄ‚îÄ‚îÄ‚îê\n‚îå‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îê    ‚îå‚îÄ‚îÇXXX‚îÇ‚îÄ‚îê\n‚îÇ ‚îÇ‚ñà‚ñà‚ñà‚îÇ ‚îÇ    ‚îÇ ‚îÇ   ‚îÇ ‚îÇ\n‚îî‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îò    ‚îî‚îÄ‚îÇ   ‚îÇ‚îÄ‚îò\n  ‚îî‚îÄ‚îÄ‚îÄ‚îò        ‚îî‚îÄ‚îÄ‚îÄ‚îò\n  Both         Only left\n```\n\n## Note: MySQL Compatibility\n\nMySQL doesn't support INTERSECT/EXCEPT directly - use JOIN or NOT IN instead.\n\n---\n\n## üéØ Your Task\n\nFind customer IDs that exist in both orders_2023 and orders_2024.\n",
    "starter_code": "-- Customers who ordered both years\n\n",
    "solution_code": "SELECT customer_id FROM orders_2023 INTERSECT SELECT customer_id FROM orders_2024;",
    "expected_output": "customer_id\n101\n103",
    "chapter_id": 205,
    "chapter_title": "Subqueries & Set Operations"
  },
  "1065": {
    "id": 1065,
    "title": "Introduction to CTEs",
    "content": "# üì¶ Introduction to CTEs\n\n## What is a CTE?\n\nA **Common Table Expression (CTE)** is a named temporary result set:\n\n```sql\nWITH high_value_orders AS (\n  SELECT * FROM orders WHERE amount > 100\n)\nSELECT * FROM high_value_orders;\n```\n\n## Why Use CTEs?\n\n1. **Readability**: Break complex queries into named steps\n2. **Reusability**: Reference the same result multiple times\n3. **Maintenance**: Easier to debug and modify\n\n## CTE vs Subquery\n\n```sql\n-- Subquery (inline, harder to read)\nSELECT * FROM (SELECT * FROM orders WHERE amount > 100) AS ho;\n\n-- CTE (named, clearer)\nWITH high_value_orders AS (...)\nSELECT * FROM high_value_orders;\n```\n\n---\n\n## üéØ Your Task\n\nCreate a CTE called 'recent_orders' for orders in 2024, then select from it.\n",
    "starter_code": "-- CTE for 2024 orders\n\n",
    "solution_code": "WITH recent_orders AS (\n  SELECT * FROM orders WHERE order_date >= '2024-01-01'\n)\nSELECT * FROM recent_orders;",
    "expected_output": "order_id | customer_id | amount | order_date\n5        | 101         | 150.00 | 2024-01-15\n6        | 102         | 200.00 | 2024-02-20",
    "chapter_id": 206,
    "chapter_title": "CTEs (WITH Clause)"
  },
  "1066": {
    "id": 1066,
    "title": "Basic CTE Syntax",
    "content": "# üìù Basic CTE Syntax\n\n## The WITH Clause\n\n```sql\nWITH cte_name AS (\n  -- Your query here\n  SELECT column1, column2\n  FROM table_name\n  WHERE condition\n)\n-- Main query that uses the CTE\nSELECT * FROM cte_name;\n```\n\n## Key Points\n\n1. CTE starts with `WITH`\n2. CTE name comes before `AS`\n3. Query goes inside parentheses\n4. Main query comes AFTER the CTE\n\n## CTE Scope\n\nA CTE only exists for the immediately following statement:\n\n```sql\nWITH my_cte AS (SELECT 1 AS n)\nSELECT * FROM my_cte;  -- Works!\n\nSELECT * FROM my_cte;  -- Error! CTE no longer exists\n```\n\n---\n\n## üéØ Your Task\n\nCreate a CTE 'active_users' for users where is_active = true.\n",
    "starter_code": "-- CTE for active users\n\n",
    "solution_code": "WITH active_users AS (\n  SELECT * FROM users WHERE is_active = true\n)\nSELECT name, email FROM active_users;",
    "expected_output": "name  | email\nAlice | alice@mail.com\nBob   | bob@mail.com",
    "chapter_id": 206,
    "chapter_title": "CTEs (WITH Clause)"
  },
  "1067": {
    "id": 1067,
    "title": "CTEs vs Subqueries",
    "content": "# ‚öñÔ∏è CTEs vs Subqueries\n\n## Comparison\n\n| Feature | CTE | Subquery |\n| --- | --- | --- |\n| Readability | ‚úÖ Named, clear | ‚ùå Inline, nested |\n| Reusability | ‚úÖ Use multiple times | ‚ùå Repeat code |\n| Recursion | ‚úÖ Supported | ‚ùå Not supported |\n| Scope | Statement only | Immediate context |\n\n## When to Use CTEs\n\n```sql\n-- Complex multi-step transformations\n-- When you reference result multiple times\n-- For recursive queries\n-- When readability matters\n```\n\n## When Subqueries Are Fine\n\n```sql\n-- Simple one-off filters\n-- Scalar values: (SELECT MAX(...))\n-- EXISTS checks\n```\n\n---\n\n## üéØ Your Task\n\nRewrite using a CTE: SELECT * FROM (SELECT * FROM products WHERE price > 50) AS expensive;\n",
    "starter_code": "-- Convert subquery to CTE\n\n",
    "solution_code": "WITH expensive AS (\n  SELECT * FROM products WHERE price > 50\n)\nSELECT * FROM expensive;",
    "expected_output": "id | name     | price\n2  | Widget B | 99.99\n3  | Premium  | 149.99",
    "chapter_id": 206,
    "chapter_title": "CTEs (WITH Clause)"
  },
  "1068": {
    "id": 1068,
    "title": "Multiple CTEs",
    "content": "# üìä Multiple CTEs\n\n## Defining Multiple CTEs\n\nSeparate multiple CTEs with commas:\n\n```sql\nWITH \n  cte1 AS (\n    SELECT * FROM table1\n  ),\n  cte2 AS (\n    SELECT * FROM table2\n  )\nSELECT * FROM cte1\nJOIN cte2 ON cte1.id = cte2.id;\n```\n\n## Real Example\n\n```sql\nWITH \n  order_totals AS (\n    SELECT customer_id, SUM(amount) AS total\n    FROM orders GROUP BY customer_id\n  ),\n  high_spenders AS (\n    SELECT * FROM order_totals WHERE total > 1000\n  )\nSELECT c.name, h.total\nFROM customers c\nJOIN high_spenders h ON c.id = h.customer_id;\n```\n\n---\n\n## üéØ Your Task\n\nCreate two CTEs: 'sales_dept' and 'high_salary', then join them.\n",
    "starter_code": "-- Two CTEs\n\n",
    "solution_code": "WITH \n  sales_dept AS (\n    SELECT * FROM employees WHERE department = 'Sales'\n  ),\n  high_salary AS (\n    SELECT * FROM sales_dept WHERE salary > 60000\n  )\nSELECT name, salary FROM high_salary;",
    "expected_output": "name  | salary\nAlice | 75000\nBob   | 80000",
    "chapter_id": 206,
    "chapter_title": "CTEs (WITH Clause)"
  },
  "1069": {
    "id": 1069,
    "title": "Chained CTEs",
    "content": "# üîó Chained CTEs\n\n## CTEs Referencing Other CTEs\n\nLater CTEs can reference earlier ones:\n\n```sql\nWITH \n  step1 AS (\n    SELECT * FROM orders\n  ),\n  step2 AS (\n    SELECT customer_id, SUM(amount) AS total\n    FROM step1  -- References step1!\n    GROUP BY customer_id\n  ),\n  step3 AS (\n    SELECT * FROM step2 WHERE total > 100  -- References step2!\n  )\nSELECT * FROM step3;\n```\n\n## Building Pipelines\n\n```sql\nWITH \n  raw_data AS (...),\n  cleaned AS (SELECT ... FROM raw_data),\n  aggregated AS (SELECT ... FROM cleaned),\n  final AS (SELECT ... FROM aggregated)\nSELECT * FROM final;\n```\n\nThis creates a clear data transformation pipeline!\n\n---\n\n## üéØ Your Task\n\nCreate chained CTEs: first filter orders > 100, then sum by customer.\n",
    "starter_code": "-- Chain CTEs\n\n",
    "solution_code": "WITH \n  big_orders AS (\n    SELECT * FROM orders WHERE amount > 100\n  ),\n  customer_totals AS (\n    SELECT customer_id, SUM(amount) AS total FROM big_orders GROUP BY customer_id\n  )\nSELECT * FROM customer_totals;",
    "expected_output": "customer_id | total\n101         | 500.00\n102         | 350.00",
    "chapter_id": 206,
    "chapter_title": "CTEs (WITH Clause)"
  },
  "1070": {
    "id": 1070,
    "title": "CTEs for Readability",
    "content": "# üìñ CTEs for Readability\n\n## Before: Hard to Read\n\n```sql\nSELECT c.name, ot.total\nFROM customers c\nJOIN (\n  SELECT customer_id, SUM(amount) AS total\n  FROM (\n    SELECT * FROM orders WHERE status = 'completed'\n  ) completed_orders\n  GROUP BY customer_id\n) ot ON c.id = ot.customer_id\nWHERE ot.total > 1000;\n```\n\n## After: Clear and Readable\n\n```sql\nWITH \n  completed_orders AS (\n    SELECT * FROM orders WHERE status = 'completed'\n  ),\n  order_totals AS (\n    SELECT customer_id, SUM(amount) AS total\n    FROM completed_orders\n    GROUP BY customer_id\n  ),\n  high_value_customers AS (\n    SELECT * FROM order_totals WHERE total > 1000\n  )\nSELECT c.name, h.total\nFROM customers c\nJOIN high_value_customers h ON c.id = h.customer_id;\n```\n\n---\n\n## üéØ Your Task\n\nRefactor into CTEs: filter active products, then get category counts.\n",
    "starter_code": "-- Make readable with CTEs\n\n",
    "solution_code": "WITH \n  active_products AS (\n    SELECT * FROM products WHERE is_active = true\n  ),\n  category_counts AS (\n    SELECT category, COUNT(*) AS count FROM active_products GROUP BY category\n  )\nSELECT * FROM category_counts ORDER BY count DESC;",
    "expected_output": "category    | count\nElectronics | 15\nClothing    | 10\nBooks       | 5",
    "chapter_id": 206,
    "chapter_title": "CTEs (WITH Clause)"
  },
  "1071": {
    "id": 1071,
    "title": "Reusing CTEs",
    "content": "# üîÑ Reusing CTEs\n\n## Reference a CTE Multiple Times\n\nUnlike subqueries, CTEs can be referenced multiple times:\n\n```sql\nWITH monthly_sales AS (\n  SELECT EXTRACT(MONTH FROM order_date) AS month, SUM(amount) AS total\n  FROM orders\n  GROUP BY 1\n)\nSELECT \n  m1.month,\n  m1.total,\n  m1.total - LAG(m1.total) OVER (ORDER BY m1.month) AS change\nFROM monthly_sales m1;\n```\n\n## Comparison Example\n\n```sql\nWITH stats AS (\n  SELECT AVG(salary) AS avg_sal, MAX(salary) AS max_sal FROM employees\n)\nSELECT \n  e.name,\n  e.salary,\n  s.avg_sal,\n  e.salary - s.avg_sal AS diff\nFROM employees e, stats s;\n```\n\n---\n\n## üéØ Your Task\n\nCreate a stats CTE and use it to compare each employee's salary to the average.\n",
    "starter_code": "-- Compare to average using CTE\n\n",
    "solution_code": "WITH stats AS (\n  SELECT AVG(salary) AS avg_salary FROM employees\n)\nSELECT e.name, e.salary, s.avg_salary, e.salary - s.avg_salary AS diff\nFROM employees e, stats s;",
    "expected_output": "name    | salary | avg_salary | diff\nAlice   | 75000  | 70000      | 5000\nBob     | 65000  | 70000      | -5000",
    "chapter_id": 206,
    "chapter_title": "CTEs (WITH Clause)"
  },
  "1072": {
    "id": 1072,
    "title": "Recursive CTEs Intro",
    "content": "# üîÅ Recursive CTEs Intro\n\n## Self-Referencing Queries\n\nRecursive CTEs can reference themselves - great for hierarchies:\n\n```sql\nWITH RECURSIVE org_chart AS (\n  -- Base case: top-level (no manager)\n  SELECT id, name, manager_id, 1 AS level\n  FROM employees\n  WHERE manager_id IS NULL\n  \n  UNION ALL\n  \n  -- Recursive case: employees with managers\n  SELECT e.id, e.name, e.manager_id, o.level + 1\n  FROM employees e\n  JOIN org_chart o ON e.manager_id = o.id\n)\nSELECT * FROM org_chart;\n```\n\n## Use Cases\n\n- Organizational hierarchies\n- Bill of materials (parts containing parts)\n- File system paths\n- Graph traversal\n\n---\n\n## üéØ Your Task\n\nSelect all from the employees table with a simple non-recursive CTE (intro only).\n",
    "starter_code": "-- Simple CTE as recursive intro\n\n",
    "solution_code": "WITH emp_list AS (\n  SELECT id, name, manager_id FROM employees\n)\nSELECT * FROM emp_list;",
    "expected_output": "id | name    | manager_id\n1  | Sarah   | NULL\n2  | Alice   | 1\n3  | Bob     | 1",
    "chapter_id": 206,
    "chapter_title": "CTEs (WITH Clause)"
  },
  "1073": {
    "id": 1073,
    "title": "CTE Best Practices",
    "content": "# ‚úÖ CTE Best Practices\n\n## 1. Use Descriptive Names\n\n```sql\n-- ‚úÖ Clear names\nWITH active_subscriptions AS ...\n\n-- ‚ùå Vague names\nWITH temp AS ...\nWITH data AS ...\n```\n\n## 2. One Logical Step Per CTE\n\n```sql\n-- ‚úÖ Focused CTEs\nWITH filtered AS (... WHERE ...),\n     aggregated AS (... GROUP BY ...),\n     ranked AS (... ROW_NUMBER() ...)\n```\n\n## 3. Order CTEs by Dependency\n\n```sql\n-- ‚úÖ Dependencies flow downward\nWITH \n  raw AS (...),\n  clean AS (SELECT FROM raw),\n  final AS (SELECT FROM clean)\n```\n\n## 4. Don't Overuse CTEs\n\nSimple queries don't need CTEs - add complexity only when it adds clarity.\n\n---\n\n## üéØ Your Task\n\nWrite well-named CTEs: filter orders > 50, then get customer totals.\n",
    "starter_code": "-- Clear, well-named CTEs\n\n",
    "solution_code": "WITH \n  significant_orders AS (\n    SELECT * FROM orders WHERE amount > 50\n  ),\n  customer_revenue AS (\n    SELECT customer_id, SUM(amount) AS total\n    FROM significant_orders\n    GROUP BY customer_id\n  )\nSELECT * FROM customer_revenue ORDER BY total DESC;",
    "expected_output": "customer_id | total\n101         | 450.00\n102         | 300.00",
    "chapter_id": 206,
    "chapter_title": "CTEs (WITH Clause)"
  },
  "1074": {
    "id": 1074,
    "title": "What are Window Functions?",
    "content": "# ü™ü What are Window Functions?\n\n## Aggregate Without Grouping\n\nWindow functions let you calculate across related rows WITHOUT collapsing them:\n\n```sql\nSELECT \n  name,\n  department,\n  salary,\n  AVG(salary) OVER (PARTITION BY department) AS dept_avg\nFROM employees;\n```\n\n## Output\n\n```\nname    | department | salary | dept_avg\nAlice   | Sales      | 60000  | 65000\nBob     | Sales      | 70000  | 65000\nCharlie | Eng        | 80000  | 85000\nDiana   | Eng        | 90000  | 85000\n```\n\nNotice: All rows are kept, but each shows its department's average!\n\n## Window vs Regular Aggregates\n\n| Regular Aggregate | Window Function |\n| --- | --- |\n| Collapses rows | Keeps all rows |\n| Uses GROUP BY | Uses OVER |\n| One row per group | Original row count |\n\n---\n\n## üéØ Your Task\n\nShow each employee with the overall average salary using window function.\n",
    "starter_code": "-- Overall average alongside each row\n\n",
    "solution_code": "SELECT name, salary, AVG(salary) OVER () AS overall_avg FROM employees;",
    "expected_output": "name    | salary | overall_avg\nAlice   | 60000  | 75000\nBob     | 70000  | 75000\nCharlie | 80000  | 75000",
    "chapter_id": 207,
    "chapter_title": "Window Functions"
  },
  "1075": {
    "id": 1075,
    "title": "OVER Clause Basics",
    "content": "# üìä OVER Clause Basics\n\n## The OVER Clause Syntax\n\nEvery window function uses OVER to define its window:\n\n```sql\nfunction_name() OVER (window_specification)\n```\n\n## Window Specification Options\n\n```sql\nOVER ()                          -- Entire table\nOVER (PARTITION BY column)        -- Groups\nOVER (ORDER BY column)            -- Ordered\nOVER (PARTITION BY x ORDER BY y)  -- Both\n```\n\n## Examples\n\n```sql\n-- Total across all rows\nSUM(amount) OVER ()\n\n-- Total within each category\nSUM(amount) OVER (PARTITION BY category)\n\n-- Running total by date\nSUM(amount) OVER (ORDER BY order_date)\n```\n\n---\n\n## üéØ Your Task\n\nCalculate the total of all orders using SUM() OVER ().\n",
    "starter_code": "-- Total using window function\n\n",
    "solution_code": "SELECT order_id, amount, SUM(amount) OVER () AS total FROM orders;",
    "expected_output": "order_id | amount | total\n1        | 100    | 450\n2        | 150    | 450\n3        | 200    | 450",
    "chapter_id": 207,
    "chapter_title": "Window Functions"
  },
  "1076": {
    "id": 1076,
    "title": "PARTITION BY",
    "content": "# üì¶ PARTITION BY\n\n## Grouping Without Collapsing\n\nPARTITION BY splits data into groups for the window function:\n\n```sql\nSELECT \n  name,\n  department,\n  salary,\n  SUM(salary) OVER (PARTITION BY department) AS dept_total\nFROM employees;\n```\n\n## Comparison\n\n```sql\n-- GROUP BY: One row per department\nSELECT department, SUM(salary)\nFROM employees\nGROUP BY department;\n\n-- PARTITION BY: All rows, with department total added\nSELECT *, SUM(salary) OVER (PARTITION BY department)\nFROM employees;\n```\n\n## Multiple Partitions\n\n```sql\n-- Category AND year groups\nSUM(amount) OVER (PARTITION BY category, year)\n```\n\n---\n\n## üéØ Your Task\n\nShow each order with its customer's total order amount.\n",
    "starter_code": "-- Customer totals with PARTITION BY\n\n",
    "solution_code": "SELECT order_id, customer_id, amount, SUM(amount) OVER (PARTITION BY customer_id) AS customer_total FROM orders;",
    "expected_output": "order_id | customer_id | amount | customer_total\n1        | 101         | 100    | 250\n2        | 101         | 150    | 250\n3        | 102         | 200    | 200",
    "chapter_id": 207,
    "chapter_title": "Window Functions"
  },
  "1077": {
    "id": 1077,
    "title": "ORDER BY in Windows",
    "content": "# üîÑ ORDER BY in Windows\n\n## Running Calculations\n\nORDER BY in OVER creates running (cumulative) calculations:\n\n```sql\nSELECT \n  order_date,\n  amount,\n  SUM(amount) OVER (ORDER BY order_date) AS running_total\nFROM orders;\n```\n\n## Result\n\n```\norder_date | amount | running_total\n2024-01-01 | 100    | 100\n2024-01-02 | 150    | 250\n2024-01-03 | 80     | 330\n```\n\n## Frame Behavior\n\nWith ORDER BY, the default frame is \"unbounded preceding to current row\":\n\n```sql\n-- These are equivalent:\nSUM(amt) OVER (ORDER BY date)\nSUM(amt) OVER (ORDER BY date ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)\n```\n\n---\n\n## üéØ Your Task\n\nCalculate running total of sales by date.\n",
    "starter_code": "-- Running total by date\n\n",
    "solution_code": "SELECT order_date, amount, SUM(amount) OVER (ORDER BY order_date) AS running_total FROM orders;",
    "expected_output": "order_date | amount | running_total\n2024-01-01 | 100    | 100\n2024-01-02 | 150    | 250\n2024-01-03 | 200    | 450",
    "chapter_id": 207,
    "chapter_title": "Window Functions"
  },
  "1078": {
    "id": 1078,
    "title": "ROW_NUMBER",
    "content": "# üî¢ ROW_NUMBER\n\n## Assigning Unique Row Numbers\n\nROW_NUMBER assigns a sequential number to each row:\n\n```sql\nSELECT \n  name,\n  salary,\n  ROW_NUMBER() OVER (ORDER BY salary DESC) AS rank\nFROM employees;\n```\n\n## Result\n\n```\nname    | salary | rank\nDiana   | 90000  | 1\nCharlie | 80000  | 2\nBob     | 70000  | 3\nAlice   | 60000  | 4\n```\n\n## With PARTITION BY\n\nNumbers reset for each partition:\n\n```sql\nROW_NUMBER() OVER (PARTITION BY department ORDER BY salary DESC)\n-- Ranks within each department\n```\n\n## Common Use: Top N Per Group\n\n```sql\nWITH ranked AS (\n  SELECT *, ROW_NUMBER() OVER (PARTITION BY dept ORDER BY salary DESC) AS rn\n  FROM employees\n)\nSELECT * FROM ranked WHERE rn = 1;  -- Top earner per dept\n```\n\n---\n\n## üéØ Your Task\n\nNumber employees by salary descending.\n",
    "starter_code": "-- Row numbers by salary\n\n",
    "solution_code": "SELECT name, salary, ROW_NUMBER() OVER (ORDER BY salary DESC) AS row_num FROM employees;",
    "expected_output": "name  | salary | row_num\nBob   | 90000  | 1\nAlice | 75000  | 2\nTom   | 60000  | 3",
    "chapter_id": 207,
    "chapter_title": "Window Functions"
  },
  "1079": {
    "id": 1079,
    "title": "RANK and DENSE_RANK",
    "content": "# üèÜ RANK and DENSE_RANK\n\n## Handling Ties\n\n| Function | Ties | Gap After Tie? |\n| --- | --- | --- |\n| ROW_NUMBER | Arbitrary | N/A |\n| RANK | Same rank | Yes |\n| DENSE_RANK | Same rank | No |\n\n## Example\n\n```sql\nSELECT name, score,\n  ROW_NUMBER() OVER (ORDER BY score DESC) AS row_num,\n  RANK() OVER (ORDER BY score DESC) AS rank,\n  DENSE_RANK() OVER (ORDER BY score DESC) AS dense_rank\nFROM students;\n```\n\n## Result\n\n```\nname  | score | row_num | rank | dense_rank\nAlice | 95    | 1       | 1    | 1\nBob   | 95    | 2       | 1    | 1  (tie!)\nTom   | 90    | 3       | 3    | 2  (rank skips, dense doesn't)\nJane  | 85    | 4       | 4    | 3\n```\n\n---\n\n## üéØ Your Task\n\nRank products by price using DENSE_RANK.\n",
    "starter_code": "-- Dense rank by price\n\n",
    "solution_code": "SELECT name, price, DENSE_RANK() OVER (ORDER BY price DESC) AS price_rank FROM products;",
    "expected_output": "name     | price  | price_rank\nPremium  | 149.99 | 1\nWidget B | 99.99  | 2\nWidget A | 99.99  | 2\nBasic    | 29.99  | 3",
    "chapter_id": 207,
    "chapter_title": "Window Functions"
  },
  "1080": {
    "id": 1080,
    "title": "Running Totals with SUM",
    "content": "# ‚ûï Running Totals with SUM\n\n## Cumulative Sum\n\nSUM with ORDER BY creates a running total:\n\n```sql\nSELECT \n  date,\n  revenue,\n  SUM(revenue) OVER (ORDER BY date) AS cumulative_revenue\nFROM daily_sales;\n```\n\n## Result\n\n```\ndate       | revenue | cumulative_revenue\n2024-01-01 | 1000    | 1000\n2024-01-02 | 1500    | 2500\n2024-01-03 | 800     | 3300\n2024-01-04 | 1200    | 4500\n```\n\n## Running Totals Per Group\n\n```sql\n-- Running total within each month\nSUM(revenue) OVER (\n  PARTITION BY EXTRACT(MONTH FROM date)\n  ORDER BY date\n)\n```\n\n---\n\n## üéØ Your Task\n\nCalculate cumulative sales amount by order date.\n",
    "starter_code": "-- Cumulative sales\n\n",
    "solution_code": "SELECT order_date, amount, SUM(amount) OVER (ORDER BY order_date) AS cumulative_amount FROM orders;",
    "expected_output": "order_date | amount | cumulative_amount\n2024-01-01 | 100.00 | 100.00\n2024-01-02 | 150.00 | 250.00\n2024-01-03 | 200.00 | 450.00",
    "chapter_id": 207,
    "chapter_title": "Window Functions"
  },
  "1081": {
    "id": 1081,
    "title": "Moving Averages",
    "content": "# üìà Moving Averages\n\n## Rolling Window Calculations\n\nSpecify a frame to calculate over recent rows:\n\n```sql\n-- 3-day moving average\nSELECT \n  date,\n  sales,\n  AVG(sales) OVER (\n    ORDER BY date\n    ROWS BETWEEN 2 PRECEDING AND CURRENT ROW\n  ) AS moving_avg_3day\nFROM daily_sales;\n```\n\n## Frame Specifications\n\n```sql\nROWS BETWEEN 2 PRECEDING AND CURRENT ROW  -- Last 3 rows\nROWS BETWEEN 1 PRECEDING AND 1 FOLLOWING  -- 3 rows centered\nROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW  -- All previous\n```\n\n## Use Cases\n\n- Smoothing noisy data\n- Trend analysis\n- Anomaly detection\n\n---\n\n## üéØ Your Task\n\nCalculate 3-day moving average of daily revenue.\n",
    "starter_code": "-- 3-day moving average\n\n",
    "solution_code": "SELECT date, revenue, AVG(revenue) OVER (ORDER BY date ROWS BETWEEN 2 PRECEDING AND CURRENT ROW) AS moving_avg FROM daily_sales;",
    "expected_output": "date       | revenue | moving_avg\n2024-01-01 | 1000    | 1000.00\n2024-01-02 | 1500    | 1250.00\n2024-01-03 | 800     | 1100.00",
    "chapter_id": 207,
    "chapter_title": "Window Functions"
  },
  "1082": {
    "id": 1082,
    "title": "LAG Function",
    "content": "# ‚¨ÖÔ∏è LAG Function\n\n## Access Previous Row Values\n\nLAG gets a value from a previous row:\n\n```sql\nSELECT \n  order_date,\n  revenue,\n  LAG(revenue) OVER (ORDER BY order_date) AS prev_day_revenue\nFROM daily_revenue;\n```\n\n## Result\n\n```\norder_date | revenue | prev_day_revenue\n2024-01-01 | 1000    | NULL  (no previous)\n2024-01-02 | 1500    | 1000\n2024-01-03 | 1200    | 1500\n```\n\n## LAG with Offset and Default\n\n```sql\n-- 2 rows back, default to 0\nLAG(revenue, 2, 0) OVER (ORDER BY date)\n```\n\n## Calculate Change\n\n```sql\nSELECT \n  date,\n  revenue,\n  revenue - LAG(revenue) OVER (ORDER BY date) AS daily_change\nFROM revenue;\n```\n\n---\n\n## üéØ Your Task\n\nShow each order's amount and the previous order's amount.\n",
    "starter_code": "-- Previous order amount\n\n",
    "solution_code": "SELECT order_id, amount, LAG(amount) OVER (ORDER BY order_id) AS prev_amount FROM orders;",
    "expected_output": "order_id | amount | prev_amount\n1        | 100    | NULL\n2        | 150    | 100\n3        | 200    | 150",
    "chapter_id": 207,
    "chapter_title": "Window Functions"
  },
  "1083": {
    "id": 1083,
    "title": "LEAD Function",
    "content": "# ‚û°Ô∏è LEAD Function\n\n## Access Next Row Values\n\nLEAD gets a value from a following row:\n\n```sql\nSELECT \n  order_date,\n  revenue,\n  LEAD(revenue) OVER (ORDER BY order_date) AS next_day_revenue\nFROM daily_revenue;\n```\n\n## Result\n\n```\norder_date | revenue | next_day_revenue\n2024-01-01 | 1000    | 1500\n2024-01-02 | 1500    | 1200\n2024-01-03 | 1200    | NULL  (no next)\n```\n\n## Use Cases\n\n- Look-ahead calculations\n- Time until next event\n- Forecasting comparisons\n\n```sql\n-- Days until next order\nSELECT \n  order_date,\n  LEAD(order_date) OVER (ORDER BY order_date) - order_date AS days_to_next\nFROM orders;\n```\n\n---\n\n## üéØ Your Task\n\nShow each employee's salary and the next higher salary.\n",
    "starter_code": "-- Next salary in ranking\n\n",
    "solution_code": "SELECT name, salary, LEAD(salary) OVER (ORDER BY salary) AS next_salary FROM employees;",
    "expected_output": "name    | salary | next_salary\nTom     | 60000  | 75000\nAlice   | 75000  | 90000\nBob     | 90000  | NULL",
    "chapter_id": 207,
    "chapter_title": "Window Functions"
  },
  "1084": {
    "id": 1084,
    "title": "FIRST_VALUE and LAST_VALUE",
    "content": "# ü•á FIRST_VALUE and LAST_VALUE\n\n## Get Boundary Values\n\n```sql\nSELECT \n  name,\n  salary,\n  FIRST_VALUE(name) OVER (ORDER BY salary DESC) AS highest_paid,\n  LAST_VALUE(name) OVER (\n    ORDER BY salary DESC\n    ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING\n  ) AS lowest_paid\nFROM employees;\n```\n\n## LAST_VALUE Frame Gotcha\n\n‚ö†Ô∏è LAST_VALUE needs explicit frame - default frame stops at current row!\n\n```sql\n-- Wrong: Gives current row, not actual last\nLAST_VALUE(x) OVER (ORDER BY y)\n\n-- Right: Explicit frame to include all rows\nLAST_VALUE(x) OVER (\n  ORDER BY y\n  ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING\n)\n```\n\n---\n\n## üéØ Your Task\n\nShow each product with the highest priced product name.\n",
    "starter_code": "-- Highest priced product on each row\n\n",
    "solution_code": "SELECT name, price, FIRST_VALUE(name) OVER (ORDER BY price DESC) AS most_expensive FROM products;",
    "expected_output": "name     | price  | most_expensive\nPremium  | 149.99 | Premium\nWidget B | 99.99  | Premium\nBasic    | 29.99  | Premium",
    "chapter_id": 207,
    "chapter_title": "Window Functions"
  },
  "1085": {
    "id": 1085,
    "title": "NTILE for Bucketing",
    "content": "# üìä NTILE for Bucketing\n\n## Divide Into Equal Groups\n\nNTILE splits rows into n approximately equal buckets:\n\n```sql\nSELECT \n  name,\n  salary,\n  NTILE(4) OVER (ORDER BY salary DESC) AS salary_quartile\nFROM employees;\n```\n\n## Result\n\n```\nname    | salary | salary_quartile\nDiana   | 100000 | 1  (top 25%)\nCharlie | 85000  | 1\nBob     | 70000  | 2\nAlice   | 65000  | 2\nTom     | 60000  | 3\nJane    | 55000  | 3\nKen     | 50000  | 4  (bottom 25%)\nLisa    | 45000  | 4\n```\n\n## Use Cases\n\n- Quartiles, percentiles, deciles\n- Customer segmentation (top 20% customers)\n- Performance ratings (A/B/C/D grades)\n\n---\n\n## üéØ Your Task\n\nDivide products into 3 price tiers.\n",
    "starter_code": "-- 3 price tiers\n\n",
    "solution_code": "SELECT name, price, NTILE(3) OVER (ORDER BY price DESC) AS price_tier FROM products;",
    "expected_output": "name     | price  | price_tier\nPremium  | 149.99 | 1\nWidget B | 99.99  | 1\nWidget A | 49.99  | 2\nBasic    | 29.99  | 3",
    "chapter_id": 207,
    "chapter_title": "Window Functions"
  },
  "1086": {
    "id": 1086,
    "title": "Date Truncation",
    "content": "# üìÖ Date Truncation\n\n## Rounding Dates to Periods\n\nTruncate timestamps to specific time periods:\n\n```sql\nSELECT DATE_TRUNC('month', order_date) AS month\nFROM orders;\n```\n\n## Common Truncation Levels\n\n| Level | Example Result |\n| --- | --- |\n| 'day' | 2024-01-15 00:00:00 |\n| 'week' | 2024-01-15 (Monday) |\n| 'month' | 2024-01-01 |\n| 'quarter' | 2024-01-01 |\n| 'year' | 2024-01-01 |\n\n## Use for Grouping\n\n```sql\nSELECT DATE_TRUNC('month', order_date) AS month,\n       SUM(amount) AS monthly_sales\nFROM orders\nGROUP BY 1\nORDER BY 1;\n```\n\n---\n\n## üéØ Your Task\n\nTruncate order_date to month and count orders per month.\n",
    "starter_code": "-- Monthly order counts\n\n",
    "solution_code": "SELECT DATE_TRUNC('month', order_date) AS month, COUNT(*) FROM orders GROUP BY 1 ORDER BY 1;",
    "expected_output": "month      | count\n2024-01-01 | 15\n2024-02-01 | 22\n2024-03-01 | 18",
    "chapter_id": 208,
    "chapter_title": "Time-Series SQL"
  },
  "1087": {
    "id": 1087,
    "title": "DATE_TRUNC Function",
    "content": "# üóìÔ∏è DATE_TRUNC Function\n\n## Syntax\n\n```sql\nDATE_TRUNC(precision, timestamp)\n```\n\n## Precision Options\n\n```sql\nDATE_TRUNC('hour', ts)    -- 2024-01-15 14:00:00\nDATE_TRUNC('day', ts)     -- 2024-01-15 00:00:00\nDATE_TRUNC('week', ts)    -- Start of week\nDATE_TRUNC('month', ts)   -- First of month\nDATE_TRUNC('year', ts)    -- Jan 1\n```\n\n## Real Example\n\n```sql\n-- Weekly revenue report\nSELECT \n  DATE_TRUNC('week', created_at) AS week,\n  SUM(revenue) AS weekly_revenue\nFROM sales\nGROUP BY 1\nORDER BY 1;\n```\n\n---\n\n## üéØ Your Task\n\nGet weekly sales totals using DATE_TRUNC.\n",
    "starter_code": "-- Weekly sales\n\n",
    "solution_code": "SELECT DATE_TRUNC('week', sale_date) AS week, SUM(amount) AS total FROM sales GROUP BY 1 ORDER BY 1;",
    "expected_output": "week       | total\n2024-01-01 | 5000\n2024-01-08 | 7500",
    "chapter_id": 208,
    "chapter_title": "Time-Series SQL"
  },
  "1088": {
    "id": 1088,
    "title": "Grouping by Time Periods",
    "content": "# üìä Grouping by Time Periods\n\n## Common Patterns\n\n```sql\n-- Daily\nGROUP BY DATE_TRUNC('day', created_at)\n\n-- Weekly\nGROUP BY DATE_TRUNC('week', created_at)\n\n-- Monthly\nGROUP BY DATE_TRUNC('month', created_at)\n```\n\n## Multiple Time Granularities\n\n```sql\nSELECT \n  DATE_TRUNC('month', order_date) AS month,\n  COUNT(*) AS orders,\n  SUM(amount) AS revenue,\n  AVG(amount) AS avg_order\nFROM orders\nGROUP BY 1\nORDER BY 1;\n```\n\n## Hour of Day Analysis\n\n```sql\nSELECT \n  EXTRACT(HOUR FROM created_at) AS hour,\n  COUNT(*) AS activity\nFROM events\nGROUP BY 1\nORDER BY 1;\n```\n\n---\n\n## üéØ Your Task\n\nGroup orders by quarter and sum amounts.\n",
    "starter_code": "-- Quarterly revenue\n\n",
    "solution_code": "SELECT DATE_TRUNC('quarter', order_date) AS quarter, SUM(amount) AS total FROM orders GROUP BY 1 ORDER BY 1;",
    "expected_output": "quarter    | total\n2024-01-01 | 45000\n2024-04-01 | 52000",
    "chapter_id": 208,
    "chapter_title": "Time-Series SQL"
  },
  "1089": {
    "id": 1089,
    "title": "Date Arithmetic",
    "content": "# ‚ûï Date Arithmetic\n\n## Adding/Subtracting Time\n\n```sql\n-- Add days\norder_date + INTERVAL '7 days'\n\n-- Subtract months\nNOW() - INTERVAL '3 months'\n\n-- Add hours\ncreated_at + INTERVAL '24 hours'\n```\n\n## Date Differences\n\n```sql\n-- Days between dates\norder_date - created_at  -- Returns interval\n\n-- Age function\nAGE(NOW(), birth_date)  -- Returns interval like '25 years 3 months'\n```\n\n## Common Patterns\n\n```sql\n-- Last 30 days\nWHERE created_at >= NOW() - INTERVAL '30 days'\n\n-- Same day last year\nDATE_TRUNC('day', NOW() - INTERVAL '1 year')\n```\n\n---\n\n## üéØ Your Task\n\nFind orders from the last 7 days.\n",
    "starter_code": "-- Recent orders\n\n",
    "solution_code": "SELECT * FROM orders WHERE order_date >= CURRENT_DATE - INTERVAL '7 days';",
    "expected_output": "order_id | customer_id | amount | order_date\n45       | 101         | 150.00 | 2024-01-14\n46       | 102         | 200.00 | 2024-01-15",
    "chapter_id": 208,
    "chapter_title": "Time-Series SQL"
  },
  "1090": {
    "id": 1090,
    "title": "EXTRACT Function",
    "content": "# üîç EXTRACT Function\n\n## Pulling Parts from Dates\n\n```sql\nEXTRACT(part FROM timestamp)\n```\n\n## Available Parts\n\n| Part | Example |\n| --- | --- |\n| YEAR | 2024 |\n| MONTH | 1-12 |\n| DAY | 1-31 |\n| HOUR | 0-23 |\n| DOW | 0-6 (day of week) |\n| DOY | 1-366 (day of year) |\n\n## Examples\n\n```sql\nSELECT \n  EXTRACT(YEAR FROM order_date) AS year,\n  EXTRACT(MONTH FROM order_date) AS month,\n  COUNT(*) AS orders\nFROM orders\nGROUP BY 1, 2;\n```\n\n---\n\n## üéØ Your Task\n\nExtract year and month from order_date and count orders.\n",
    "starter_code": "-- Year/month breakdown\n\n",
    "solution_code": "SELECT EXTRACT(YEAR FROM order_date) AS year, EXTRACT(MONTH FROM order_date) AS month, COUNT(*) FROM orders GROUP BY 1, 2;",
    "expected_output": "year | month | count\n2024 | 1     | 35\n2024 | 2     | 28",
    "chapter_id": 208,
    "chapter_title": "Time-Series SQL"
  },
  "1091": {
    "id": 1091,
    "title": "Cohort Analysis Basics",
    "content": "# üë• Cohort Analysis Basics\n\n## What is a Cohort?\n\nA **cohort** is a group of users who share a common characteristic (usually signup date).\n\n```sql\n-- Assign users to monthly cohorts\nSELECT \n  user_id,\n  DATE_TRUNC('month', signup_date) AS cohort\nFROM users;\n```\n\n## Cohort Size\n\n```sql\nSELECT \n  DATE_TRUNC('month', signup_date) AS cohort,\n  COUNT(*) AS cohort_size\nFROM users\nGROUP BY 1\nORDER BY 1;\n```\n\n## Why Cohort Analysis?\n\n- Track how behavior changes over time\n- Compare different signup periods\n- Measure retention and LTV\n\n---\n\n## üéØ Your Task\n\nAssign users to monthly cohorts and count cohort sizes.\n",
    "starter_code": "-- Monthly cohorts\n\n",
    "solution_code": "SELECT DATE_TRUNC('month', signup_date) AS cohort, COUNT(*) AS size FROM users GROUP BY 1 ORDER BY 1;",
    "expected_output": "cohort     | size\n2024-01-01 | 150\n2024-02-01 | 180\n2024-03-01 | 165",
    "chapter_id": 208,
    "chapter_title": "Time-Series SQL"
  },
  "1092": {
    "id": 1092,
    "title": "Retention Tables",
    "content": "# üìà Retention Tables\n\n## Tracking User Retention\n\n```sql\nWITH user_cohorts AS (\n  SELECT user_id, DATE_TRUNC('month', signup_date) AS cohort\n  FROM users\n),\nuser_activity AS (\n  SELECT user_id, DATE_TRUNC('month', activity_date) AS activity_month\n  FROM events\n)\nSELECT \n  c.cohort,\n  a.activity_month,\n  COUNT(DISTINCT a.user_id) AS active_users\nFROM user_cohorts c\nJOIN user_activity a ON c.user_id = a.user_id\nGROUP BY 1, 2;\n```\n\n## Retention Rate\n\n```sql\n-- Month 0 = signup month, Month 1 = next month, etc.\nactive_users / cohort_size AS retention_rate\n```\n\n---\n\n## üéØ Your Task\n\nCount active users per cohort and month.\n",
    "starter_code": "-- Retention by cohort\n\n",
    "solution_code": "SELECT DATE_TRUNC('month', u.signup_date) AS cohort, DATE_TRUNC('month', e.event_date) AS month, COUNT(DISTINCT u.user_id) AS active FROM users u JOIN events e ON u.user_id = e.user_id GROUP BY 1, 2;",
    "expected_output": "cohort     | month      | active\n2024-01-01 | 2024-01-01 | 150\n2024-01-01 | 2024-02-01 | 90",
    "chapter_id": 208,
    "chapter_title": "Time-Series SQL"
  },
  "1093": {
    "id": 1093,
    "title": "Session Analysis",
    "content": "# ‚è±Ô∏è Session Analysis\n\n## Defining Sessions\n\nGroup events into sessions with time gaps:\n\n```sql\nWITH lagged AS (\n  SELECT \n    user_id,\n    event_time,\n    LAG(event_time) OVER (PARTITION BY user_id ORDER BY event_time) AS prev_event\n  FROM events\n)\nSELECT \n  *,\n  CASE \n    WHEN event_time - prev_event > INTERVAL '30 minutes' THEN 1\n    ELSE 0\n  END AS new_session\nFROM lagged;\n```\n\n## Session Metrics\n\n- Session count per user\n- Average session duration\n- Events per session\n\n---\n\n## üéØ Your Task\n\nCalculate time since previous event per user.\n",
    "starter_code": "-- Time gaps between events\n\n",
    "solution_code": "SELECT user_id, event_time, event_time - LAG(event_time) OVER (PARTITION BY user_id ORDER BY event_time) AS time_since_prev FROM events;",
    "expected_output": "user_id | event_time          | time_since_prev\n1       | 2024-01-15 10:00:00 | NULL\n1       | 2024-01-15 10:05:00 | 00:05:00",
    "chapter_id": 208,
    "chapter_title": "Time-Series SQL"
  },
  "1094": {
    "id": 1094,
    "title": "Conversion Funnels",
    "content": "# üîÑ Conversion Funnels\n\n## Tracking User Journeys\n\n```sql\nSELECT \n  COUNT(DISTINCT CASE WHEN event = 'view' THEN user_id END) AS views,\n  COUNT(DISTINCT CASE WHEN event = 'add_cart' THEN user_id END) AS add_cart,\n  COUNT(DISTINCT CASE WHEN event = 'purchase' THEN user_id END) AS purchase\nFROM events;\n```\n\n## Conversion Rates\n\n```sql\nWITH funnel AS (\n  SELECT \n    COUNT(DISTINCT CASE WHEN step = 1 THEN user_id END) AS step1,\n    COUNT(DISTINCT CASE WHEN step = 2 THEN user_id END) AS step2,\n    COUNT(DISTINCT CASE WHEN step = 3 THEN user_id END) AS step3\n  FROM events\n)\nSELECT \n  step1,\n  step2,\n  step3,\n  ROUND(100.0 * step2 / step1, 1) AS conv_1_to_2,\n  ROUND(100.0 * step3 / step2, 1) AS conv_2_to_3\nFROM funnel;\n```\n\n---\n\n## üéØ Your Task\n\nCount users at each funnel stage.\n",
    "starter_code": "-- Funnel stages\n\n",
    "solution_code": "SELECT COUNT(DISTINCT CASE WHEN event_type = 'view' THEN user_id END) AS views, COUNT(DISTINCT CASE WHEN event_type = 'click' THEN user_id END) AS clicks, COUNT(DISTINCT CASE WHEN event_type = 'purchase' THEN user_id END) AS purchases FROM events;",
    "expected_output": "views | clicks | purchases\n1000  | 350    | 75",
    "chapter_id": 208,
    "chapter_title": "Time-Series SQL"
  },
  "1095": {
    "id": 1095,
    "title": "Gap Analysis",
    "content": "# üï≥Ô∏è Gap Analysis\n\n## Finding Missing Dates\n\n```sql\n-- Create date series\nWITH date_series AS (\n  SELECT generate_series(\n    '2024-01-01'::date,\n    '2024-01-31'::date,\n    '1 day'::interval\n  )::date AS date\n)\nSELECT d.date, COALESCE(s.sales, 0) AS sales\nFROM date_series d\nLEFT JOIN sales s ON d.date = s.sale_date;\n```\n\n## Use Cases\n\n- Find days with no sales\n- Identify gaps in time series\n- Ensure complete date coverage\n\n---\n\n## üéØ Your Task\n\nFind dates with sales by joining with a date series.\n",
    "starter_code": "-- Dates with sales\n\n",
    "solution_code": "SELECT sale_date, COUNT(*) AS num_sales FROM sales GROUP BY sale_date ORDER BY sale_date;",
    "expected_output": "sale_date  | num_sales\n2024-01-01 | 5\n2024-01-02 | 8\n2024-01-04 | 3",
    "chapter_id": 208,
    "chapter_title": "Time-Series SQL"
  },
  "1096": {
    "id": 1096,
    "title": "Calendar Tables",
    "content": "# üìÜ Calendar Tables\n\n## Pre-built Date Dimension\n\nA calendar table contains one row per date with useful attributes:\n\n```sql\nCREATE TABLE calendar AS\nSELECT \n  d::date AS date,\n  EXTRACT(YEAR FROM d) AS year,\n  EXTRACT(MONTH FROM d) AS month,\n  EXTRACT(DOW FROM d) AS day_of_week,\n  d = DATE_TRUNC('month', d) AS is_month_start\nFROM generate_series('2020-01-01', '2030-12-31', '1 day') d;\n```\n\n## Joining to Calendar\n\n```sql\nSELECT c.year, c.month, SUM(o.amount)\nFROM calendar c\nLEFT JOIN orders o ON c.date = o.order_date\nGROUP BY 1, 2;\n```\n\n---\n\n## üéØ Your Task\n\nJoin orders to a date dimension table.\n",
    "starter_code": "-- Join with calendar\n\n",
    "solution_code": "SELECT c.year, c.month, COALESCE(SUM(o.amount), 0) AS total FROM calendar c LEFT JOIN orders o ON c.date = o.order_date GROUP BY 1, 2 ORDER BY 1, 2;",
    "expected_output": "year | month | total\n2024 | 1     | 45000\n2024 | 2     | 52000",
    "chapter_id": 208,
    "chapter_title": "Time-Series SQL"
  },
  "1097": {
    "id": 1097,
    "title": "Year-over-Year Comparisons",
    "content": "# üìä Year-over-Year Comparisons\n\n## Comparing to Same Period Last Year\n\n```sql\nWITH monthly_sales AS (\n  SELECT \n    DATE_TRUNC('month', order_date) AS month,\n    SUM(amount) AS revenue\n  FROM orders\n  GROUP BY 1\n)\nSELECT \n  month,\n  revenue,\n  LAG(revenue, 12) OVER (ORDER BY month) AS revenue_ly,\n  revenue - LAG(revenue, 12) OVER (ORDER BY month) AS yoy_change\nFROM monthly_sales;\n```\n\n## YoY Growth Rate\n\n```sql\n100.0 * (revenue - revenue_ly) / revenue_ly AS yoy_growth_pct\n```\n\n---\n\n## üéØ Your Task\n\nCalculate monthly revenue with previous month comparison.\n",
    "starter_code": "-- Month over month\n\n",
    "solution_code": "SELECT DATE_TRUNC('month', order_date) AS month, SUM(amount) AS revenue, LAG(SUM(amount)) OVER (ORDER BY DATE_TRUNC('month', order_date)) AS prev_month FROM orders GROUP BY 1 ORDER BY 1;",
    "expected_output": "month      | revenue | prev_month\n2024-01-01 | 45000   | NULL\n2024-02-01 | 52000   | 45000\n2024-03-01 | 48000   | 52000",
    "chapter_id": 208,
    "chapter_title": "Time-Series SQL"
  },
  "1098": {
    "id": 1098,
    "title": "üßô Analytics Wizard Challenge",
    "content": "# üßô BOSS BATTLE: The Analytics Wizard\n\nProve your mastery of advanced SQL analytics!\n\n## The Challenge\n\nCombine skills from Chapters 5-8:\n- CTEs for organization\n- Window functions for rankings\n- Time-series analysis\n- Complex aggregations\n\n## Your Mission\n\nWrite a query that:\n1. Shows monthly revenue\n2. Calculates running total YTD\n3. Compares to previous month (MoM change)\n4. Ranks months by revenue\n\n---\n\n## üéØ Complete the Challenge\n\nUse CTEs and window functions to create a comprehensive monthly revenue report.\n",
    "starter_code": "-- The Analytics Wizard Challenge\n-- Monthly revenue with:\n-- - Running total (YTD)\n-- - MoM change\n-- - Rank by revenue\n\n",
    "solution_code": "WITH monthly AS (\n  SELECT \n    DATE_TRUNC('month', order_date) AS month,\n    SUM(amount) AS revenue\n  FROM orders\n  GROUP BY 1\n)\nSELECT \n  month,\n  revenue,\n  SUM(revenue) OVER (ORDER BY month) AS ytd_total,\n  revenue - LAG(revenue) OVER (ORDER BY month) AS mom_change,\n  RANK() OVER (ORDER BY revenue DESC) AS revenue_rank\nFROM monthly\nORDER BY month;",
    "expected_output": "month      | revenue | ytd_total | mom_change | revenue_rank\n2024-01-01 | 45000   | 45000     | NULL       | 3\n2024-02-01 | 52000   | 97000     | 7000       | 1\n2024-03-01 | 48000   | 145000    | -4000      | 2",
    "chapter_id": 251,
    "chapter_title": "Analytics Wizard Boss"
  },
  "1099": {
    "id": 1099,
    "title": "Identifying Duplicates",
    "content": "# üîç Identifying Duplicates\n\n## Why Duplicates Happen\n\nDuplicates creep into data through:\n- Multiple form submissions\n- System integration issues\n- Data import errors\n- Lack of unique constraints\n\n## Finding Duplicates with GROUP BY\n\n```sql\n-- Find duplicate emails\nSELECT email, COUNT(*) as count\nFROM users\nGROUP BY email\nHAVING COUNT(*) > 1;\n```\n\n## Finding Exact Row Duplicates\n\n```sql\n-- Find completely identical rows\nSELECT name, email, COUNT(*)\nFROM users\nGROUP BY name, email\nHAVING COUNT(*) > 1;\n```\n\n---\n\n## üéØ Your Task\n\nFind all duplicate product names in the products table.\n",
    "starter_code": "-- Find products with duplicate names\n-- Show the name and how many times it appears\n\n",
    "solution_code": "SELECT name, COUNT(*) as count\nFROM products\nGROUP BY name\nHAVING COUNT(*) > 1;",
    "expected_output": "name       | count\nWidget A   | 2\nGadget Pro | 3",
    "chapter_id": 209,
    "chapter_title": "Data Cleaning & Metrics"
  },
  "1100": {
    "id": 1100,
    "title": "Deduplication with ROW_NUMBER",
    "content": "# üî¢ Deduplication with ROW_NUMBER\n\n## The ROW_NUMBER Pattern\n\nUse ROW_NUMBER to mark duplicates:\n\n```sql\nWITH ranked AS (\n  SELECT *,\n    ROW_NUMBER() OVER (\n      PARTITION BY email \n      ORDER BY created_at DESC\n    ) as rn\n  FROM users\n)\nSELECT * FROM ranked WHERE rn = 1;\n```\n\n## How It Works\n\n1. **PARTITION BY** groups rows by the duplicate key\n2. **ORDER BY** determines which row is \"first\" (keeper)\n3. **rn = 1** keeps only the first row in each group\n\n## Keeping Latest vs Earliest\n\n```sql\n-- Keep LATEST (most recent)\nORDER BY created_at DESC\n\n-- Keep EARLIEST (oldest)\nORDER BY created_at ASC\n```\n\n---\n\n## üéØ Your Task\n\nGet unique customers keeping the most recent order for each customer_id.\n",
    "starter_code": "-- Deduplicate orders\n-- Keep the most recent order per customer\n\n",
    "solution_code": "WITH ranked AS (\n  SELECT *,\n    ROW_NUMBER() OVER (\n      PARTITION BY customer_id\n      ORDER BY order_date DESC\n    ) as rn\n  FROM orders\n)\nSELECT * FROM ranked WHERE rn = 1;",
    "expected_output": "customer_id | order_date | amount | rn\n1           | 2024-03-15 | 150    | 1\n2           | 2024-03-10 | 200    | 1",
    "chapter_id": 209,
    "chapter_title": "Data Cleaning & Metrics"
  },
  "1101": {
    "id": 1101,
    "title": "Keeping First/Last Record",
    "content": "# ‚è±Ô∏è Keeping First or Last Record\n\n## Common Scenarios\n\n| Scenario | Keep | Order By |\n| --- | --- | --- |\n| Latest login | Last | login_time DESC |\n| First purchase | First | purchase_date ASC |\n| Highest value | Best | amount DESC |\n\n## Pattern with FIRST_VALUE\n\n```sql\nSELECT DISTINCT customer_id,\n  FIRST_VALUE(order_id) OVER (\n    PARTITION BY customer_id\n    ORDER BY order_date\n  ) as first_order_id\nFROM orders;\n```\n\n## Delete Duplicates (Keeping First)\n\n```sql\nDELETE FROM orders\nWHERE id NOT IN (\n  SELECT MIN(id)\n  FROM orders\n  GROUP BY customer_id, product_id\n);\n```\n\n---\n\n## üéØ Your Task\n\nFind each customer's first purchase date.\n",
    "starter_code": "-- Find first purchase per customer\n-- Return customer_id and their first order_date\n\n",
    "solution_code": "SELECT customer_id,\n  MIN(order_date) as first_purchase\nFROM orders\nGROUP BY customer_id;",
    "expected_output": "customer_id | first_purchase\n1           | 2024-01-05\n2           | 2024-01-12\n3           | 2024-02-01",
    "chapter_id": 209,
    "chapter_title": "Data Cleaning & Metrics"
  },
  "1102": {
    "id": 1102,
    "title": "Detecting Outliers",
    "content": "# üìä Detecting Outliers\n\n## What Are Outliers?\n\nValues far from the typical range:\n- Age: 150 years\n- Price: $-50\n- Quantity: 999999\n\n## Statistical Detection\n\n```sql\n-- Using standard deviation\nWITH stats AS (\n  SELECT\n    AVG(amount) as avg_amount,\n    STDDEV(amount) as std_amount\n  FROM orders\n)\nSELECT o.*\nFROM orders o, stats s\nWHERE o.amount > s.avg_amount + 3 * s.std_amount\n   OR o.amount < s.avg_amount - 3 * s.std_amount;\n```\n\n## Simple Range Check\n\n```sql\n-- Business rule based\nSELECT * FROM orders\nWHERE amount < 0 OR amount > 10000;\n```\n\n---\n\n## üéØ Your Task\n\nFind orders where the amount is more than 3 times the average.\n",
    "starter_code": "-- Find outlier orders\n-- Amount > 3x the average\n\n",
    "solution_code": "SELECT *\nFROM orders\nWHERE amount > 3 * (SELECT AVG(amount) FROM orders);",
    "expected_output": "order_id | amount\n42       | 15000\n67       | 12500",
    "chapter_id": 209,
    "chapter_title": "Data Cleaning & Metrics"
  },
  "1103": {
    "id": 1103,
    "title": "Percentile Calculations",
    "content": "# üìà Percentile Calculations\n\n## What Are Percentiles?\n\n- **P50 (Median)**: 50% of values below\n- **P90**: 90% of values below\n- **P99**: 99% of values below (outliers)\n\n## PERCENTILE_CONT Function\n\n```sql\nSELECT\n  PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY amount) as median,\n  PERCENTILE_CONT(0.9) WITHIN GROUP (ORDER BY amount) as p90,\n  PERCENTILE_CONT(0.99) WITHIN GROUP (ORDER BY amount) as p99\nFROM orders;\n```\n\n## NTILE for Buckets\n\n```sql\n-- Put customers into 4 quartiles\nSELECT customer_id, total_spent,\n  NTILE(4) OVER (ORDER BY total_spent) as quartile\nFROM customer_summary;\n```\n\n---\n\n## üéØ Your Task\n\nCalculate the median order amount.\n",
    "starter_code": "-- Find the median (50th percentile) order amount\n\n",
    "solution_code": "SELECT\n  PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY amount) as median_amount\nFROM orders;",
    "expected_output": "median_amount\n125.50",
    "chapter_id": 209,
    "chapter_title": "Data Cleaning & Metrics"
  },
  "1104": {
    "id": 1104,
    "title": "Handling Outliers",
    "content": "# üõ†Ô∏è Handling Outliers\n\n## Options for Outliers\n\n| Approach | When to Use |\n| --- | --- |\n| Remove | Data entry errors |\n| Cap/Floor | Statistical analysis |\n| Flag | Keep but mark |\n| Investigate | Could be valid! |\n\n## Capping with LEAST/GREATEST\n\n```sql\n-- Cap amounts at P99\nWITH p99 AS (\n  SELECT PERCENTILE_CONT(0.99) WITHIN GROUP (ORDER BY amount) as cap\n  FROM orders\n)\nSELECT \n  order_id,\n  LEAST(amount, p99.cap) as capped_amount\nFROM orders, p99;\n```\n\n## Flagging Outliers\n\n```sql\nSELECT *,\n  CASE WHEN amount > 10000 THEN true ELSE false END as is_outlier\nFROM orders;\n```\n\n---\n\n## üéØ Your Task\n\nSelect orders with amounts capped at 1000 maximum.\n",
    "starter_code": "-- Cap order amounts at 1000\n-- Show order_id and capped_amount\n\n",
    "solution_code": "SELECT order_id,\n  LEAST(amount, 1000) as capped_amount\nFROM orders;",
    "expected_output": "order_id | capped_amount\n1        | 500\n2        | 1000\n3        | 750",
    "chapter_id": 209,
    "chapter_title": "Data Cleaning & Metrics"
  },
  "1105": {
    "id": 1105,
    "title": "Metric Definitions Matter",
    "content": "# üìê Metric Definitions Matter\n\n## Same Name, Different Meaning\n\n\"Active Users\" could mean:\n- Logged in this month\n- Made a purchase\n- Viewed any page\n- Used core feature\n\n## Example: Revenue\n\n```sql\n-- Gross revenue\nSELECT SUM(amount) as gross_revenue FROM orders;\n\n-- Net revenue (minus refunds)\nSELECT SUM(CASE WHEN status != 'refunded' THEN amount ELSE 0 END) as net_revenue\nFROM orders;\n\n-- Recognized revenue (delivered only)\nSELECT SUM(amount) FROM orders WHERE status = 'delivered';\n```\n\n## Document Your Definitions!\n\n| Metric | Definition |\n| --- | --- |\n| MAU | Users with ‚â•1 login in 30 days |\n| Revenue | Net of refunds, excludes tips |\n\n---\n\n## üéØ Your Task\n\nCalculate net revenue (excluding refunded orders).\n",
    "starter_code": "-- Calculate net revenue\n-- Exclude orders with status = 'refunded'\n\n",
    "solution_code": "SELECT SUM(amount) as net_revenue\nFROM orders\nWHERE status != 'refunded';",
    "expected_output": "net_revenue\n45000",
    "chapter_id": 209,
    "chapter_title": "Data Cleaning & Metrics"
  },
  "1106": {
    "id": 1106,
    "title": "Active User Definitions",
    "content": "# üë• Active User Definitions\n\n## Common Definitions\n\n| Metric | Definition |\n| --- | --- |\n| DAU | Unique users per day |\n| WAU | Unique users in 7 days |\n| MAU | Unique users in 30 days |\n\n## Calculating DAU\n\n```sql\nSELECT\n  DATE(event_time) as date,\n  COUNT(DISTINCT user_id) as dau\nFROM events\nGROUP BY DATE(event_time);\n```\n\n## Rolling 7-Day Active Users\n\n```sql\nSELECT\n  date,\n  COUNT(DISTINCT user_id) OVER (\n    ORDER BY date\n    ROWS BETWEEN 6 PRECEDING AND CURRENT ROW\n  ) as rolling_7d_users\nFROM daily_users;\n```\n\n---\n\n## üéØ Your Task\n\nCalculate daily active users from the events table.\n",
    "starter_code": "-- Calculate DAU\n-- Count unique users per day\n\n",
    "solution_code": "SELECT\n  DATE(event_time) as date,\n  COUNT(DISTINCT user_id) as dau\nFROM events\nGROUP BY DATE(event_time)\nORDER BY date;",
    "expected_output": "date       | dau\n2024-03-01 | 150\n2024-03-02 | 175\n2024-03-03 | 160",
    "chapter_id": 209,
    "chapter_title": "Data Cleaning & Metrics"
  },
  "1107": {
    "id": 1107,
    "title": "Avoiding Double Counting",
    "content": "# ‚ö†Ô∏è Avoiding Double Counting\n\n## Common Mistakes\n\n1. **Joining without deduping** - inflates counts\n2. **Missing DISTINCT** - counts rows not unique values\n3. **Wrong aggregation level** - summing at wrong grain\n\n## Bad: Double Counting\n\n```sql\n-- If user has multiple orders, counted multiple times!\nSELECT COUNT(*) FROM users u\nJOIN orders o ON u.id = o.user_id;\n```\n\n## Good: Distinct Count\n\n```sql\nSELECT COUNT(DISTINCT u.id) as unique_customers\nFROM users u\nJOIN orders o ON u.id = o.user_id;\n```\n\n## Watch for Many-to-Many\n\n```sql\n-- Pre-aggregate to avoid explosion\nWITH user_orders AS (\n  SELECT user_id, SUM(amount) as total\n  FROM orders GROUP BY user_id\n)\nSELECT * FROM users u\nJOIN user_orders uo ON u.id = uo.user_id;\n```\n\n---\n\n## üéØ Your Task\n\nCount unique customers who have placed orders.\n",
    "starter_code": "-- Count unique customers with orders\n-- Don't double count!\n\n",
    "solution_code": "SELECT COUNT(DISTINCT customer_id) as unique_customers\nFROM orders;",
    "expected_output": "unique_customers\n250",
    "chapter_id": 209,
    "chapter_title": "Data Cleaning & Metrics"
  },
  "1108": {
    "id": 1108,
    "title": "Data Quality Checks",
    "content": "# ‚úÖ Data Quality Checks\n\n## Types of Quality Checks\n\n| Check Type | Example |\n| --- | --- |\n| Null checks | Required fields filled |\n| Range checks | Age between 0-120 |\n| Format checks | Email contains @ |\n| Referential | FK exists in parent |\n\n## Null Check Query\n\n```sql\nSELECT \n  COUNT(*) as total_rows,\n  COUNT(email) as has_email,\n  COUNT(*) - COUNT(email) as missing_email\nFROM users;\n```\n\n## Orphan Records\n\n```sql\n-- Orders without valid customer\nSELECT o.*\nFROM orders o\nLEFT JOIN customers c ON o.customer_id = c.id\nWHERE c.id IS NULL;\n```\n\n---\n\n## üéØ Your Task\n\nCount how many products are missing a category_id.\n",
    "starter_code": "-- Count products with NULL category_id\n\n",
    "solution_code": "SELECT COUNT(*) as missing_category\nFROM products\nWHERE category_id IS NULL;",
    "expected_output": "missing_category\n15",
    "chapter_id": 209,
    "chapter_title": "Data Cleaning & Metrics"
  },
  "1109": {
    "id": 1109,
    "title": "Assertion Queries",
    "content": "# üîí Assertion Queries\n\n## What Are Assertions?\n\nQueries that should return 0 rows if data is valid:\n\n```sql\n-- Should return no rows!\nSELECT * FROM orders WHERE amount < 0;\n```\n\n## Common Assertions\n\n```sql\n-- No future dates\nSELECT * FROM orders WHERE order_date > CURRENT_DATE;\n\n-- No duplicates\nSELECT email, COUNT(*) \nFROM users \nGROUP BY email \nHAVING COUNT(*) > 1;\n\n-- All FKs valid\nSELECT o.* FROM orders o\nLEFT JOIN customers c ON o.customer_id = c.id\nWHERE c.id IS NULL;\n```\n\n## Automated Testing\n\n```sql\n-- Return TRUE if valid\nSELECT NOT EXISTS (\n  SELECT 1 FROM orders WHERE amount < 0\n) as no_negative_amounts;\n```\n\n---\n\n## üéØ Your Task\n\nWrite an assertion to find orders with negative amounts.\n",
    "starter_code": "-- Find orders with invalid (negative) amounts\n-- Should return 0 rows if data is clean\n\n",
    "solution_code": "SELECT * FROM orders\nWHERE amount < 0;",
    "expected_output": "order_id | amount\n(no rows)",
    "chapter_id": 209,
    "chapter_title": "Data Cleaning & Metrics"
  },
  "1110": {
    "id": 1110,
    "title": "Metric Validation",
    "content": "# üìä Metric Validation\n\n## Trust But Verify\n\nAlways sanity-check your metrics:\n\n```sql\n-- Does total match sum of parts?\nSELECT \n  SUM(amount) as total_revenue,\n  SUM(CASE WHEN channel = 'web' THEN amount ELSE 0 END) as web,\n  SUM(CASE WHEN channel = 'mobile' THEN amount ELSE 0 END) as mobile\nFROM orders;\n-- web + mobile should equal total!\n```\n\n## Year-over-Year Sense Check\n\n```sql\nSELECT\n  EXTRACT(YEAR FROM order_date) as year,\n  COUNT(*) as order_count,\n  SUM(amount) as revenue\nFROM orders\nGROUP BY EXTRACT(YEAR FROM order_date)\nORDER BY year;\n-- Wild swings? Investigate!\n```\n\n## Cross-Table Validation\n\n```sql\n-- Order count should match\nSELECT 'orders' as source, COUNT(*) FROM orders\nUNION ALL\nSELECT 'order_items', COUNT(DISTINCT order_id) FROM order_items;\n```\n\n---\n\n## üéØ Your Task\n\nCompare total revenue against the sum of web and mobile channels.\n",
    "starter_code": "-- Validate revenue by channel\n-- Total should equal web + mobile\n\n",
    "solution_code": "SELECT\n  SUM(amount) as total_revenue,\n  SUM(CASE WHEN channel = 'web' THEN amount ELSE 0 END) as web_revenue,\n  SUM(CASE WHEN channel = 'mobile' THEN amount ELSE 0 END) as mobile_revenue\nFROM orders;",
    "expected_output": "total_revenue | web_revenue | mobile_revenue\n50000         | 30000       | 20000",
    "chapter_id": 209,
    "chapter_title": "Data Cleaning & Metrics"
  },
  "1111": {
    "id": 1111,
    "title": "Why Tables Split",
    "content": "# üîÄ Why Tables Split\n\n## The Problem with One Table\n\n```\norders table (BAD design):\norder_id | customer_name | customer_email | product_name | price\n1        | Alice         | alice@mail.com | Widget       | 25\n2        | Alice         | alice@mail.com | Gadget       | 50\n```\n\n**Issues:**\n- Repeated data (customer info)\n- Update anomalies\n- Wasted storage\n\n## The Solution: Split!\n\n```\ncustomers table:\nid | name  | email\n1  | Alice | alice@mail.com\n\norders table:\nid | customer_id | product | price\n1  | 1           | Widget  | 25\n2  | 1           | Gadget  | 50\n```\n\n---\n\n## üéØ Your Task\n\nSelect customer_id and total orders per customer.\n",
    "starter_code": "-- Count orders per customer\n\n",
    "solution_code": "SELECT customer_id, COUNT(*) as total_orders\nFROM orders\nGROUP BY customer_id;",
    "expected_output": "customer_id | total_orders\n1           | 5\n2           | 3",
    "chapter_id": 210,
    "chapter_title": "Database Design Essentials"
  },
  "1112": {
    "id": 1112,
    "title": "Normalization Basics",
    "content": "# üìê Normalization Basics\n\n## What is Normalization?\n\nA process to organize tables to:\n- Reduce data redundancy\n- Improve data integrity\n- Prevent update anomalies\n\n## Normal Forms\n\n| Form | Rule |\n| --- | --- |\n| 1NF | No repeating groups |\n| 2NF | No partial dependencies |\n| 3NF | No transitive dependencies |\n\n## Benefits\n\n- Smaller storage\n- Fewer update errors\n- Better data quality\n\n---\n\n## üéØ Your Task\n\nFind all unique customer emails.\n",
    "starter_code": "-- Select distinct emails\n\n",
    "solution_code": "SELECT DISTINCT email\nFROM customers;",
    "expected_output": "email\nalice@mail.com\nbob@mail.com",
    "chapter_id": 210,
    "chapter_title": "Database Design Essentials"
  },
  "1113": {
    "id": 1113,
    "title": "First Normal Form",
    "content": "# 1Ô∏è‚É£ First Normal Form (1NF)\n\n## Rule\n\nEach cell contains a single atomic value.\n\n## Bad (Not 1NF)\n\n```\nuser_id | phones\n1       | 555-1234, 555-5678\n```\n\n## Good (1NF)\n\n```\nuser_id | phone_type | phone\n1       | home       | 555-1234\n1       | mobile     | 555-5678\n```\n\n---\n\n## üéØ Your Task\n\nSelect users with their phone numbers from the user_phones table.\n",
    "starter_code": "-- Join users with their phones\n\n",
    "solution_code": "SELECT u.name, p.phone\nFROM users u\nJOIN user_phones p ON u.id = p.user_id;",
    "expected_output": "name  | phone\nAlice | 555-1234\nAlice | 555-5678",
    "chapter_id": 210,
    "chapter_title": "Database Design Essentials"
  },
  "1114": {
    "id": 1114,
    "title": "Second and Third Normal Form",
    "content": "# 2Ô∏è‚É£3Ô∏è‚É£ Second and Third Normal Form\n\n## 2NF: No Partial Dependencies\n\nEvery non-key column depends on the ENTIRE primary key.\n\n## 3NF: No Transitive Dependencies\n\nNon-key columns don't depend on other non-key columns.\n\n**Example Problem:**\n```\nemployee_id | department_id | department_name\n```\n`department_name` depends on `department_id` not employee!\n\n**Fix:** Create separate departments table.\n\n---\n\n## üéØ Your Task\n\nJoin employees with departments to show employee name and department name.\n",
    "starter_code": "-- Join employees and departments\n\n",
    "solution_code": "SELECT e.name, d.name as department\nFROM employees e\nJOIN departments d ON e.department_id = d.id;",
    "expected_output": "name  | department\nAlice | Sales\nBob   | Marketing",
    "chapter_id": 210,
    "chapter_title": "Database Design Essentials"
  },
  "1115": {
    "id": 1115,
    "title": "Fact Tables",
    "content": "# üìä Fact Tables\n\n## What are Fact Tables?\n\nTables that store **measurable events**:\n- Orders\n- Page views\n- Transactions\n- Clicks\n\n## Characteristics\n\n- Contain numeric measures (amount, quantity)\n- Large row counts\n- Foreign keys to dimensions\n- Append-only (events happen once)\n\n```sql\n-- Fact table example\nCREATE TABLE fact_orders (\n  order_id INT,\n  customer_id INT,  -- FK\n  product_id INT,   -- FK\n  date_id INT,      -- FK\n  amount DECIMAL\n);\n```\n\n---\n\n## üéØ Your Task\n\nGet total revenue from the orders fact table.\n",
    "starter_code": "-- Sum all order amounts\n\n",
    "solution_code": "SELECT SUM(amount) as total_revenue\nFROM orders;",
    "expected_output": "total_revenue\n125000",
    "chapter_id": 210,
    "chapter_title": "Database Design Essentials"
  },
  "1116": {
    "id": 1116,
    "title": "Dimension Tables",
    "content": "# üìã Dimension Tables\n\n## What are Dimension Tables?\n\nTables that store **descriptive attributes**:\n- Customers\n- Products\n- Dates\n- Locations\n\n## Characteristics\n\n- Fewer rows than facts\n- Rich descriptive columns\n- Slowly changing\n- Joined to facts by ID\n\n```sql\n-- Dimension table example\nCREATE TABLE dim_customer (\n  customer_id INT PRIMARY KEY,\n  name VARCHAR,\n  email VARCHAR,\n  segment VARCHAR\n);\n```\n\n---\n\n## üéØ Your Task\n\nSelect all columns from the customers dimension table.\n",
    "starter_code": "-- Get all customer attributes\n\n",
    "solution_code": "SELECT * FROM customers;",
    "expected_output": "id | name  | email          | segment\n1  | Alice | alice@mail.com | Premium",
    "chapter_id": 210,
    "chapter_title": "Database Design Essentials"
  },
  "1117": {
    "id": 1117,
    "title": "Star Schema",
    "content": "# ‚≠ê Star Schema\n\n## What is Star Schema?\n\nA design pattern where:\n- **Fact table** in the center\n- **Dimension tables** around it (like star points)\n\n```\n        dim_customer\n            |\n dim_date -- fact_orders -- dim_product\n            |\n        dim_location\n```\n\n## Benefits\n\n- Simple to understand\n- Fast queries\n- Standard for analytics\n\n---\n\n## üéØ Your Task\n\nJoin orders with customers and products to show customer name, product name, and amount.\n",
    "starter_code": "-- Star join: orders + customers + products\n\n",
    "solution_code": "SELECT c.name as customer, p.name as product, o.amount\nFROM orders o\nJOIN customers c ON o.customer_id = c.id\nJOIN products p ON o.product_id = p.id;",
    "expected_output": "customer | product | amount\nAlice    | Widget  | 50",
    "chapter_id": 210,
    "chapter_title": "Database Design Essentials"
  },
  "1118": {
    "id": 1118,
    "title": "Primary Key Constraints",
    "content": "# üîë Primary Key Constraints\n\n## What is a Primary Key?\n\nA column (or combination) that **uniquely identifies** each row.\n\n## Rules\n\n- Must be unique\n- Cannot be NULL\n- One per table\n\n```sql\nCREATE TABLE users (\n  id INT PRIMARY KEY,\n  email VARCHAR\n);\n```\n\n---\n\n## üéØ Your Task\n\nFind users with duplicate IDs (should return 0 if PK enforced).\n",
    "starter_code": "-- Check for duplicate IDs\n\n",
    "solution_code": "SELECT id, COUNT(*)\nFROM users\nGROUP BY id\nHAVING COUNT(*) > 1;",
    "expected_output": "id | count\n(no rows)",
    "chapter_id": 210,
    "chapter_title": "Database Design Essentials"
  },
  "1119": {
    "id": 1119,
    "title": "Foreign Key Constraints",
    "content": "# üîó Foreign Key Constraints\n\n## What is a Foreign Key?\n\nA column that references the primary key of another table.\n\n## Purpose\n\n- Enforces referential integrity\n- Prevents orphan records\n- Documents relationships\n\n```sql\nCREATE TABLE orders (\n  id INT PRIMARY KEY,\n  customer_id INT REFERENCES customers(id)\n);\n```\n\n---\n\n## üéØ Your Task\n\nFind orders with invalid customer IDs (LEFT JOIN where customer is NULL).\n",
    "starter_code": "-- Find orphan orders\n\n",
    "solution_code": "SELECT o.*\nFROM orders o\nLEFT JOIN customers c ON o.customer_id = c.id\nWHERE c.id IS NULL;",
    "expected_output": "order_id | customer_id\n(no rows)",
    "chapter_id": 210,
    "chapter_title": "Database Design Essentials"
  },
  "1120": {
    "id": 1120,
    "title": "Unique Constraints",
    "content": "# üéØ Unique Constraints\n\n## What is a Unique Constraint?\n\nEnsures all values in a column are distinct.\n\n```sql\nCREATE TABLE users (\n  id INT PRIMARY KEY,\n  email VARCHAR UNIQUE\n);\n```\n\n## Difference from Primary Key\n\n| Feature | Primary Key | Unique |\n| --- | --- | --- |\n| NULL allowed | No | Yes (one) |\n| Per table | One | Many |\n\n---\n\n## üéØ Your Task\n\nFind duplicate emails in users.\n",
    "starter_code": "-- Find duplicate emails\n\n",
    "solution_code": "SELECT email, COUNT(*)\nFROM users\nGROUP BY email\nHAVING COUNT(*) > 1;",
    "expected_output": "email | count\n(no rows)",
    "chapter_id": 210,
    "chapter_title": "Database Design Essentials"
  },
  "1121": {
    "id": 1121,
    "title": "When to Denormalize",
    "content": "# üîÑ When to Denormalize\n\n## Sometimes Breaking Rules is OK\n\n**Denormalize when:**\n- Read performance critical\n- Joins too expensive\n- Analytics/reporting use case\n- Data rarely changes\n\n**Keep normalized when:**\n- Transactional system\n- Data changes frequently\n- Storage matters\n\n## Common Denormalization\n\n```sql\n-- Pre-aggregate daily revenue\nCREATE TABLE daily_revenue AS\nSELECT DATE(order_date) as date, SUM(amount) as revenue\nFROM orders GROUP BY 1;\n```\n\n---\n\n## üéØ Your Task\n\nCreate a summary query showing daily order counts.\n",
    "starter_code": "-- Get daily order counts\n\n",
    "solution_code": "SELECT DATE(order_date) as date, COUNT(*) as order_count\nFROM orders\nGROUP BY DATE(order_date);",
    "expected_output": "date       | order_count\n2024-03-01 | 15\n2024-03-02 | 23",
    "chapter_id": 210,
    "chapter_title": "Database Design Essentials"
  },
  "1122": {
    "id": 1122,
    "title": "Analytics Schema Design",
    "content": "# üìä Analytics Schema Design\n\n## Best Practices\n\n1. **Date dimension** - always include\n2. **Surrogate keys** - use INT not natural keys\n3. **Grain matters** - define clearly\n4. **Additive measures** - SUM-friendly\n\n## Example Analytics Schema\n\n```\ndim_date (date_id, date, month, quarter, year)\ndim_customer (customer_id, name, segment)\nfact_orders (date_id, customer_id, amount)\n```\n\n---\n\n## üéØ Your Task\n\nJoin orders with dates to get monthly revenue.\n",
    "starter_code": "-- Monthly revenue aggregation\n\n",
    "solution_code": "SELECT DATE_TRUNC('month', order_date) as month, SUM(amount) as revenue\nFROM orders\nGROUP BY DATE_TRUNC('month', order_date)\nORDER BY month;",
    "expected_output": "month      | revenue\n2024-01-01 | 45000\n2024-02-01 | 52000",
    "chapter_id": 210,
    "chapter_title": "Database Design Essentials"
  },
  "1123": {
    "id": 1123,
    "title": "Why Performance Matters",
    "content": "# ‚ö° Why Performance Matters\n\n## Real Impact\n\n- Slow dashboards = frustrated users\n- Expensive cloud bills\n- Timeouts on large queries\n\n## Key Metrics\n\n| Metric | Good | Bad |\n| --- | --- | --- |\n| Query time | < 5 sec | > 30 sec |\n| Rows scanned | Minimal | Full table |\n| Cost | Predictable | Spiky |\n\n---\n\n## üéØ Your Task\n\nSelect only the columns you need (not SELECT *).\n",
    "starter_code": "-- Select only id and name from users\n\n",
    "solution_code": "SELECT id, name FROM users;",
    "expected_output": "id | name\n1  | Alice\n2  | Bob",
    "chapter_id": 211,
    "chapter_title": "Performance & Query Plans"
  },
  "1124": {
    "id": 1124,
    "title": "Introduction to Indexes",
    "content": "# üìá Introduction to Indexes\n\n## What is an Index?\n\nA data structure that speeds up lookups, like a book index.\n\n## Without Index\n\nDatabase scans every row (table scan).\n\n## With Index\n\nDatabase jumps directly to matching rows.\n\n```sql\nCREATE INDEX idx_email ON users(email);\n```\n\n---\n\n## üéØ Your Task\n\nFind user by email (uses index if exists).\n",
    "starter_code": "-- Find user by email\n\n",
    "solution_code": "SELECT * FROM users WHERE email = 'alice@mail.com';",
    "expected_output": "id | name  | email\n1  | Alice | alice@mail.com",
    "chapter_id": 211,
    "chapter_title": "Performance & Query Plans"
  },
  "1125": {
    "id": 1125,
    "title": "How Indexes Work",
    "content": "# üå≥ How Indexes Work\n\n## B-Tree Structure\n\nMost indexes use B-trees:\n- Sorted data\n- O(log n) lookups\n- Good for equals and ranges\n\n## Index Lookup\n\n1. Search index tree\n2. Find row pointers\n3. Fetch actual rows\n\n---\n\n## üéØ Your Task\n\nFind orders in a date range (benefits from index on order_date).\n",
    "starter_code": "-- Find orders in March 2024\n\n",
    "solution_code": "SELECT * FROM orders\nWHERE order_date BETWEEN '2024-03-01' AND '2024-03-31';",
    "expected_output": "order_id | order_date | amount\n10       | 2024-03-15 | 100",
    "chapter_id": 211,
    "chapter_title": "Performance & Query Plans"
  },
  "1126": {
    "id": 1126,
    "title": "Index Trade-offs",
    "content": "# ‚öñÔ∏è Index Trade-offs\n\n## Benefits\n\n- Faster reads\n- Quick lookups\n\n## Costs\n\n- Slower writes (index updates)\n- Storage space\n- Maintenance overhead\n\n## When to Index\n\n| Index | Don't Index |\n| --- | --- |\n| Frequently filtered | Rarely queried |\n| High cardinality | Low cardinality |\n| JOIN keys | Write-heavy tables |\n\n---\n\n## üéØ Your Task\n\nFilter by high-cardinality column (customer_id is good for indexing).\n",
    "starter_code": "-- Find orders for customer 5\n\n",
    "solution_code": "SELECT * FROM orders WHERE customer_id = 5;",
    "expected_output": "order_id | customer_id | amount\n12       | 5           | 200",
    "chapter_id": 211,
    "chapter_title": "Performance & Query Plans"
  },
  "1127": {
    "id": 1127,
    "title": "Reading EXPLAIN Output",
    "content": "# üìñ Reading EXPLAIN Output\n\n## EXPLAIN Basics\n\n```sql\nEXPLAIN SELECT * FROM orders WHERE customer_id = 5;\n```\n\n## What to Look For\n\n| Term | Meaning |\n| --- | --- |\n| Seq Scan | Full table scan (slow) |\n| Index Scan | Uses index (fast) |\n| Rows | Estimated rows |\n| Cost | Query cost estimate |\n\n---\n\n## üéØ Your Task\n\nWrite a query that would use an index on customer_id.\n",
    "starter_code": "-- Query that benefits from customer_id index\n\n",
    "solution_code": "SELECT * FROM orders WHERE customer_id = 1;",
    "expected_output": "order_id | customer_id | amount\n1        | 1           | 50",
    "chapter_id": 211,
    "chapter_title": "Performance & Query Plans"
  },
  "1128": {
    "id": 1128,
    "title": "Sequential vs Index Scan",
    "content": "# üîç Sequential vs Index Scan\n\n## Sequential Scan\n\n- Reads every row\n- Good for: small tables, no WHERE\n\n## Index Scan\n\n- Uses index to find rows\n- Good for: selective WHERE clauses\n\n## Rule of Thumb\n\nIf <5-10% of rows match, use index.\n\n---\n\n## üéØ Your Task\n\nWrite a selective query (finds few rows).\n",
    "starter_code": "-- Find the single order with id = 1\n\n",
    "solution_code": "SELECT * FROM orders WHERE id = 1;",
    "expected_output": "id | amount\n1  | 50",
    "chapter_id": 211,
    "chapter_title": "Performance & Query Plans"
  },
  "1129": {
    "id": 1129,
    "title": "Filter Early Principle",
    "content": "# üéØ Filter Early Principle\n\n## Key Insight\n\nThe sooner you filter, the less data to process.\n\n## Bad: Filter Late\n\n```sql\n-- Joins all rows first!\nSELECT * FROM orders o\nJOIN customers c ON o.customer_id = c.id\nWHERE o.order_date > '2024-01-01';\n```\n\n## Good: Filter in Subquery\n\n```sql\nWITH recent_orders AS (\n  SELECT * FROM orders WHERE order_date > '2024-01-01'\n)\nSELECT * FROM recent_orders o\nJOIN customers c ON o.customer_id = c.id;\n```\n\n---\n\n## üéØ Your Task\n\nFilter orders first, then join.\n",
    "starter_code": "-- Filter orders before joining\n\n",
    "solution_code": "SELECT c.name, o.amount\nFROM orders o\nJOIN customers c ON o.customer_id = c.id\nWHERE o.amount > 100;",
    "expected_output": "name  | amount\nAlice | 150",
    "chapter_id": 211,
    "chapter_title": "Performance & Query Plans"
  },
  "1130": {
    "id": 1130,
    "title": "Reducing Rows Before Joins",
    "content": "# üîª Reducing Rows Before Joins\n\n## Pre-aggregate Pattern\n\n```sql\nWITH customer_totals AS (\n  SELECT customer_id, SUM(amount) as total\n  FROM orders\n  GROUP BY customer_id\n)\nSELECT c.name, ct.total\nFROM customers c\nJOIN customer_totals ct ON c.id = ct.customer_id;\n```\n\n## Benefits\n\n- Fewer rows in join\n- Less memory\n- Faster execution\n\n---\n\n## üéØ Your Task\n\nPre-aggregate orders then join to customers.\n",
    "starter_code": "-- Aggregate first, join second\n\n",
    "solution_code": "WITH order_totals AS (\n  SELECT customer_id, SUM(amount) as total\n  FROM orders\n  GROUP BY customer_id\n)\nSELECT c.name, ot.total\nFROM customers c\nJOIN order_totals ot ON c.id = ot.customer_id;",
    "expected_output": "name  | total\nAlice | 500\nBob   | 300",
    "chapter_id": 211,
    "chapter_title": "Performance & Query Plans"
  },
  "1131": {
    "id": 1131,
    "title": "Avoiding SELECT *",
    "content": "# üö´ Avoiding SELECT *\n\n## Why Avoid?\n\n- Fetches unneeded columns\n- More network transfer\n- Can't use covering indexes\n\n## Better Practice\n\n```sql\n-- Bad\nSELECT * FROM users;\n\n-- Good\nSELECT id, name, email FROM users;\n```\n\n---\n\n## üéØ Your Task\n\nSelect only name and email from customers.\n",
    "starter_code": "-- Select specific columns only\n\n",
    "solution_code": "SELECT name, email FROM customers;",
    "expected_output": "name  | email\nAlice | alice@mail.com",
    "chapter_id": 211,
    "chapter_title": "Performance & Query Plans"
  },
  "1132": {
    "id": 1132,
    "title": "INSERT Basics",
    "content": "# ‚ûï INSERT Basics\n\n## Inserting a Row\n\n```sql\nINSERT INTO users (name, email)\nVALUES ('Alice', 'alice@mail.com');\n```\n\n## Key Points\n\n- Specify columns explicitly\n- Values must match column order\n- Returns inserted rows (in Postgres)\n\n---\n\n## üéØ Your Task\n\nInsert a new product named 'Widget'.\n",
    "starter_code": "-- Insert a product\n\n",
    "solution_code": "INSERT INTO products (name, price)\nVALUES ('Widget', 25.00);",
    "expected_output": "INSERT 0 1",
    "chapter_id": 212,
    "chapter_title": "Mutations & Transactions"
  },
  "1133": {
    "id": 1133,
    "title": "INSERT Multiple Rows",
    "content": "# ‚ûï‚ûï INSERT Multiple Rows\n\n## Bulk Insert\n\n```sql\nINSERT INTO products (name, price) VALUES\n  ('Widget', 25),\n  ('Gadget', 50),\n  ('Gizmo', 75);\n```\n\n## Benefits\n\n- Single transaction\n- Faster than multiple INSERTs\n- Less overhead\n\n---\n\n## üéØ Your Task\n\nInsert 3 new users.\n",
    "starter_code": "-- Insert multiple users\n\n",
    "solution_code": "INSERT INTO users (name, email) VALUES\n  ('Alice', 'alice@mail.com'),\n  ('Bob', 'bob@mail.com'),\n  ('Charlie', 'charlie@mail.com');",
    "expected_output": "INSERT 0 3",
    "chapter_id": 212,
    "chapter_title": "Mutations & Transactions"
  },
  "1134": {
    "id": 1134,
    "title": "INSERT from SELECT",
    "content": "# üìã INSERT from SELECT\n\n## Copy Data Pattern\n\n```sql\nINSERT INTO archive_orders\nSELECT * FROM orders\nWHERE order_date < '2023-01-01';\n```\n\n## Use Cases\n\n- Archiving old data\n- Creating summary tables\n- Copying between tables\n\n---\n\n## üéØ Your Task\n\nInsert high-value orders (>1000) into vip_orders.\n",
    "starter_code": "-- Copy high-value orders\n\n",
    "solution_code": "INSERT INTO vip_orders\nSELECT * FROM orders WHERE amount > 1000;",
    "expected_output": "INSERT 0 5",
    "chapter_id": 212,
    "chapter_title": "Mutations & Transactions"
  },
  "1135": {
    "id": 1135,
    "title": "UPDATE Basics",
    "content": "# ‚úèÔ∏è UPDATE Basics\n\n## Updating Rows\n\n```sql\nUPDATE users\nSET email = 'new@mail.com'\nWHERE id = 1;\n```\n\n## ‚ö†Ô∏è ALWAYS use WHERE!\n\nWithout WHERE, updates ALL rows!\n\n---\n\n## üéØ Your Task\n\nUpdate product price for 'Widget' to 30.\n",
    "starter_code": "-- Update product price\n\n",
    "solution_code": "UPDATE products\nSET price = 30\nWHERE name = 'Widget';",
    "expected_output": "UPDATE 1",
    "chapter_id": 212,
    "chapter_title": "Mutations & Transactions"
  },
  "1136": {
    "id": 1136,
    "title": "UPDATE with Conditions",
    "content": "# ‚úèÔ∏è UPDATE with Conditions\n\n## Multiple Conditions\n\n```sql\nUPDATE orders\nSET status = 'shipped'\nWHERE status = 'paid' AND order_date < '2024-03-01';\n```\n\n## Update Multiple Columns\n\n```sql\nUPDATE users\nSET name = 'Alice Smith', updated_at = NOW()\nWHERE id = 1;\n```\n\n---\n\n## üéØ Your Task\n\nSet all pending orders to 'processing'.\n",
    "starter_code": "-- Update pending order status\n\n",
    "solution_code": "UPDATE orders\nSET status = 'processing'\nWHERE status = 'pending';",
    "expected_output": "UPDATE 10",
    "chapter_id": 212,
    "chapter_title": "Mutations & Transactions"
  },
  "1137": {
    "id": 1137,
    "title": "DELETE Basics",
    "content": "# üóëÔ∏è DELETE Basics\n\n## Deleting Rows\n\n```sql\nDELETE FROM users WHERE id = 1;\n```\n\n## ‚ö†Ô∏è ALWAYS use WHERE!\n\n```sql\nDELETE FROM users;  -- Deletes EVERYTHING!\n```\n\n---\n\n## üéØ Your Task\n\nDelete cancelled orders.\n",
    "starter_code": "-- Delete cancelled orders\n\n",
    "solution_code": "DELETE FROM orders WHERE status = 'cancelled';",
    "expected_output": "DELETE 5",
    "chapter_id": 212,
    "chapter_title": "Mutations & Transactions"
  },
  "1138": {
    "id": 1138,
    "title": "DELETE with Conditions",
    "content": "# üóëÔ∏è DELETE with Conditions\n\n## Safe Delete Pattern\n\n```sql\n-- Preview first\nSELECT * FROM orders WHERE order_date < '2020-01-01';\n\n-- Then delete\nDELETE FROM orders WHERE order_date < '2020-01-01';\n```\n\n## Using Subquery\n\n```sql\nDELETE FROM order_items\nWHERE order_id IN (\n  SELECT id FROM orders WHERE status = 'cancelled'\n);\n```\n\n---\n\n## üéØ Your Task\n\nDelete old orders (before 2023).\n",
    "starter_code": "-- Delete orders before 2023\n\n",
    "solution_code": "DELETE FROM orders WHERE order_date < '2023-01-01';",
    "expected_output": "DELETE 100",
    "chapter_id": 212,
    "chapter_title": "Mutations & Transactions"
  },
  "1139": {
    "id": 1139,
    "title": "Transaction Basics",
    "content": "# üîÑ Transaction Basics\n\n## What is a Transaction?\n\nA group of operations that succeed or fail together.\n\n## ACID Properties\n\n| Property | Meaning |\n| --- | --- |\n| Atomicity | All or nothing |\n| Consistency | Valid state |\n| Isolation | No interference |\n| Durability | Persisted |\n\n---\n\n## üéØ Your Task\n\nSelect orders to understand what you'll modify.\n",
    "starter_code": "-- Preview data before transaction\n\n",
    "solution_code": "SELECT * FROM orders WHERE status = 'pending';",
    "expected_output": "order_id | status\n1        | pending",
    "chapter_id": 212,
    "chapter_title": "Mutations & Transactions"
  },
  "1140": {
    "id": 1140,
    "title": "BEGIN, COMMIT, ROLLBACK",
    "content": "# üîí BEGIN, COMMIT, ROLLBACK\n\n## Transaction Flow\n\n```sql\nBEGIN;\n  UPDATE accounts SET balance = balance - 100 WHERE id = 1;\n  UPDATE accounts SET balance = balance + 100 WHERE id = 2;\nCOMMIT;  -- Save changes\n```\n\n## Rollback on Error\n\n```sql\nBEGIN;\n  -- If something goes wrong...\nROLLBACK;  -- Undo everything\n```\n\n---\n\n## üéØ Your Task\n\nSelect account balances.\n",
    "starter_code": "-- Check account balances\n\n",
    "solution_code": "SELECT id, balance FROM accounts;",
    "expected_output": "id | balance\n1  | 1000\n2  | 500",
    "chapter_id": 212,
    "chapter_title": "Mutations & Transactions"
  },
  "1141": {
    "id": 1141,
    "title": "Savepoints",
    "content": "# üìå Savepoints\n\n## Partial Rollback\n\n```sql\nBEGIN;\n  INSERT INTO orders VALUES (1, 100);\n  SAVEPOINT after_order;\n  INSERT INTO payments VALUES (1, 100);  -- Error!\n  ROLLBACK TO after_order;  -- Keep order, undo payment\nCOMMIT;\n```\n\n---\n\n## üéØ Your Task\n\nCount orders (understanding state before changes).\n",
    "starter_code": "-- Count existing orders\n\n",
    "solution_code": "SELECT COUNT(*) as order_count FROM orders;",
    "expected_output": "order_count\n150",
    "chapter_id": 212,
    "chapter_title": "Mutations & Transactions"
  },
  "1142": {
    "id": 1142,
    "title": "Isolation Levels Intro",
    "content": "# üîê Isolation Levels Intro\n\n## Levels\n\n| Level | Dirty Read | Lost Update |\n| --- | --- | --- |\n| Read Uncommitted | Yes | Yes |\n| Read Committed | No | Yes |\n| Repeatable Read | No | No |\n| Serializable | No | No |\n\n## Default\n\nMost databases: Read Committed\n\n---\n\n## üéØ Your Task\n\nShow current session settings.\n",
    "starter_code": "-- Simple query to test\n\n",
    "solution_code": "SELECT 1 as test;",
    "expected_output": "test\n1",
    "chapter_id": 212,
    "chapter_title": "Mutations & Transactions"
  },
  "1143": {
    "id": 1143,
    "title": "Safe Update Patterns",
    "content": "# üõ°Ô∏è Safe Update Patterns\n\n## Best Practices\n\n1. **Preview first**: SELECT before UPDATE/DELETE\n2. **Use transactions**: BEGIN...COMMIT\n3. **Limit rows**: Add LIMIT to test\n4. **Backup**: Create a copy before bulk changes\n\n```sql\n-- Safe pattern\nBEGIN;\nSELECT * FROM products WHERE price < 10;  -- Preview\nUPDATE products SET price = price * 1.1 WHERE price < 10;\n-- Verify, then COMMIT or ROLLBACK\n```\n\n---\n\n## üéØ Your Task\n\nPreview products that will be updated.\n",
    "starter_code": "-- Preview products with price < 10\n\n",
    "solution_code": "SELECT * FROM products WHERE price < 10;",
    "expected_output": "id | name   | price\n1  | Widget | 5",
    "chapter_id": 212,
    "chapter_title": "Mutations & Transactions"
  },
  "1144": {
    "id": 1144,
    "title": "Views Introduction",
    "content": "# üëÅÔ∏è Views Introduction\n\n## What is a View?\n\nA saved query that acts like a virtual table.\n\n```sql\nCREATE VIEW active_users AS\nSELECT * FROM users WHERE status = 'active';\n```\n\n## Benefits\n\n- Simplify complex queries\n- Security (hide columns)\n- Abstraction layer\n\n---\n\n## üéØ Your Task\n\nQuery from a conceptual 'active_orders' view.\n",
    "starter_code": "-- Query active orders\n\n",
    "solution_code": "SELECT * FROM orders WHERE status = 'active';",
    "expected_output": "order_id | status\n1        | active",
    "chapter_id": 213,
    "chapter_title": "Analytics Engineering"
  },
  "1145": {
    "id": 1145,
    "title": "Creating Views",
    "content": "# üî® Creating Views\n\n## Syntax\n\n```sql\nCREATE VIEW view_name AS\nSELECT columns FROM table WHERE condition;\n```\n\n## Example\n\n```sql\nCREATE VIEW monthly_revenue AS\nSELECT DATE_TRUNC('month', order_date) as month, SUM(amount) as revenue\nFROM orders GROUP BY 1;\n```\n\n---\n\n## üéØ Your Task\n\nWrite the SELECT for a daily_orders view.\n",
    "starter_code": "-- Query for daily orders view\n\n",
    "solution_code": "SELECT DATE(order_date) as date, COUNT(*) as orders\nFROM orders\nGROUP BY DATE(order_date);",
    "expected_output": "date       | orders\n2024-03-01 | 15",
    "chapter_id": 213,
    "chapter_title": "Analytics Engineering"
  },
  "1146": {
    "id": 1146,
    "title": "Views vs Tables",
    "content": "# ‚öñÔ∏è Views vs Tables\n\n## Differences\n\n| Feature | Table | View |\n| --- | --- | --- |\n| Stores data | Yes | No |\n| Updates | Direct | Through base |\n| Performance | Fast | Computed |\n\n## When to Use Views\n\n- Simplify complex joins\n- Restrict access\n- Reusable queries\n\n---\n\n## üéØ Your Task\n\nWrite a query that would make a good view.\n",
    "starter_code": "-- Customer summary suitable for a view\n\n",
    "solution_code": "SELECT c.name, COUNT(o.id) as order_count, SUM(o.amount) as total\nFROM customers c\nLEFT JOIN orders o ON c.id = o.customer_id\nGROUP BY c.id, c.name;",
    "expected_output": "name  | order_count | total\nAlice | 5           | 500",
    "chapter_id": 213,
    "chapter_title": "Analytics Engineering"
  },
  "1147": {
    "id": 1147,
    "title": "Materialized Views",
    "content": "# üíæ Materialized Views: Pre-Computed Results\n\n## What is a Materialized View?\n\nA **materialized view** stores the result of a query physically. Unlike regular views, the data is pre-computed and saved, making queries much faster!\n\n## Regular View vs Materialized View\n\n| Feature | Regular View | Materialized View |\n|---------|-------------|-------------------|\n| Storage | No data stored | Data is stored |\n| Query speed | Recomputes each time | Instant (reads saved data) |\n| Freshness | Always current | May be stale |\n| Use case | Simple abstraction | Performance optimization |\n\n## Real-World Analogy\n\n- **Regular View**: Calculating your bank balance every time (always accurate, but slow)\n- **Materialized View**: Your cached balance on the app (fast, but might be slightly old)\n\n## Creating a Materialized View\n\n```sql\nCREATE MATERIALIZED VIEW daily_summary AS\nSELECT \n    date,\n    SUM(sales) as total_sales,\n    COUNT(*) as order_count\nFROM orders\nGROUP BY date;\n```\n\n## Refreshing Data\n\n```sql\n-- Manual refresh\nREFRESH MATERIALIZED VIEW daily_summary;\n\n-- In some databases, can set auto-refresh\n```\n\n## When to Use\n\n‚úÖ Expensive aggregations run frequently\n‚úÖ Data doesn't need to be real-time\n‚úÖ Dashboard queries\n‚ùå Rapidly changing data needing real-time accuracy\n\n---\n\n## üéØ Your Task\n\nCreate a materialized view for monthly sales summary.",
    "starter_code": "-- Create a materialized view for monthly sales\nCREATE MATERIALIZED VIEW monthly_sales_summary AS\nSELECT \n    DATE_TRUNC('month', order_date) as month,\n    SUM(amount) as total_revenue,\n    COUNT(DISTINCT customer_id) as unique_customers,\n    AVG(amount) as avg_order_value\nFROM orders\nGROUP BY DATE_TRUNC('month', order_date);\n\n-- Query it instantly!\nSELECT * FROM monthly_sales_summary;",
    "solution_code": "CREATE MATERIALIZED VIEW monthly_sales_summary AS\nSELECT \n    DATE_TRUNC('month', order_date) as month,\n    SUM(amount) as total_revenue,\n    COUNT(DISTINCT customer_id) as unique_customers,\n    AVG(amount) as avg_order_value\nFROM orders\nGROUP BY DATE_TRUNC('month', order_date);\n\nSELECT * FROM monthly_sales_summary;",
    "expected_output": "2024-01|125000|450|277.78\n2024-02|142000|520|273.08",
    "chapter_id": 213,
    "chapter_title": "Analytics Engineering"
  },
  "1148": {
    "id": 1148,
    "title": "Naming Conventions",
    "content": "# üìù SQL Naming Conventions: Consistency Matters\n\n## Why Naming Conventions?\n\nGood naming makes code **readable**, **maintainable**, and **self-documenting**. When you return to code months later, clear names save hours!\n\n## Table Naming Best Practices\n\n| Convention | Example | Why |\n|------------|---------|-----|\n| snake_case | order_items | Consistent, readable |\n| Plural nouns | customers | Tables contain many rows |\n| Prefix by layer | stg_orders | Know the data stage |\n| No abbreviations | customer_id | Clarity over brevity |\n\n## Column Naming\n\n```sql\n-- ‚úÖ Good\ncustomer_id, order_date, total_amount, is_active\n\n-- ‚ùå Bad\nCustID, ord_dt, amt, Active\n```\n\n## Common Prefixes\n\n- **is_** for booleans: `is_active`, `is_deleted`\n- **has_** for booleans: `has_subscription`\n- **_at** for timestamps: `created_at`, `updated_at`\n- **_date** for dates: `order_date`, `birth_date`\n- **_id** for foreign keys: `customer_id`, `product_id`\n\n## Layer Prefixes\n\n| Prefix | Layer | Example |\n|--------|-------|---------|\n| raw_ | Raw source | raw_stripe_payments |\n| stg_ | Staging | stg_payments |\n| int_ | Intermediate | int_payment_joined |\n| dim_ | Dimension | dim_customers |\n| fct_ | Fact | fct_orders |\n\n## Real-World Impact\n\n```sql\n-- Which query would you rather debug at 2am?\nSELECT c.cid, o.amt FROM tbl_c c JOIN o_data o ON c.cid = o.c_id\n\n-- vs\n\nSELECT c.customer_id, o.order_amount \nFROM dim_customers c \nJOIN fct_orders o ON c.customer_id = o.customer_id\n```\n\n---\n\n## üéØ Your Task\n\nRename these poorly-named columns following conventions.",
    "starter_code": "-- Before: Bad naming\nCREATE TABLE tbl_cust (\n    ID int,\n    CustName varchar,\n    email varchar,\n    Active boolean,\n    DtCreated timestamp\n);\n\n-- After: Good naming  \nCREATE TABLE customers (\n    customer_id int,\n    customer_name varchar,\n    email varchar,\n    is_active boolean,\n    created_at timestamp\n);",
    "solution_code": "CREATE TABLE customers (\n    customer_id int,\n    customer_name varchar,\n    email varchar,\n    is_active boolean,\n    created_at timestamp\n);",
    "expected_output": "Table created with proper naming",
    "chapter_id": 213,
    "chapter_title": "Analytics Engineering"
  },
  "1149": {
    "id": 1149,
    "title": "SQL Style Guide",
    "content": "# üìê SQL Style Guide: Writing Beautiful Queries\n\n## Why Style Matters\n\nConsistent style makes SQL **readable**, **reviewable**, and **maintainable**. In a team, everyone should write SQL the same way.\n\n## Capitalization\n\n```sql\n-- ‚úÖ Keywords in UPPERCASE, identifiers in lowercase\nSELECT customer_name, order_amount\nFROM orders\nWHERE status = 'completed'\n\n-- ‚ùå Inconsistent capitalization\nselect Customer_Name, ORDER_AMOUNT\nfrom ORDERS\nWhere Status = 'completed'\n```\n\n## Indentation and Line Breaks\n\n```sql\n-- ‚úÖ Good: Each clause on new line, consistent indentation\nSELECT \n    c.customer_name,\n    o.order_date,\n    o.order_amount\nFROM customers c\nJOIN orders o\n    ON c.customer_id = o.customer_id\nWHERE o.order_date >= '2024-01-01'\n  AND o.status = 'completed'\nORDER BY o.order_date DESC;\n\n-- ‚ùå Bad: Everything on one line\nSELECT c.customer_name, o.order_date, o.order_amount FROM customers c JOIN orders o ON c.customer_id = o.customer_id WHERE o.order_date >= '2024-01-01' AND o.status = 'completed' ORDER BY o.order_date DESC;\n```\n\n## Comma Style\n\n```sql\n-- Leading commas (easier to comment out lines)\nSELECT \n    customer_id\n    ,customer_name\n    ,email\n    ,created_at\n\n-- Trailing commas (more common)\nSELECT \n    customer_id,\n    customer_name,\n    email,\n    created_at\n```\n\n## CTEs and Subqueries\n\n```sql\n-- ‚úÖ Descriptive CTE names\nWITH monthly_revenue AS (\n    SELECT DATE_TRUNC('month', order_date) as month,\n           SUM(amount) as revenue\n    FROM orders\n    GROUP BY 1\n)\nSELECT * FROM monthly_revenue;\n```\n\n---\n\n## üéØ Your Task\n\nReformat this messy query following style guidelines.",
    "starter_code": "-- Before: Messy\nselect c.name,count(*) as cnt,sum(o.amt) as total from customers c join orders o on c.id=o.cust_id where o.status='completed' group by c.name having count(*)>5 order by total desc;\n\n-- After: Clean and styled\nSELECT \n    c.customer_name,\n    COUNT(*) as order_count,\n    SUM(o.amount) as total_amount\nFROM customers c\nJOIN orders o \n    ON c.customer_id = o.customer_id\nWHERE o.status = 'completed'\nGROUP BY c.customer_name\nHAVING COUNT(*) > 5\nORDER BY total_amount DESC;",
    "solution_code": "SELECT \n    c.customer_name,\n    COUNT(*) as order_count,\n    SUM(o.amount) as total_amount\nFROM customers c\nJOIN orders o \n    ON c.customer_id = o.customer_id\nWHERE o.status = 'completed'\nGROUP BY c.customer_name\nHAVING COUNT(*) > 5\nORDER BY total_amount DESC;",
    "expected_output": "Query formatted successfully",
    "chapter_id": 213,
    "chapter_title": "Analytics Engineering"
  },
  "1150": {
    "id": 1150,
    "title": "Staging Models",
    "content": "# üèóÔ∏è Staging Models: The First Layer of Transformation\n\n## What are Staging Models?\n\n**Staging models** are the first layer in a dbt/analytics engineering project. They sit directly on top of raw source tables and handle initial cleaning.\n\n## The Role of Staging\n\n1. **Rename** confusing column names to clear ones\n2. **Type cast** strings to proper types\n3. **Filter** out test/junk data\n4. **Standardize** naming conventions\n5. **NO business logic** - just cleaning!\n\n## Real-World Analogy\n\nStaging is like the mail room: sort, label, and route packages (data) to the right departments‚Äîbut don't open them or make decisions about their contents.\n\n## Example Staging Model\n\n```sql\n-- stg_customers.sql\nSELECT\n    -- Rename columns\n    id as customer_id,\n    cust_nm as customer_name,\n    \n    -- Type casting\n    CAST(signup_dt as DATE) as signup_date,\n    \n    -- Standardize\n    LOWER(email) as email,\n    UPPER(state_code) as state\n    \nFROM raw.customers\nWHERE is_test = false  -- Filter test data\n```\n\n## Naming Convention\n\n- Prefix with `stg_`\n- Use source table name\n- Example: `stg_stripe_payments`, `stg_salesforce_accounts`\n\n## One Staging Model Per Source\n\nEach raw table gets exactly one staging model. Never join multiple sources in staging!\n\n---\n\n## üéØ Your Task\n\nCreate a staging model for the raw orders table.",
    "starter_code": "-- stg_orders.sql\n-- Clean up the raw orders table\n\nSELECT\n    -- Rename and clean columns\n    order_id,\n    customer_id,\n    \n    -- Cast to proper types\n    CAST(order_dt as DATE) as order_date,\n    CAST(total_amt as DECIMAL(10,2)) as order_amount,\n    \n    -- Standardize status values\n    UPPER(status) as order_status,\n    \n    -- Add metadata\n    CURRENT_TIMESTAMP as _loaded_at\n\nFROM raw.orders\nWHERE is_deleted = false;",
    "solution_code": "SELECT\n    order_id,\n    customer_id,\n    CAST(order_dt as DATE) as order_date,\n    CAST(total_amt as DECIMAL(10,2)) as order_amount,\n    UPPER(status) as order_status,\n    CURRENT_TIMESTAMP as _loaded_at\nFROM raw.orders\nWHERE is_deleted = false;",
    "expected_output": "Staging model created successfully",
    "chapter_id": 213,
    "chapter_title": "Analytics Engineering"
  },
  "1151": {
    "id": 1151,
    "title": "Intermediate Models",
    "content": "# üîß Intermediate Models: Building Blocks of Analysis\n\n## What are Intermediate Models?\n\n**Intermediate models** (or \"int\" models) are the middle layer where you:\n- Join data from multiple staging models\n- Apply business logic\n- Create reusable building blocks\n\n## The Transformation Pipeline\n\n```\nRaw Sources ‚Üí Staging ‚Üí Intermediate ‚Üí Marts\n     ‚Üì           ‚Üì           ‚Üì           ‚Üì\n  \"raw\"       \"stg_\"      \"int_\"      \"dim_/fct_\"\n```\n\n## What Happens in Intermediate?\n\n1. **Join** related staging models\n2. **Apply business logic** (calculations, flags)\n3. **Create reusable objects** used by multiple marts\n4. **Complex transformations** that are too big for marts\n\n## Example Intermediate Model\n\n```sql\n-- int_orders_with_customers.sql\nSELECT\n    o.order_id,\n    o.order_date,\n    o.order_amount,\n    c.customer_name,\n    c.customer_segment,\n    -- Business logic: calculate customer lifetime value\n    SUM(o.order_amount) OVER (PARTITION BY o.customer_id) as customer_ltv\nFROM stg_orders o\nJOIN stg_customers c ON o.customer_id = c.customer_id\n```\n\n## Naming Convention\n\n- Prefix with `int_`\n- Descriptive name of what it contains\n- Example: `int_orders_with_products`, `int_customer_order_history`\n\n---\n\n## üéØ Your Task\n\nCreate an intermediate model joining orders with customer data.",
    "starter_code": "-- int_orders_enriched.sql\n-- Join orders with customer information\n\nSELECT\n    o.order_id,\n    o.order_date,\n    o.order_amount,\n    o.order_status,\n    \n    -- Customer info\n    c.customer_name,\n    c.email,\n    c.signup_date,\n    \n    -- Business logic: days since signup\n    o.order_date - c.signup_date as days_as_customer,\n    \n    -- Customer order rank\n    ROW_NUMBER() OVER (PARTITION BY o.customer_id ORDER BY o.order_date) as customer_order_number\n\nFROM stg_orders o\nLEFT JOIN stg_customers c ON o.customer_id = c.customer_id;",
    "solution_code": "SELECT\n    o.order_id,\n    o.order_date,\n    o.order_amount,\n    o.order_status,\n    c.customer_name,\n    c.email,\n    c.signup_date,\n    o.order_date - c.signup_date as days_as_customer,\n    ROW_NUMBER() OVER (PARTITION BY o.customer_id ORDER BY o.order_date) as customer_order_number\nFROM stg_orders o\nLEFT JOIN stg_customers c ON o.customer_id = c.customer_id;",
    "expected_output": "Intermediate model created",
    "chapter_id": 213,
    "chapter_title": "Analytics Engineering"
  },
  "1152": {
    "id": 1152,
    "title": "Marts Layer",
    "content": "# üè™ Marts Layer: Business-Ready Data\n\n## What are Marts?\n\n**Marts** (or \"data marts\") are the final output tables that business users query. They're organized by business domain and ready for dashboards!\n\n## Types of Mart Tables\n\n### Dimension Tables (dim_)\nDescriptive data about entities:\n- `dim_customers` - customer attributes\n- `dim_products` - product catalog\n- `dim_dates` - date dimension\n\n### Fact Tables (fct_)\nMeasurable events/transactions:\n- `fct_orders` - order transactions\n- `fct_page_views` - website events\n- `fct_payments` - payment records\n\n## Mart Organization\n\nOrganize marts by business domain:\n```\nmarts/\n‚îú‚îÄ‚îÄ core/          # Shared across domains\n‚îÇ   ‚îú‚îÄ‚îÄ dim_customers.sql\n‚îÇ   ‚îî‚îÄ‚îÄ dim_dates.sql\n‚îú‚îÄ‚îÄ sales/         # Sales team\n‚îÇ   ‚îî‚îÄ‚îÄ fct_orders.sql\n‚îî‚îÄ‚îÄ marketing/     # Marketing team\n    ‚îî‚îÄ‚îÄ fct_campaigns.sql\n```\n\n## What Makes a Good Mart?\n\n‚úÖ **Self-contained**: Can be queried without joins\n‚úÖ **Well-documented**: Column descriptions\n‚úÖ **Performant**: Optimized for common queries\n‚úÖ **Business-friendly**: Uses clear naming\n\n## Example Mart\n\n```sql\n-- fct_orders.sql\nSELECT\n    order_id,\n    customer_id,\n    order_date,\n    order_amount,\n    order_status,\n    -- Pre-calculated metrics\n    SUM(order_amount) OVER (PARTITION BY customer_id) as customer_total_revenue\nFROM int_orders_enriched\n```\n\n---\n\n## üéØ Your Task\n\nCreate a fact table for orders with pre-calculated metrics.",
    "starter_code": "-- fct_orders.sql\n-- Final orders mart ready for business users\n\nSELECT\n    -- Keys\n    order_id,\n    customer_id,\n    product_id,\n    \n    -- Dates\n    order_date,\n    DATE_TRUNC('month', order_date) as order_month,\n    \n    -- Measures\n    quantity,\n    unit_price,\n    quantity * unit_price as line_total,\n    \n    -- Status\n    order_status,\n    CASE WHEN order_status = 'DELIVERED' THEN true ELSE false END as is_completed\n\nFROM int_orders_enriched;",
    "solution_code": "SELECT\n    order_id,\n    customer_id,\n    product_id,\n    order_date,\n    DATE_TRUNC('month', order_date) as order_month,\n    quantity,\n    unit_price,\n    quantity * unit_price as line_total,\n    order_status,\n    CASE WHEN order_status = 'DELIVERED' THEN true ELSE false END as is_completed\nFROM int_orders_enriched;",
    "expected_output": "Fact table created",
    "chapter_id": 213,
    "chapter_title": "Analytics Engineering"
  },
  "1153": {
    "id": 1153,
    "title": "Cloud vs Traditional DB",
    "content": "# ‚òÅÔ∏è Cloud vs Traditional Databases\n\n## The Fundamental Difference\n\n| Feature | Traditional DB | Cloud Warehouse |\n|---------|---------------|-----------------|\n| Scaling | Buy bigger server | Add more compute |\n| Cost | Fixed hardware | Pay per use |\n| Storage | Limited | Virtually unlimited |\n| Concurrency | Limited users | Many users |\n\n## Separation of Storage and Compute\n\nCloud warehouses separate storage and compute:\n- **Storage**: Your data sits in cheap cloud storage (S3, GCS)\n- **Compute**: Processing power scales up/down as needed\n\n## Real-World Analogy\n\n- **Traditional DB**: Owning a restaurant kitchen (fixed capacity)\n- **Cloud Warehouse**: Renting commercial kitchens by the hour (scale on demand)\n\n## Key Cloud Warehouse Features\n\n### 1. Elastic Scaling\n```\nNeed to run a big query? Scale up temporarily.\nQuery done? Scale back down.\nPay only for what you use!\n```\n\n### 2. Warehouse/Compute Clusters\n```sql\n-- Snowflake: Multiple warehouses for different teams\n-- BigQuery: Slots for compute allocation\n-- Redshift: Serverless or provisioned clusters\n```\n\n### 3. Results Caching\nMany cloud warehouses cache query results:\n```sql\n-- First run: 30 seconds, $0.50\n-- Second run: 0.5 seconds, $0 (cached!)\n```\n\n## Popular Cloud Warehouses\n\n| Name | Cloud Provider | Strength |\n|------|---------------|----------|\n| BigQuery | Google Cloud | Serverless, ML built-in |\n| Snowflake | Multi-cloud | Sharing, governance |\n| Redshift | AWS | AWS integration |\n| Databricks | Multi-cloud | Lakehouse, notebooks |\n\n---\n\n## üéØ Your Task\n\nCompare query performance concepts in cloud vs traditional.",
    "starter_code": "-- Cloud warehouse advantage: parallel processing\n-- Each node processes part of the data simultaneously\n\n-- Example: 10 billion row table\n-- Traditional: 1 server processes all rows sequentially\n-- Cloud: 100 nodes each process 100M rows in parallel\n\n-- Pseudo-code showing the concept\n/*\nTraditional (sequential):\n  for row in all_rows:\n    process(row)\n  // Time: 10 hours\n\nCloud (parallel):\n  parallel_for row_chunk in distribute(all_rows, 100):\n    process(row_chunk)\n  // Time: 6 minutes\n*/",
    "solution_code": "-- Cloud parallel processing example\nSELECT COUNT(*), SUM(amount)\nFROM billion_row_table\nWHERE date = '2024-01-15';\n-- Processed in seconds via parallel compute",
    "expected_output": "Cloud processing demonstrated",
    "chapter_id": 214,
    "chapter_title": "Cloud Warehouse Features"
  },
  "1154": {
    "id": 1154,
    "title": "QUALIFY Clause",
    "content": "# üéØ QUALIFY: Filter Window Function Results\n\n## What is QUALIFY?\n\n**QUALIFY** is a powerful clause (in Snowflake, Databricks, and others) that filters the results of window functions‚Äîlike WHERE, but for window calculations!\n\n## The Problem\n\nWithout QUALIFY, filtering on window functions is tedious:\n```sql\n-- Subquery required\nSELECT * FROM (\n    SELECT *, ROW_NUMBER() OVER (PARTITION BY dept ORDER BY salary DESC) as rn\n    FROM employees\n) \nWHERE rn = 1;\n```\n\n## The QUALIFY Solution\n\n```sql\n-- Clean and simple!\nSELECT *\nFROM employees\nQUALIFY ROW_NUMBER() OVER (PARTITION BY dept ORDER BY salary DESC) = 1;\n```\n\n## Execution Order\n\n```\nFROM ‚Üí WHERE ‚Üí GROUP BY ‚Üí HAVING ‚Üí SELECT ‚Üí QUALIFY ‚Üí ORDER BY\n```\n\nQUALIFY runs AFTER the window function is calculated.\n\n## Common Use Cases\n\n### Top N Per Group\n```sql\nSELECT *\nFROM orders\nQUALIFY ROW_NUMBER() OVER (PARTITION BY customer_id ORDER BY order_date DESC) <= 3;\n```\n\n### Deduplication\n```sql\nSELECT *\nFROM raw_events\nQUALIFY ROW_NUMBER() OVER (PARTITION BY event_id ORDER BY loaded_at DESC) = 1;\n```\n\n### Running Total Filter\n```sql\nSELECT *\nFROM transactions\nQUALIFY SUM(amount) OVER (ORDER BY date) >= 1000;\n```\n\n## Database Support\n\n| Database | QUALIFY Support |\n|----------|----------------|\n| Snowflake | ‚úÖ |\n| Databricks | ‚úÖ |\n| BigQuery | ‚úÖ (recent) |\n| PostgreSQL | ‚ùå (use subquery) |\n| MySQL | ‚ùå (use subquery) |\n\n---\n\n## üéØ Your Task\n\nUse QUALIFY to find the highest salary per department.",
    "starter_code": "-- Find top earner in each department using QUALIFY\nSELECT \n    employee_name,\n    department,\n    salary\nFROM employees\nQUALIFY ROW_NUMBER() OVER (\n    PARTITION BY department \n    ORDER BY salary DESC\n) = 1;",
    "solution_code": "SELECT \n    employee_name,\n    department,\n    salary\nFROM employees\nQUALIFY ROW_NUMBER() OVER (\n    PARTITION BY department \n    ORDER BY salary DESC\n) = 1;",
    "expected_output": "Alice|Engineering|120000\nBob|Sales|95000",
    "chapter_id": 214,
    "chapter_title": "Cloud Warehouse Features"
  },
  "1155": {
    "id": 1155,
    "title": "QUALIFY with ROW_NUMBER",
    "content": "# üî¢ QUALIFY with ROW_NUMBER: Powerful Deduplication\n\n## The Deduplication Problem\n\nRaw data often has duplicates. You need to keep just one version of each record‚Äîusually the most recent or highest quality.\n\n## Traditional Approach (Messy)\n\n```sql\n-- Requires subquery\nSELECT * FROM (\n    SELECT *,\n           ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY updated_at DESC) as rn\n    FROM raw_users\n)\nWHERE rn = 1;\n```\n\n## QUALIFY Approach (Clean)\n\n```sql\nSELECT *\nFROM raw_users\nQUALIFY ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY updated_at DESC) = 1;\n```\n\n## Common Patterns\n\n### Keep Latest Version\n```sql\nSELECT *\nFROM events\nQUALIFY ROW_NUMBER() OVER (PARTITION BY event_id ORDER BY loaded_at DESC) = 1;\n```\n\n### Keep First Occurrence\n```sql\nSELECT *\nFROM purchases  \nQUALIFY ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY purchase_date ASC) = 1;\n```\n\n### Keep Top N per Group\n```sql\nSELECT *\nFROM orders\nQUALIFY ROW_NUMBER() OVER (PARTITION BY customer_id ORDER BY order_amount DESC) <= 3;\n```\n\n### Keep Highest Priority\n```sql\nSELECT *\nFROM raw_data\nQUALIFY ROW_NUMBER() OVER (\n    PARTITION BY id \n    ORDER BY \n        CASE source WHEN 'primary' THEN 1 WHEN 'secondary' THEN 2 ELSE 3 END\n) = 1;\n```\n\n## Performance Benefits\n\nQUALIFY is not only cleaner but often performs better because the database can optimize the window function and filter together.\n\n---\n\n## üéØ Your Task\n\nDeduplicate raw orders keeping the latest update per order.",
    "starter_code": "-- Deduplicate raw_orders keeping latest version per order_id\nSELECT\n    order_id,\n    customer_id,\n    order_amount,\n    order_status,\n    updated_at\nFROM raw_orders\nQUALIFY ROW_NUMBER() OVER (\n    PARTITION BY order_id \n    ORDER BY updated_at DESC\n) = 1;",
    "solution_code": "SELECT\n    order_id,\n    customer_id,\n    order_amount,\n    order_status,\n    updated_at\nFROM raw_orders\nQUALIFY ROW_NUMBER() OVER (\n    PARTITION BY order_id \n    ORDER BY updated_at DESC\n) = 1;",
    "expected_output": "Deduplicated results",
    "chapter_id": 214,
    "chapter_title": "Cloud Warehouse Features"
  },
  "1156": {
    "id": 1156,
    "title": "Table Partitioning",
    "content": "# üìä Table Partitioning: Divide and Conquer\n\n## What is Partitioning?\n\n**Partitioning** divides a large table into smaller, more manageable pieces based on column values. Queries only scan relevant partitions!\n\n## Real-World Analogy\n\nInstead of searching through one giant filing cabinet, partition your files by year‚Äîthen when you need 2024 data, you only search the 2024 drawer!\n\n## How It Works\n\n```sql\n-- Query without partitioning: scans ALL data\nSELECT * FROM orders WHERE order_date = '2024-01-15';\n-- Scans: 10 billion rows üò±\n\n-- Query with date partitioning: scans ONE partition\nSELECT * FROM orders WHERE order_date = '2024-01-15';\n-- Scans: 27 million rows (just January 2024) ‚úÖ\n```\n\n## Creating Partitioned Tables\n\n### BigQuery\n```sql\nCREATE TABLE orders\nPARTITION BY DATE(order_date)\nAS SELECT * FROM raw_orders;\n```\n\n### Snowflake\n```sql\nCREATE TABLE orders\nCLUSTER BY (order_date)  -- Similar concept\nAS SELECT * FROM raw_orders;\n```\n\n## Partition Strategies\n\n| Strategy | Use When |\n|----------|----------|\n| Date/Time | Time-series data, most common |\n| Integer Range | ID ranges |\n| List | Known categories (country, status) |\n\n## Best Practices\n\n‚úÖ Partition on columns used in WHERE clauses\n‚úÖ Avoid too many small partitions\n‚úÖ Consider partition pruning in query design\n‚ùå Don't partition if table is small (<1GB)\n\n---\n\n## üéØ Your Task\n\nCreate a partitioned table for web events.",
    "starter_code": "-- Create date-partitioned events table (BigQuery syntax)\nCREATE TABLE analytics.events\nPARTITION BY DATE(event_timestamp)\nOPTIONS (\n    partition_expiration_days = 365\n)\nAS\nSELECT\n    event_id,\n    user_id,\n    event_type,\n    event_timestamp,\n    page_url\nFROM raw.events;\n\n-- Query only scans relevant date partitions\nSELECT event_type, COUNT(*)\nFROM analytics.events\nWHERE DATE(event_timestamp) = '2024-01-15'\nGROUP BY event_type;",
    "solution_code": "CREATE TABLE analytics.events\nPARTITION BY DATE(event_timestamp)\nAS SELECT * FROM raw.events;\n\nSELECT event_type, COUNT(*)\nFROM analytics.events\nWHERE DATE(event_timestamp) = '2024-01-15'\nGROUP BY event_type;",
    "expected_output": "Partitioned table created",
    "chapter_id": 214,
    "chapter_title": "Cloud Warehouse Features"
  },
  "1157": {
    "id": 1157,
    "title": "Clustering Keys",
    "content": "# üóÇÔ∏è Clustering Keys: Organizing Data Within Partitions\n\n## What is Clustering?\n\n**Clustering** organizes data within partitions by sorting and grouping related rows together. This optimizes queries filtering on clustered columns.\n\n## Partitioning vs Clustering\n\n| Feature | Partitioning | Clustering |\n|---------|-------------|------------|\n| Divides | Into separate partitions | Sorts within partitions |\n| Columns | Usually 1 (often date) | Up to 4 columns |\n| When to use | Date filters | Other frequent filters |\n\n## How It Works\n\nWithout clustering:\n```\nData stored randomly: [user_5, user_3, user_1, user_5, user_2, user_3...]\n```\n\nWith clustering on user_id:\n```\nData sorted together: [user_1, user_1, user_2, user_2, user_3, user_3...]\n```\n\n## Creating Clustered Tables\n\n### BigQuery\n```sql\nCREATE TABLE orders\nPARTITION BY DATE(order_date)\nCLUSTER BY customer_id, product_id\nAS SELECT * FROM raw_orders;\n```\n\n### Snowflake\n```sql\nCREATE TABLE orders\nCLUSTER BY (region, customer_id);\n```\n\n## When to Use Clustering\n\n‚úÖ Columns frequently used in WHERE clauses\n‚úÖ Columns used in JOINs\n‚úÖ High-cardinality columns (many unique values)\n‚úÖ Columns used in aggregations (GROUP BY)\n\n## Best Practices\n\n- Order matters! Put most important filter column first\n- Use with partitioning for best results\n- Monitor cluster efficiency over time\n\n---\n\n## üéØ Your Task\n\nCreate a clustered table for order analytics.",
    "starter_code": "-- Create partitioned AND clustered table\nCREATE TABLE analytics.orders\nPARTITION BY DATE(order_date)\nCLUSTER BY customer_id, region, product_category\nAS\nSELECT\n    order_id,\n    customer_id,\n    region,\n    product_category,\n    order_date,\n    order_amount\nFROM raw.orders;\n\n-- This query benefits from both partition pruning AND clustering\nSELECT customer_id, SUM(order_amount) as total\nFROM analytics.orders\nWHERE order_date BETWEEN '2024-01-01' AND '2024-01-31'\n  AND region = 'US-WEST'\nGROUP BY customer_id;",
    "solution_code": "CREATE TABLE analytics.orders\nPARTITION BY DATE(order_date)\nCLUSTER BY customer_id, region, product_category\nAS SELECT * FROM raw.orders;\n\nSELECT customer_id, SUM(order_amount)\nFROM analytics.orders\nWHERE order_date BETWEEN '2024-01-01' AND '2024-01-31'\n  AND region = 'US-WEST'\nGROUP BY customer_id;",
    "expected_output": "Clustered table created",
    "chapter_id": 214,
    "chapter_title": "Cloud Warehouse Features"
  },
  "1158": {
    "id": 1158,
    "title": "Cost-Based Thinking",
    "content": "# üí∞ Cost-Based Thinking: Money and Performance\n\n## Cloud Warehouse Pricing\n\nIn cloud data warehouses (BigQuery, Snowflake, Redshift), you typically pay for:\n- **Compute**: Time spent processing queries\n- **Storage**: Data stored in tables\n- **Data scanned**: Amount of data read\n\n## The Cost Equation\n\n```\nCost = Data Scanned √ó Price per TB\n```\n\nFor example, in BigQuery:\n- On-demand: ~$5 per TB scanned\n- 1 TB table fully scanned = $5 per query!\n\n## Reducing Costs\n\n### 1. Only SELECT Columns You Need\n```sql\n-- ‚ùå Expensive: scans all columns\nSELECT * FROM large_table;\n\n-- ‚úÖ Cheap: scans only needed columns\nSELECT customer_id, order_amount FROM large_table;\n```\n\n### 2. Use Partitions\n```sql\n-- ‚ùå Scans entire table\nSELECT * FROM events WHERE event_type = 'purchase';\n\n-- ‚úÖ Scans only 1 day of partitions\nSELECT * FROM events \nWHERE event_date = '2024-01-15' \n  AND event_type = 'purchase';\n```\n\n### 3. Preview Before Running\n```sql\n-- BigQuery: Dry run shows bytes scanned\n-- Snowflake: Query history shows costs\n```\n\n## Monitoring Costs\n\n- Set up query budgets\n- Review expensive queries weekly\n- Train team on cost-conscious queries\n\n---\n\n## üéØ Your Task\n\nOptimize this expensive query for lower costs.",
    "starter_code": "-- ‚ùå Expensive query (scans everything)\nSELECT * \nFROM events \nWHERE user_id = 12345;\n\n-- ‚úÖ Optimized query\nSELECT \n    event_id,\n    event_type,\n    event_timestamp\nFROM events \nWHERE event_date = CURRENT_DATE  -- Partition pruning\n  AND user_id = 12345;  -- Then filter",
    "solution_code": "SELECT \n    event_id,\n    event_type,\n    event_timestamp\nFROM events \nWHERE event_date = CURRENT_DATE\n  AND user_id = 12345;",
    "expected_output": "Query optimized for cost",
    "chapter_id": 214,
    "chapter_title": "Cloud Warehouse Features"
  },
  "1159": {
    "id": 1159,
    "title": "Scanning Fewer Columns",
    "content": "# üìâ Scanning Fewer Columns: Column Pruning\n\n## The Problem\n\nIn columnar databases (BigQuery, Snowflake, Redshift), data is stored by column. `SELECT *` forces the engine to read EVERY column!\n\n## Cost Impact\n\n```sql\n-- Wide table: 100 columns, 10 billion rows\n\nSELECT *  -- Reads all 100 columns = $$$$\nFROM huge_table;\n\nSELECT customer_id, order_amount  -- Reads 2 columns = $\nFROM huge_table;\n```\n\n## Real-World Example\n\n| Query | Columns Read | Data Scanned | Cost |\n|-------|-------------|--------------|------|\n| SELECT * | 100 | 500 GB | $2.50 |\n| SELECT (5 cols) | 5 | 25 GB | $0.13 |\n\nThat's **95% savings** just by being specific!\n\n## Best Practices\n\n### ‚úÖ Always name your columns\n```sql\nSELECT customer_id, order_date, order_amount\nFROM orders;\n```\n\n### ‚ùå Never use SELECT * in production\n```sql\nSELECT * FROM orders;  -- Don't do this!\n```\n\n### ‚úÖ Especially in subqueries and CTEs\n```sql\nWITH order_summary AS (\n    SELECT customer_id, SUM(amount) as total  -- Only what's needed\n    FROM orders\n    GROUP BY customer_id\n)\nSELECT * FROM order_summary;  -- OK here - CTE is already narrow\n```\n\n## Exceptions\n\n- **Exploring data**: SELECT * is fine in development\n- **Very narrow tables**: If table has 3-5 columns\n- **Exporting full rows**: When you truly need everything\n\n---\n\n## üéØ Your Task\n\nOptimize this query by selecting only needed columns.",
    "starter_code": "-- ‚ùå Before: Scans all columns\nSELECT *\nFROM customer_transactions\nWHERE transaction_date = '2024-01-15';\n\n-- ‚úÖ After: Only needed columns\nSELECT \n    transaction_id,\n    customer_id,\n    amount,\n    transaction_type\nFROM customer_transactions\nWHERE transaction_date = '2024-01-15';",
    "solution_code": "SELECT \n    transaction_id,\n    customer_id,\n    amount,\n    transaction_type\nFROM customer_transactions\nWHERE transaction_date = '2024-01-15';",
    "expected_output": "Query optimized",
    "chapter_id": 214,
    "chapter_title": "Cloud Warehouse Features"
  },
  "1160": {
    "id": 1160,
    "title": "Scanning Fewer Rows",
    "content": "# üìä Scanning Fewer Rows: Partition Pruning\n\n## The Core Concept\n\n**Partition pruning** is when the query engine skips entire partitions of data that don't match your filters. This can reduce scans from billions to millions of rows!\n\n## How Partitioning Helps\n\n```\nTable: events (partitioned by date)\n‚îú‚îÄ‚îÄ 2024-01-01/  (100M rows)\n‚îú‚îÄ‚îÄ 2024-01-02/  (100M rows)\n‚îú‚îÄ‚îÄ 2024-01-03/  (100M rows)\n‚îî‚îÄ‚îÄ ... (365 days = 36.5B rows)\n\nQuery: WHERE event_date = '2024-01-15'\nResult: Only scans 100M rows (0.3% of table!)\n```\n\n## Writing Partition-Pruning Queries\n\n### ‚úÖ Good: Filter on partition column\n```sql\nSELECT *\nFROM events\nWHERE event_date = '2024-01-15';  -- Scans 1 partition\n```\n\n### ‚ùå Bad: Function on partition column\n```sql\nSELECT *\nFROM events\nWHERE YEAR(event_date) = 2024;  -- Scans ALL partitions!\n```\n\n### ‚úÖ Fixed: Use range instead\n```sql\nSELECT *\nFROM events\nWHERE event_date >= '2024-01-01' \n  AND event_date < '2025-01-01';  -- Prunes correctly\n```\n\n## Common Mistakes\n\n| Query Pattern | Pruning? | Why |\n|--------------|----------|-----|\n| WHERE date = '2024-01-15' | ‚úÖ Yes | Direct comparison |\n| WHERE date BETWEEN dates | ‚úÖ Yes | Range comparison |\n| WHERE EXTRACT(YEAR FROM date) = 2024 | ‚ùå No | Function on column |\n| WHERE date_string LIKE '2024%' | ‚ùå No | String pattern |\n\n## Verify Pruning\n\n```sql\n-- BigQuery\nSELECT total_bytes_processed FROM query_plan;\n\n-- Snowflake  \nSELECT partitions_scanned FROM query_history;\n```\n\n---\n\n## üéØ Your Task\n\nRewrite this query to enable partition pruning.",
    "starter_code": "-- ‚ùå Before: No partition pruning (function on partition column)\nSELECT customer_id, SUM(amount)\nFROM transactions\nWHERE MONTH(transaction_date) = 1 AND YEAR(transaction_date) = 2024\nGROUP BY customer_id;\n\n-- ‚úÖ After: Partition pruning enabled\nSELECT customer_id, SUM(amount)\nFROM transactions\nWHERE transaction_date >= '2024-01-01' \n  AND transaction_date < '2024-02-01'\nGROUP BY customer_id;",
    "solution_code": "SELECT customer_id, SUM(amount)\nFROM transactions\nWHERE transaction_date >= '2024-01-01' \n  AND transaction_date < '2024-02-01'\nGROUP BY customer_id;",
    "expected_output": "Query optimized for partition pruning",
    "chapter_id": 214,
    "chapter_title": "Cloud Warehouse Features"
  },
  "1161": {
    "id": 1161,
    "title": "Query Optimization Tips",
    "content": "# ‚ö° Query Optimization: Best Practices\n\n## The Optimization Checklist\n\nBefore running any expensive query, run through this checklist:\n\n### 1. Column Selection\n```sql\n-- ‚ùå SELECT *\n-- ‚úÖ Select only needed columns\nSELECT customer_id, order_date, amount FROM orders;\n```\n\n### 2. Partition Filters\n```sql\n-- ‚ùå WHERE YEAR(date) = 2024\n-- ‚úÖ Use direct date ranges\nWHERE order_date >= '2024-01-01' AND order_date < '2025-01-01'\n```\n\n### 3. Predicate Pushdown\nPut filters as early as possible:\n```sql\n-- ‚ùå Filter after join\nSELECT * FROM a JOIN b ON a.id = b.id WHERE a.status = 'active';\n\n-- ‚úÖ Filter before join (if possible)\nSELECT * FROM (SELECT * FROM a WHERE status = 'active') a \nJOIN b ON a.id = b.id;\n```\n\n### 4. Avoid DISTINCT When Possible\n```sql\n-- ‚ùå Expensive\nSELECT DISTINCT customer_id FROM orders;\n\n-- ‚úÖ If grouping anyway\nSELECT customer_id FROM orders GROUP BY customer_id;\n```\n\n### 5. Use Approximate Functions\n```sql\n-- ‚ùå Exact count (slow)\nSELECT COUNT(DISTINCT user_id) FROM events;\n\n-- ‚úÖ Approximate count (fast, ~2% error)\nSELECT APPROX_COUNT_DISTINCT(user_id) FROM events;\n```\n\n### 6. Limit Early in Development\n```sql\n-- Always limit when exploring\nSELECT * FROM huge_table LIMIT 100;\n```\n\n## Performance Analysis\n\n```sql\n-- View query plan\nEXPLAIN SELECT ...\n\n-- View execution stats\nEXPLAIN ANALYZE SELECT ...\n```\n\n---\n\n## üéØ Your Task\n\nOptimize this inefficient query using multiple techniques.",
    "starter_code": "-- ‚ùå Before: Multiple inefficiencies\nSELECT DISTINCT *\nFROM customer_orders\nWHERE EXTRACT(YEAR FROM order_date) = 2024\n  AND EXTRACT(MONTH FROM order_date) = 1;\n\n-- ‚úÖ After: Optimized\nSELECT \n    order_id,\n    customer_id,\n    order_amount,\n    order_date\nFROM customer_orders\nWHERE order_date >= '2024-01-01' \n  AND order_date < '2024-02-01'\nGROUP BY 1, 2, 3, 4;",
    "solution_code": "SELECT \n    order_id,\n    customer_id,\n    order_amount,\n    order_date\nFROM customer_orders\nWHERE order_date >= '2024-01-01' \n  AND order_date < '2024-02-01';",
    "expected_output": "Query fully optimized",
    "chapter_id": 214,
    "chapter_title": "Cloud Warehouse Features"
  },
  "145": {
    "id": 145,
    "title": "Variable Swapping Challenge",
    "content": "# üîÑ Variable Swapping Challenge\n\n## The Challenge\n\nIn data science, you often need to swap values between variables. This is common when:\n- Sorting data manually\n- Reordering elements\n- Implementing algorithms\n\n## Python's Elegant Swap\n\nPython has a unique feature:\n\n```python\na = 10\nb = 20\na, b = b, a  # Swap!\n```\n\n---\n\n## üéØ Your Task\n\nYou have three podium positions. Due to a scoring error, shift positions:\n- Gold ‚Üí Silver\n- Silver ‚Üí Bronze  \n- Bronze ‚Üí Gold\n\nSwap and print the new podium.",
    "starter_code": "# Current podium\ngold = \"Alice\"\nsilver = \"Bob\"\nbronze = \"Charlie\"\n\n# Swap positions\n\n\n# Print new podium\nprint(f\"Gold: {gold}\")\nprint(f\"Silver: {silver}\")\nprint(f\"Bronze: {bronze}\")",
    "solution_code": "# Current podium\ngold = \"Alice\"\nsilver = \"Bob\"\nbronze = \"Charlie\"\n\n# Swap positions\ngold, silver, bronze = bronze, gold, silver\n\n# Print new podium\nprint(f\"Gold: {gold}\")\nprint(f\"Silver: {silver}\")\nprint(f\"Bronze: {bronze}\")",
    "expected_output": "Gold: Charlie\nSilver: Alice\nBronze: Bob",
    "chapter_id": 1,
    "chapter_title": "Variables, Types & Memory"
  },
  "146": {
    "id": 146,
    "title": "Data Cleaning with Strings",
    "content": "# üßπ Data Cleaning with Strings\n\n## Why Data Cleaning Matters\n\nReal-world data is messy! Common issues:\n- Extra whitespace\n- Inconsistent capitalization\n\n## String Methods for Cleaning\n\n```python\nraw = \"  JOHN DOE  \"\nclean = raw.strip().title()\nprint(clean)  # \"John Doe\"\n```\n\n---\n\n## üéØ Your Task\n\nClean messy user data:\n1. Name: trim + Title Case\n2. Email: trim + lowercase\n3. Phone: trim only",
    "starter_code": "# Messy user data\nname = \"   jOHN   sMITH   \"\nemail = \"  JOHN.SMITH@COMPANY.COM  \"\nphone = \"  (555) 123-4567  \"\n\n# Clean name\nname = \n\n# Clean email\nemail = \n\n# Clean phone\nphone = \n\n# Print results\nprint(name)\nprint(email)\nprint(phone)",
    "solution_code": "# Messy user data\nname = \"   jOHN   sMITH   \"\nemail = \"  JOHN.SMITH@COMPANY.COM  \"\nphone = \"  (555) 123-4567  \"\n\n# Clean name\nname = name.strip().title()\n\n# Clean email\nemail = email.strip().lower()\n\n# Clean phone\nphone = phone.strip()\n\n# Print results\nprint(name)\nprint(email)\nprint(phone)",
    "expected_output": "John   Smith\njohn.smith@company.com\n(555) 123-4567",
    "chapter_id": 1,
    "chapter_title": "Variables, Types & Memory"
  },
  "147": {
    "title": "Calculating Statistics",
    "chapter_title": "Variables, Types & Memory",
    "content": "# üìä Calculating Statistics: Your First Data Analysis!\n\n## Welcome to Real Data Science\n\nYou've learned about numbers and math‚Äînow let's use those skills to analyze real data! Statistics help us summarize and understand large amounts of information.\n\n## Real-World Scenario\n\nImagine you're the sales manager for a small business. Your boss asks: *\"How did we do each quarter this year?\"* Instead of looking at hundreds of transactions, you calculate summary statistics!\n\n## Key Statistics We'll Calculate\n\n### 1. Total (Sum)\nAdd up all values to get the grand total.\n```python\ntotal = sum(sales)  # or: sales[0] + sales[1] + ...\n```\n\n### 2. Average (Mean)\nDivide total by count to find the typical value.\n```python\naverage = sum(sales) / len(sales)\n```\n\n### 3. Maximum\nFind the best-performing period.\n```python\nbest = max(sales)\n```\n\n### 4. Range\nHow much variation exists? (max - min)\n```python\nrange_value = max(sales) - min(sales)\n```\n\n## Example Walkthrough\n\n```python\nquarterly_sales = [15000, 18500, 24500, 22000]\n\n# Total revenue\ntotal = sum(quarterly_sales)  # 80000\n\n# Average per quarter\naverage = total / len(quarterly_sales)  # 20000\n\n# Best quarter\nbest = max(quarterly_sales)  # 24500\n\n# How much variation?\nrange_val = max(quarterly_sales) - min(quarterly_sales)  # 9500\n```\n\n---\n\n## üéØ Your Task\n\nYour company had these quarterly sales: Q1=$15,000, Q2=$18,500, Q3=$24,500, Q4=$22,000\n\nCalculate all four statistics and print a complete summary report!",
    "starter_code": "# Your company's quarterly sales data\nquarterly_sales = [15000, 18500, 24500, 22000]\n\n# Calculate statistics\ntotal_sales = sum(quarterly_sales)\naverage_sales = total_sales / len(quarterly_sales)\nbest_quarter = max(quarterly_sales)\nsales_range = max(quarterly_sales) - min(quarterly_sales)\n\n# Print your report\nprint(f\"Total: ${total_sales}\")\nprint(f\"Average: ${average_sales}\")\nprint(f\"Best Quarter: ${best_quarter}\")\nprint(f\"Range: ${sales_range}\")",
    "solution_code": "quarterly_sales = [15000, 18500, 24500, 22000]\n\ntotal_sales = sum(quarterly_sales)\naverage_sales = total_sales / len(quarterly_sales)\nbest_quarter = max(quarterly_sales)\nsales_range = max(quarterly_sales) - min(quarterly_sales)\n\nprint(f\"Total: ${total_sales}\")\nprint(f\"Average: ${average_sales}\")\nprint(f\"Best Quarter: ${best_quarter}\")\nprint(f\"Range: ${sales_range}\")",
    "expected_output": "Total: $80000\nAverage: $20000.0\nBest Quarter: $24500\nRange: $9500"
  },
  "148": {
    "title": "Financial Calculations",
    "chapter_title": "Variables, Types & Memory",
    "content": "# üí∞ Financial Calculations: E-Commerce Checkout\n\n## The Business Problem\n\nYou're building the checkout page for an online store. When a customer is ready to pay, you need to calculate:\n\n1. **Subtotal**: Sum of all items\n2. **Discount**: The amount saved (percentage off)\n3. **Tax**: Sales tax on the discounted price\n4. **Final Total**: What they actually pay\n\n## The Math Behind It\n\n```python\n# Step 1: Add up all items\nsubtotal = item1 + item2 + item3\n\n# Step 2: Calculate discount amount\ndiscount = subtotal * discount_percent\n\n# Step 3: Apply discount to get taxable amount\nafter_discount = subtotal - discount\n\n# Step 4: Calculate tax\ntax = after_discount * tax_rate\n\n# Step 5: Final total\nfinal_total = after_discount + tax\n```\n\n## Order of Operations Matters!\n\n‚ö†Ô∏è **Common mistake**: Applying tax BEFORE discount!\n\n**Wrong**: Tax on $100, then discount = $108 - $15 = $93\n**Right**: Discount first ($85), then tax = $85 + $7.23 = $92.23\n\nThe customer saves more when you discount first!\n\n## Real Example\n\n```python\nitems = [25.99, 15.49, 8.99, 49.99]  # Shopping cart\nsubtotal = sum(items)  # $100.46\n\ndiscount_percent = 0.15  # 15% off\ndiscount = subtotal * discount_percent  # $15.07\n\nafter_discount = subtotal - discount  # $85.39\ntax_rate = 0.085  # 8.5% sales tax\ntax = after_discount * tax_rate  # $7.26\n\nfinal_total = after_discount + tax  # $92.65\n```\n\n---\n\n## üéØ Your Task\n\nBuild a shopping cart calculator! The cart has items totaling $100. Apply a 15% discount, then 8.5% tax. Print each step and the final total.",
    "starter_code": "# Shopping cart items\nitems = [29.99, 15.99, 24.99, 19.99, 9.04]\n\n# Step 1: Calculate subtotal\nsubtotal = sum(items)\n\n# Step 2: Apply 15% discount\ndiscount_rate = 0.15\ndiscount_amount = subtotal * discount_rate\nafter_discount = subtotal - discount_amount\n\n# Step 3: Apply 8.5% tax\ntax_rate = 0.085\ntax_amount = after_discount * tax_rate\n\n# Step 4: Calculate final total\nfinal_total = after_discount + tax_amount\n\n# Print the receipt\nprint(f\"Subtotal: ${subtotal:.2f}\")\nprint(f\"Discount (15%): -${discount_amount:.2f}\")\nprint(f\"After Discount: ${after_discount:.2f}\")\nprint(f\"Tax (8.5%): ${tax_amount:.2f}\")\nprint(f\"Total: ${final_total:.2f}\")",
    "solution_code": "items = [29.99, 15.99, 24.99, 19.99, 9.04]\n\nsubtotal = sum(items)\ndiscount_rate = 0.15\ndiscount_amount = subtotal * discount_rate\nafter_discount = subtotal - discount_amount\n\ntax_rate = 0.085\ntax_amount = after_discount * tax_rate\n\nfinal_total = after_discount + tax_amount\n\nprint(f\"Subtotal: ${subtotal:.2f}\")\nprint(f\"Discount (15%): -${discount_amount:.2f}\")\nprint(f\"After Discount: ${after_discount:.2f}\")\nprint(f\"Tax (8.5%): ${tax_amount:.2f}\")\nprint(f\"Total: ${final_total:.2f}\")",
    "expected_output": "Subtotal: $100.00\nDiscount (15%): -$15.00\nAfter Discount: $85.00\nTax (8.5%): $7.23\nTotal: $92.23"
  },
  "149": {
    "id": 149,
    "title": "Converting Between Types",
    "content": "# üîÑ Converting Between Types\n\n## Common Conversions\n\n| Function | Example |\n|----------|--------|\n| `int()` | `int(\"42\")` ‚Üí 42 |\n| `float()` | `float(\"3.14\")` ‚Üí 3.14 |\n| `str()` | `str(42)` ‚Üí \"42\" |\n| `bool()` | `bool(1)` ‚Üí True |\n\n---\n\n## üéØ Your Task\n\nConvert survey data:\n- age_str ‚Üí integer\n- height_str ‚Üí float  \n- has_car_str ‚Üí boolean",
    "starter_code": "# Survey data (strings)\nage_str = \"28\"\nheight_str = \"5.9\"\nhas_car_str = \"1\"\n\n# Convert to integer\nage = \n\n# Convert to float\nheight = \n\n# Convert to boolean\nhas_car = \n\n# Print with types\nprint(f\"Age: {age} ({type(age).__name__})\")\nprint(f\"Height: {height} ({type(height).__name__})\")\nprint(f\"Has Car: {has_car} ({type(has_car).__name__})\")",
    "solution_code": "# Survey data (strings)\nage_str = \"28\"\nheight_str = \"5.9\"\nhas_car_str = \"1\"\n\n# Convert to integer\nage = int(age_str)\n\n# Convert to float\nheight = float(height_str)\n\n# Convert to boolean\nhas_car = bool(int(has_car_str))\n\n# Print with types\nprint(f\"Age: {age} ({type(age).__name__})\")\nprint(f\"Height: {height} ({type(height).__name__})\")\nprint(f\"Has Car: {has_car} ({type(has_car).__name__})\")",
    "expected_output": "Age: 28 (int)\nHeight: 5.9 (float)\nHas Car: True (bool)",
    "chapter_id": 1,
    "chapter_title": "Variables, Types & Memory"
  },
  "150": {
    "id": 150,
    "title": "Truthy and Falsy Values",
    "content": "# ‚ö° Truthy and Falsy Values\n\n## Falsy Values\n\n| Value | bool() |\n|-------|--------|\n| `0` | False |\n| `\"\"` | False |\n| `None` | False |\n| `[]` | False |\n\nEverything else is Truthy!\n\n---\n\n## üéØ Your Task\n\nPredict and print bool() of:\n- 0, \"0\", \" \", [], [0]",
    "starter_code": "# Test values\nvalue1 = 0\nvalue2 = \"0\"\nvalue3 = \" \"\nvalue4 = []\nvalue5 = [0]\n\n# Print the boolean of each\nprint(f\"value1: {bool(value1)}\")\nprint(f\"value2: {bool(value2)}\")\nprint(f\"value3: {bool(value3)}\")\nprint(f\"value4: {bool(value4)}\")\nprint(f\"value5: {bool(value5)}\")",
    "solution_code": "# Test values\nvalue1 = 0\nvalue2 = \"0\"\nvalue3 = \" \"\nvalue4 = []\nvalue5 = [0]\n\n# Print the boolean of each\nprint(f\"value1: {bool(value1)}\")\nprint(f\"value2: {bool(value2)}\")\nprint(f\"value3: {bool(value3)}\")\nprint(f\"value4: {bool(value4)}\")\nprint(f\"value5: {bool(value5)}\")",
    "expected_output": "value1: False\nvalue2: True\nvalue3: True\nvalue4: False\nvalue5: True",
    "chapter_id": 1,
    "chapter_title": "Variables, Types & Memory"
  },
  "151": {
    "id": 151,
    "title": "Parsing User Input",
    "content": "# üì• Parsing User Input\n\n## Splitting Strings\n\n```python\ndata = \"Alice,25,Engineer\"\nparts = data.split(\",\")\nname = parts[0]\nage = int(parts[1])\n```\n\n---\n\n## üéØ Your Task\n\nParse product record:\n`\"SKU12345,Widget Pro,29.99,150\"`\n\nExtract: sku, name, price (float), quantity (int)\nCalculate: total_value",
    "starter_code": "# Product record\nrecord = \"  SKU12345,Widget Pro,29.99,150  \"\n\n# Strip and split\nparts = \n\n# Extract fields\nsku = \nname = \nprice = \nquantity = \n\n# Calculate total value\ntotal_value = \n\n# Print results\nprint(f\"SKU: {sku}\")\nprint(f\"Name: {name}\")\nprint(f\"Price: ${price}\")\nprint(f\"Quantity: {quantity}\")\nprint(f\"Total Value: ${total_value}\")",
    "solution_code": "# Product record\nrecord = \"  SKU12345,Widget Pro,29.99,150  \"\n\n# Strip and split\nparts = record.strip().split(\",\")\n\n# Extract fields\nsku = parts[0]\nname = parts[1]\nprice = float(parts[2])\nquantity = int(parts[3])\n\n# Calculate total value\ntotal_value = price * quantity\n\n# Print results\nprint(f\"SKU: {sku}\")\nprint(f\"Name: {name}\")\nprint(f\"Price: ${price}\")\nprint(f\"Quantity: {quantity}\")\nprint(f\"Total Value: ${total_value}\")",
    "expected_output": "SKU: SKU12345\nName: Widget Pro\nPrice: $29.99\nQuantity: 150\nTotal Value: $4498.5",
    "chapter_id": 1,
    "chapter_title": "Variables, Types & Memory"
  },
  "152": {
    "id": 152,
    "title": "Type Validation Challenge",
    "content": "# üèÜ Type Validation Challenge\n\n## Final Challenge\n\nCombine parsing and calculations!\n\n---\n\n## üéØ Your Task\n\nParse sales record:\n`\"Electronics,Laptop Pro,1299.99,5,0.10\"`\n\nFormat: category,product,price,qty,discount_rate\n\nCalculate:\n- subtotal = price √ó qty\n- discount = subtotal √ó rate\n- final = subtotal - discount",
    "starter_code": "# Raw sales data\nraw_data = \"  Electronics,Laptop Pro,1299.99,5,0.10  \"\n\n# Parse the data\nparts = \ncategory = \nproduct = \nunit_price = \nquantity = \ndiscount_rate = \n\n# Calculate metrics\nsubtotal = \ndiscount = \nfinal_total = \n\n# Print receipt\nprint(f\"Category: {category}\")\nprint(f\"Product: {product}\")\nprint(f\"Subtotal: ${subtotal}\")\nprint(f\"Discount: ${discount}\")\nprint(f\"Final Total: ${final_total}\")",
    "solution_code": "# Raw sales data\nraw_data = \"  Electronics,Laptop Pro,1299.99,5,0.10  \"\n\n# Parse the data\nparts = raw_data.strip().split(\",\")\ncategory = parts[0]\nproduct = parts[1]\nunit_price = float(parts[2])\nquantity = int(parts[3])\ndiscount_rate = float(parts[4])\n\n# Calculate metrics\nsubtotal = unit_price * quantity\ndiscount = subtotal * discount_rate\nfinal_total = subtotal - discount\n\n# Print receipt\nprint(f\"Category: {category}\")\nprint(f\"Product: {product}\")\nprint(f\"Subtotal: ${subtotal}\")\nprint(f\"Discount: ${discount}\")\nprint(f\"Final Total: ${final_total}\")",
    "expected_output": "Category: Electronics\nProduct: Laptop Pro\nSubtotal: $6499.95\nDiscount: $649.995\nFinal Total: $5849.955",
    "chapter_id": 1,
    "chapter_title": "Variables, Types & Memory"
  },
  "153": {
    "id": 153,
    "title": "Counting Items",
    "content": "# üî¢ Counting Items in a Dataset\n\n## The Challenge\n\nIn data science, you often need to count specific items in a dataset. Let's practice this essential skill!\n\n## Using Loops to Count\n\n```python\nsales = [150, 200, 50, 300, 175]\nhigh_sales = 0\n\nfor sale in sales:\n    if sale > 100:\n        high_sales += 1\n\nprint(f\"High sales: {high_sales}\")  # Output: 4\n```\n\n## Pattern: Counter Variable\n\n1. Initialize a counter to 0\n2. Loop through items\n3. Add to counter when condition is met\n\n---\n\n## üéØ Your Task\n\nGiven a list of temperatures:\n```python\ntemps = [72, 85, 68, 91, 76, 88, 95, 70]\n```\n\nCount how many are above 80 degrees and print the result.",
    "starter_code": "temps = [72, 85, 68, 91, 76, 88, 95, 70]\n\n# Count temperatures above 80\nhot_days = 0\n\nfor temp in temps:\n    # Your code here\n    pass\n\nprint(f\"Hot days: {hot_days}\")",
    "solution_code": "temps = [72, 85, 68, 91, 76, 88, 95, 70]\n\n# Count temperatures above 80\nhot_days = 0\n\nfor temp in temps:\n    if temp > 80:\n        hot_days += 1\n\nprint(f\"Hot days: {hot_days}\")",
    "expected_output": "Hot days: 4",
    "chapter_id": 2,
    "chapter_title": "Loops (Iteration)"
  },
  "154": {
    "id": 154,
    "title": "Finding Totals",
    "content": "# ‚ûï Finding Totals with Loops\n\n## Accumulating Values\n\nA common pattern is summing values as you loop:\n\n```python\nprices = [29.99, 15.50, 42.00]\ntotal = 0\n\nfor price in prices:\n    total += price\n\nprint(f\"Total: ${total}\")\n```\n\n## Real-World Use Cases\n\n- Calculate total sales revenue\n- Sum expenses in a budget\n- Aggregate sensor readings\n\n---\n\n## üéØ Your Task\n\nCalculate the total points scored:\n```python\nscores = [12, 24, 18, 30, 15, 28]\n```\n\nPrint the total score.",
    "starter_code": "scores = [12, 24, 18, 30, 15, 28]\n\n# Calculate total\ntotal_points = 0\n\nfor score in scores:\n    # Add to total\n    pass\n\nprint(f\"Total points: {total_points}\")",
    "solution_code": "scores = [12, 24, 18, 30, 15, 28]\n\n# Calculate total\ntotal_points = 0\n\nfor score in scores:\n    total_points += score\n\nprint(f\"Total points: {total_points}\")",
    "expected_output": "Total points: 127",
    "chapter_id": 2,
    "chapter_title": "Loops (Iteration)"
  },
  "155": {
    "id": 155,
    "title": "Number Sequences",
    "content": "# üî¢ Generating Number Sequences\n\n## The range() Function\n\n`range()` generates sequences of numbers perfect for loops:\n\n```python\n# Print 0 to 4\nfor i in range(5):\n    print(i)\n\n# Print 1 to 5\nfor i in range(1, 6):\n    print(i)\n```\n\n## Creating Custom Sequences\n\n```python\n# Even numbers from 2 to 10\nfor num in range(2, 11, 2):\n    print(num)  # 2, 4, 6, 8, 10\n```\n\n---\n\n## üéØ Your Task\n\nGenerate and print the first 5 multiples of 3 (3, 6, 9, 12, 15).",
    "starter_code": "# Print first 5 multiples of 3\n# Use range() with step\n\nfor num in range():  # Fix the range\n    print(num)",
    "solution_code": "# Print first 5 multiples of 3\n# Use range() with step\n\nfor num in range(3, 16, 3):\n    print(num)",
    "expected_output": "3\n6\n9\n12\n15",
    "chapter_id": 2,
    "chapter_title": "Loops (Iteration)"
  },
  "156": {
    "id": 156,
    "title": "Countdown Timer",
    "content": "# ‚è∞ Countdown Timer\n\n## Counting Down with range()\n\nUse negative step to count down:\n\n```python\nfor i in range(5, 0, -1):\n    print(i)\nprint(\"Blastoff!\")\n```\n\nOutput: 5, 4, 3, 2, 1, Blastoff!\n\n---\n\n## üéØ Your Task\n\nCreate a countdown from 10 to 1, then print \"Happy New Year!\" ",
    "starter_code": "# Countdown from 10 to 1\n\nfor i in range():  # Fix the range\n    print(i)\n\nprint(\"Happy New Year!\")",
    "solution_code": "# Countdown from 10 to 1\n\nfor i in range(10, 0, -1):\n    print(i)\n\nprint(\"Happy New Year!\")",
    "expected_output": "10\n9\n8\n7\n6\n5\n4\n3\n2\n1\nHappy New Year!",
    "chapter_id": 2,
    "chapter_title": "Loops (Iteration)"
  },
  "157": {
    "id": 157,
    "title": "Input Validation",
    "content": "# ‚úÖ Input Validation with While Loops\n\n## Keep Asking Until Valid\n\nWhile loops are perfect for validation:\n\n```python\npassword = \"\"\nwhile len(password) < 8:\n    password = input(\"Enter password (8+ chars): \")\n\nprint(\"Password accepted!\")\n```\n\n## Simulated Validation\n\nFor this exercise, we'll simulate with a list of attempts.\n\n---\n\n## üéØ Your Task\n\nGiven a list of password attempts, use a while loop to find the first valid password (8+ characters) and print it.",
    "starter_code": "attempts = [\"abc\", \"12345\", \"password123\", \"hi\"]\n\n# Find first valid password (8+ chars)\ni = 0\nvalid_password = None\n\nwhile i < len(attempts):\n    # Check if current attempt is valid\n    # If valid, save it and break\n    pass\n\nprint(f\"Valid password: {valid_password}\")",
    "solution_code": "attempts = [\"abc\", \"12345\", \"password123\", \"hi\"]\n\n# Find first valid password (8+ chars)\ni = 0\nvalid_password = None\n\nwhile i < len(attempts):\n    if len(attempts[i]) >= 8:\n        valid_password = attempts[i]\n        break\n    i += 1\n\nprint(f\"Valid password: {valid_password}\")",
    "expected_output": "Valid password: password123",
    "chapter_id": 2,
    "chapter_title": "Loops (Iteration)"
  },
  "158": {
    "id": 158,
    "title": "Data Processing Loop",
    "content": "# üîÑ Data Processing Until Complete\n\n## While Loops for Processing\n\nProcess data until a condition is met:\n\n```python\nqueue = [5, 3, 8, 2]\nwhile len(queue) > 0:\n    item = queue.pop(0)  # Remove first item\n    print(f\"Processing: {item}\")\n```\n\n---\n\n## üéØ Your Task\n\nProcess items from a queue until it's empty. Calculate and print the sum of all processed items.",
    "starter_code": "queue = [10, 25, 15, 30, 20]\ntotal = 0\n\nwhile len(queue) > 0:\n    # Remove first item and add to total\n    pass\n\nprint(f\"Processed total: {total}\")",
    "solution_code": "queue = [10, 25, 15, 30, 20]\ntotal = 0\n\nwhile len(queue) > 0:\n    item = queue.pop(0)\n    total += item\n\nprint(f\"Processed total: {total}\")",
    "expected_output": "Processed total: 100",
    "chapter_id": 2,
    "chapter_title": "Loops (Iteration)"
  },
  "159": {
    "id": 159,
    "title": "Grade Calculator",
    "content": "# üìä Grade Calculator\n\n## Mapping Scores to Grades\n\nUse if-elif-else to assign letter grades:\n\n```python\nscore = 85\n\nif score >= 90:\n    grade = \"A\"\nelif score >= 80:\n    grade = \"B\"\nelif score >= 70:\n    grade = \"C\"\nelse:\n    grade = \"F\"\n```\n\n---\n\n## üéØ Your Task\n\nGiven a score, assign the correct letter grade and print it.\n- 90+: A\n- 80+: B\n- 70+: C\n- 60+: D\n- Below 60: F",
    "starter_code": "score = 75\n\n# Assign letter grade\ngrade = \"\"\n\n# Your if-elif-else here\n\nprint(f\"Grade: {grade}\")",
    "solution_code": "score = 75\n\n# Assign letter grade\nif score >= 90:\n    grade = \"A\"\nelif score >= 80:\n    grade = \"B\"\nelif score >= 70:\n    grade = \"C\"\nelif score >= 60:\n    grade = \"D\"\nelse:\n    grade = \"F\"\n\nprint(f\"Grade: {grade}\")",
    "expected_output": "Grade: C",
    "chapter_id": 3,
    "chapter_title": "Logic & Control Flow"
  },
  "160": {
    "id": 160,
    "title": "Age Categories",
    "content": "# üë• Age Categories\n\n## Categorizing Data\n\nData science often requires categorizing continuous values:\n\n```python\nage = 25\n\nif age < 18:\n    category = \"Minor\"\nelif age < 65:\n    category = \"Adult\"\nelse:\n    category = \"Senior\"\n```\n\n---\n\n## üéØ Your Task\n\nCategorize the age into: Child (0-12), Teen (13-19), Adult (20-64), Senior (65+).",
    "starter_code": "age = 45\n\n# Determine category\ncategory = \"\"\n\n# Your code here\n\nprint(f\"Category: {category}\")",
    "solution_code": "age = 45\n\n# Determine category\nif age <= 12:\n    category = \"Child\"\nelif age <= 19:\n    category = \"Teen\"\nelif age <= 64:\n    category = \"Adult\"\nelse:\n    category = \"Senior\"\n\nprint(f\"Category: {category}\")",
    "expected_output": "Category: Adult",
    "chapter_id": 3,
    "chapter_title": "Logic & Control Flow"
  },
  "161": {
    "id": 161,
    "title": "Complex Conditions",
    "content": "# üîó Complex Conditions\n\n## Combining AND/OR\n\nCreate sophisticated filters with logical operators:\n\n```python\nage = 25\nincome = 50000\ncredit_score = 720\n\n# All three conditions must be true\nif age >= 21 and income >= 30000 and credit_score >= 700:\n    approved = True\n```\n\n---\n\n## üéØ Your Task\n\nDetermine loan eligibility: approved if (age >= 18 AND income >= 25000) OR credit_score >= 750.",
    "starter_code": "age = 17\nincome = 30000\ncredit_score = 800\n\n# Determine eligibility\napproved = False\n\n# Your condition here\n\nprint(f\"Loan approved: {approved}\")",
    "solution_code": "age = 17\nincome = 30000\ncredit_score = 800\n\n# Determine eligibility\nif (age >= 18 and income >= 25000) or credit_score >= 750:\n    approved = True\nelse:\n    approved = False\n\nprint(f\"Loan approved: {approved}\")",
    "expected_output": "Loan approved: True",
    "chapter_id": 3,
    "chapter_title": "Logic & Control Flow"
  },
  "162": {
    "id": 162,
    "title": "Nested Decision Tree",
    "content": "# üå≥ Nested Decision Trees\n\n## Multi-Level Decisions\n\nSometimes decisions depend on previous decisions:\n\n```python\nage = 25\nincome = 50000\n\nif age >= 18:\n    if income >= 30000:\n        category = \"Qualified Adult\"\n    else:\n        category = \"Entry-Level Adult\"\nelse:\n    category = \"Minor\"\n```\n\n---\n\n## üéØ Your Task\n\nClassify a customer based on:\n- Premium: age >= 25 AND spending > 1000\n- Standard: age >= 18\n- Minor: age < 18",
    "starter_code": "age = 30\nspending = 1500\n\n# Classify customer\ncategory = \"\"\n\n# Your nested conditions\n\nprint(f\"Customer category: {category}\")",
    "solution_code": "age = 30\nspending = 1500\n\n# Classify customer\nif age >= 25 and spending > 1000:\n    category = \"Premium\"\nelif age >= 18:\n    category = \"Standard\"\nelse:\n    category = \"Minor\"\n\nprint(f\"Customer category: {category}\")",
    "expected_output": "Customer category: Premium",
    "chapter_id": 3,
    "chapter_title": "Logic & Control Flow"
  },
  "163": {
    "id": 163,
    "title": "Smart Filter",
    "content": "# üîç Smart Filtering\n\n## Complex Filter Logic\n\nCombine multiple conditions to filter data:\n\n```python\nproducts = [{\"name\": \"A\", \"price\": 100, \"stock\": 5}]\n\nfor p in products:\n    if p[\"price\"] < 50 and p[\"stock\"] > 0:\n        print(p[\"name\"])\n```\n\n---\n\n## üéØ Your Task\n\nFilter products that are: in stock (> 0) AND either (price < 100 OR on_sale is True)",
    "starter_code": "products = [\n    {\"name\": \"Widget\", \"price\": 150, \"stock\": 10, \"on_sale\": True},\n    {\"name\": \"Gadget\", \"price\": 80, \"stock\": 0, \"on_sale\": False},\n    {\"name\": \"Tool\", \"price\": 50, \"stock\": 5, \"on_sale\": False}\n]\n\n# Filter products\nfor p in products:\n    # Check: in stock AND (cheap OR on_sale)\n    pass",
    "solution_code": "products = [\n    {\"name\": \"Widget\", \"price\": 150, \"stock\": 10, \"on_sale\": True},\n    {\"name\": \"Gadget\", \"price\": 80, \"stock\": 0, \"on_sale\": False},\n    {\"name\": \"Tool\", \"price\": 50, \"stock\": 5, \"on_sale\": False}\n]\n\n# Filter products\nfor p in products:\n    if p[\"stock\"] > 0 and (p[\"price\"] < 100 or p[\"on_sale\"]):\n        print(p[\"name\"])",
    "expected_output": "Widget\nTool",
    "chapter_id": 3,
    "chapter_title": "Logic & Control Flow"
  },
  "164": {
    "id": 164,
    "title": "Priority Sorter",
    "content": "# üéØ Priority Assignment\n\n## Assigning Priorities\n\nUse conditions to assign priority levels:\n\n```python\nif urgent and important:\n    priority = \"Critical\"\nelif urgent or important:\n    priority = \"High\"\nelse:\n    priority = \"Normal\"\n```\n\n---\n\n## üéØ Your Task\n\nAssign priority: Critical (urgent AND important), High (urgent OR important), Normal (neither)",
    "starter_code": "urgent = True\nimportant = False\n\n# Assign priority\npriority = \"\"\n\n# Your conditions\n\nprint(f\"Priority: {priority}\")",
    "solution_code": "urgent = True\nimportant = False\n\n# Assign priority\nif urgent and important:\n    priority = \"Critical\"\nelif urgent or important:\n    priority = \"High\"\nelse:\n    priority = \"Normal\"\n\nprint(f\"Priority: {priority}\")",
    "expected_output": "Priority: High",
    "chapter_id": 3,
    "chapter_title": "Logic & Control Flow"
  },
  "165": {
    "id": 165,
    "title": "Calculate Tax",
    "content": "# üí∞ Tax Calculation Function\n\n## Functions for Calculations\n\n```python\ndef calculate_tax(amount, rate=0.1):\n    return amount * rate\n\ntax = calculate_tax(100)  # 10.0\n```\n\n---\n\n## üéØ Your Task\n\nCreate a function that calculates tax with a default rate of 8.5%.",
    "starter_code": "def calculate_tax(amount, rate=0.085):\n    # Return the tax amount\n    pass\n\n# Test\nresult = calculate_tax(100)\nprint(f\"Tax: ${result}\")",
    "solution_code": "def calculate_tax(amount, rate=0.085):\n    return amount * rate\n\n# Test\nresult = calculate_tax(100)\nprint(f\"Tax: ${result}\")",
    "expected_output": "Tax: $8.5",
    "chapter_id": 4,
    "chapter_title": "Functions"
  },
  "166": {
    "id": 166,
    "title": "Format Currency",
    "content": "# üíµ Currency Formatting Function\n\n## String Formatting in Functions\n\n```python\ndef format_currency(amount, symbol=\"$\"):\n    return f\"{symbol}{amount:,.2f}\"\n```\n\n---\n\n## üéØ Your Task\n\nCreate a function to format numbers as currency with 2 decimal places.",
    "starter_code": "def format_currency(amount, symbol=\"$\"):\n    # Format with 2 decimals and comma separators\n    pass\n\n# Test\nprint(format_currency(1234.5))\nprint(format_currency(9999999, \"‚Ç¨\"))",
    "solution_code": "def format_currency(amount, symbol=\"$\"):\n    return f\"{symbol}{amount:,.2f}\"\n\n# Test\nprint(format_currency(1234.5))\nprint(format_currency(9999999, \"‚Ç¨\"))",
    "expected_output": "$1,234.50\n‚Ç¨9,999,999.00",
    "chapter_id": 4,
    "chapter_title": "Functions"
  },
  "167": {
    "id": 167,
    "title": "Flexible Greeting",
    "content": "# üëã Flexible Greeting Function\n\n## Using Default and Keyword Arguments\n\n```python\ndef greet(name, greeting=\"Hello\", punctuation=\"!\"):\n    return f\"{greeting}, {name}{punctuation}\"\n```\n\n---\n\n## üéØ Your Task\n\nCreate a greeting function with customizable greeting and punctuation.",
    "starter_code": "def greet(name, greeting=\"Hello\", punctuation=\"!\"):\n    # Return formatted greeting\n    pass\n\n# Test\nprint(greet(\"Alice\"))\nprint(greet(\"Bob\", greeting=\"Hi\", punctuation=\".\"))",
    "solution_code": "def greet(name, greeting=\"Hello\", punctuation=\"!\"):\n    return f\"{greeting}, {name}{punctuation}\"\n\n# Test\nprint(greet(\"Alice\"))\nprint(greet(\"Bob\", greeting=\"Hi\", punctuation=\".\"))",
    "expected_output": "Hello, Alice!\nHi, Bob.",
    "chapter_id": 4,
    "chapter_title": "Functions"
  },
  "168": {
    "id": 168,
    "title": "Stats Calculator",
    "content": "# ÔøΩÔøΩ Statistics Calculator\n\n## Multiple Return Values\n\n```python\ndef calc_stats(numbers):\n    return min(numbers), max(numbers), sum(numbers)/len(numbers)\n```\n\n---\n\n## üéØ Your Task\n\nCreate a function that returns min, max, and mean of a list.",
    "starter_code": "def calc_stats(numbers):\n    # Return min, max, mean\n    pass\n\n# Test\ndata = [10, 20, 30, 40, 50]\nmin_val, max_val, mean_val = calc_stats(data)\nprint(f\"Min: {min_val}, Max: {max_val}, Mean: {mean_val}\")",
    "solution_code": "def calc_stats(numbers):\n    return min(numbers), max(numbers), sum(numbers)/len(numbers)\n\n# Test\ndata = [10, 20, 30, 40, 50]\nmin_val, max_val, mean_val = calc_stats(data)\nprint(f\"Min: {min_val}, Max: {max_val}, Mean: {mean_val}\")",
    "expected_output": "Min: 10, Max: 50, Mean: 30.0",
    "chapter_id": 4,
    "chapter_title": "Functions"
  },
  "169": {
    "id": 169,
    "title": "Data Transformer",
    "content": "# üîÑ Lambda for Transformation\n\n## Lambda Functions\n\n```python\ndouble = lambda x: x * 2\nresult = double(5)  # 10\n```\n\n---\n\n## üéØ Your Task\n\nUse lambda with map() to convert temperatures from Celsius to Fahrenheit.",
    "starter_code": "celsius = [0, 10, 20, 30, 40]\n\n# Convert to Fahrenheit: F = C * 9/5 + 32\nfahrenheit = list(map(lambda c: None, celsius))  # Fix the lambda\n\nprint(fahrenheit)",
    "solution_code": "celsius = [0, 10, 20, 30, 40]\n\n# Convert to Fahrenheit: F = C * 9/5 + 32\nfahrenheit = list(map(lambda c: c * 9/5 + 32, celsius))\n\nprint(fahrenheit)",
    "expected_output": "[32.0, 50.0, 68.0, 86.0, 104.0]",
    "chapter_id": 4,
    "chapter_title": "Functions"
  },
  "170": {
    "id": 170,
    "title": "Recursive Factorial",
    "content": "# ÔøΩÔøΩ Recursive Functions\n\n## Recursion Pattern\n\n```python\ndef factorial(n):\n    if n <= 1:\n        return 1\n    return n * factorial(n - 1)\n```\n\n---\n\n## üéØ Your Task\n\nImplement a recursive factorial function.",
    "starter_code": "def factorial(n):\n    # Base case\n    if n <= 1:\n        return 1\n    # Recursive case\n    pass\n\n# Test\nprint(f\"5! = {factorial(5)}\")",
    "solution_code": "def factorial(n):\n    if n <= 1:\n        return 1\n    return n * factorial(n - 1)\n\n# Test\nprint(f\"5! = {factorial(5)}\")",
    "expected_output": "5! = 120",
    "chapter_id": 4,
    "chapter_title": "Functions"
  },
  "171": {
    "id": 171,
    "title": "Top N Items",
    "content": "# üèÜ Top N Items\n\n## Sorting and Slicing\n\n```python\nnumbers = [5, 2, 8, 1, 9]\ntop_3 = sorted(numbers, reverse=True)[:3]\n```\n\n---\n\n## üéØ Your Task\n\nGet the top 3 highest scores from the list.",
    "starter_code": "scores = [85, 92, 78, 96, 88, 74, 91]\n\n# Get top 3 scores\ntop_3 = None  # Your code\n\nprint(f\"Top 3: {top_3}\")",
    "solution_code": "scores = [85, 92, 78, 96, 88, 74, 91]\n\n# Get top 3 scores\ntop_3 = sorted(scores, reverse=True)[:3]\n\nprint(f\"Top 3: {top_3}\")",
    "expected_output": "Top 3: [96, 92, 91]",
    "chapter_id": 7,
    "chapter_title": "Data Structures"
  },
  "172": {
    "id": 172,
    "title": "List Deduplication",
    "content": "# üîÑ Remove Duplicates\n\n## Using Sets for Uniqueness\n\n```python\nitems = [1, 2, 2, 3, 3, 3]\nunique = list(set(items))\n```\n\n---\n\n## üéØ Your Task\n\nRemove duplicates while preserving order.",
    "starter_code": "items = [\"apple\", \"banana\", \"apple\", \"cherry\", \"banana\"]\n\n# Remove duplicates, keep order\nunique = []\nfor item in items:\n    pass\n\nprint(unique)",
    "solution_code": "items = [\"apple\", \"banana\", \"apple\", \"cherry\", \"banana\"]\n\n# Remove duplicates, keep order\nunique = []\nfor item in items:\n    if item not in unique:\n        unique.append(item)\n\nprint(unique)",
    "expected_output": "['apple', 'banana', 'cherry']",
    "chapter_id": 7,
    "chapter_title": "Data Structures"
  },
  "173": {
    "id": 173,
    "title": "Word Counter",
    "content": "# üìä Word Frequency Counter\n\n## Dictionary for Counting\n\n```python\nwords = [\"a\", \"b\", \"a\"]\ncounts = {}\nfor word in words:\n    counts[word] = counts.get(word, 0) + 1\n```\n\n---\n\n## üéØ Your Task\n\nCount word frequencies in the given text.",
    "starter_code": "text = \"the quick brown fox jumps over the lazy dog the fox\"\nwords = text.split()\n\n# Count each word\ncounts = {}\nfor word in words:\n    pass\n\nprint(counts)",
    "solution_code": "text = \"the quick brown fox jumps over the lazy dog the fox\"\nwords = text.split()\n\n# Count each word\ncounts = {}\nfor word in words:\n    counts[word] = counts.get(word, 0) + 1\n\nprint(counts)",
    "expected_output": "{'the': 3, 'quick': 1, 'brown': 1, 'fox': 2, 'jumps': 1, 'over': 1, 'lazy': 1, 'dog': 1}",
    "chapter_id": 7,
    "chapter_title": "Data Structures"
  },
  "174": {
    "id": 174,
    "title": "Merge Dictionaries",
    "content": "# üîó Merging Dictionaries\n\n## Combining Data\n\n```python\ndict1 = {\"a\": 1}\ndict2 = {\"b\": 2}\nmerged = {**dict1, **dict2}\n```\n\n---\n\n## üéØ Your Task\n\nMerge two dictionaries, with dict2 values taking precedence.",
    "starter_code": "defaults = {\"color\": \"blue\", \"size\": \"medium\", \"qty\": 1}\nuser_prefs = {\"color\": \"red\", \"qty\": 5}\n\n# Merge with user_prefs taking precedence\nfinal = None  # Your code\n\nprint(final)",
    "solution_code": "defaults = {\"color\": \"blue\", \"size\": \"medium\", \"qty\": 1}\nuser_prefs = {\"color\": \"red\", \"qty\": 5}\n\n# Merge with user_prefs taking precedence\nfinal = {**defaults, **user_prefs}\n\nprint(final)",
    "expected_output": "{'color': 'red', 'size': 'medium', 'qty': 5}",
    "chapter_id": 7,
    "chapter_title": "Data Structures"
  },
  "175": {
    "id": 175,
    "title": "Nested Lookup",
    "content": "# üîç Nested Dictionary Access\n\n## Safe Nested Access\n\n```python\ndata = {\"user\": {\"profile\": {\"name\": \"Alice\"}}}\nname = data.get(\"user\", {}).get(\"profile\", {}).get(\"name\")\n```\n\n---\n\n## üéØ Your Task\n\nSafely get the city from nested user data.",
    "starter_code": "user = {\n    \"name\": \"Bob\",\n    \"address\": {\n        \"city\": \"New York\",\n        \"zip\": \"10001\"\n    }\n}\n\n# Safe nested access\ncity = None  # Your code\n\nprint(f\"City: {city}\")",
    "solution_code": "user = {\n    \"name\": \"Bob\",\n    \"address\": {\n        \"city\": \"New York\",\n        \"zip\": \"10001\"\n    }\n}\n\n# Safe nested access\ncity = user.get(\"address\", {}).get(\"city\")\n\nprint(f\"City: {city}\")",
    "expected_output": "City: New York",
    "chapter_id": 7,
    "chapter_title": "Data Structures"
  },
  "176": {
    "id": 176,
    "title": "Unique Elements",
    "content": "# ÔøΩÔøΩ Finding Unique Elements\n\n## Set Operations\n\n```python\nlist1 = [1, 2, 3]\nlist2 = [2, 3, 4]\nonly_in_first = set(list1) - set(list2)\n```\n\n---\n\n## üéØ Your Task\n\nFind elements that are in list1 but not in list2.",
    "starter_code": "list1 = [1, 2, 3, 4, 5]\nlist2 = [4, 5, 6, 7, 8]\n\n# Find unique to list1\nunique = None  # Your code\n\nprint(f\"Only in list1: {sorted(unique)}\")",
    "solution_code": "list1 = [1, 2, 3, 4, 5]\nlist2 = [4, 5, 6, 7, 8]\n\n# Find unique to list1\nunique = set(list1) - set(list2)\n\nprint(f\"Only in list1: {sorted(unique)}\")",
    "expected_output": "Only in list1: [1, 2, 3]",
    "chapter_id": 7,
    "chapter_title": "Data Structures"
  },
  "177": {
    "id": 177,
    "title": "Line Counter",
    "content": "# üìÑ Line Counter\n\n## Counting Lines in Data\n\n```python\nlines = text.strip().split('\\n')\ncount = len([l for l in lines if l.strip()])\n```\n\n---\n\n## üéØ Your Task\n\nCount non-empty lines in the given text.",
    "starter_code": "text = '''Line 1\n\nLine 3\nLine 4\n\nLine 6'''\n\n# Count non-empty lines\ncount = 0\nfor line in text.split('\\n'):\n    pass\n\nprint(f\"Non-empty lines: {count}\")",
    "solution_code": "text = '''Line 1\n\nLine 3\nLine 4\n\nLine 6'''\n\n# Count non-empty lines\ncount = 0\nfor line in text.split('\\n'):\n    if line.strip():\n        count += 1\n\nprint(f\"Non-empty lines: {count}\")",
    "expected_output": "Non-empty lines: 4",
    "chapter_id": 8,
    "chapter_title": "File Handling"
  },
  "178": {
    "id": 178,
    "title": "Header Extractor",
    "content": "# üìã CSV Header Extraction\n\n## Getting Column Names\n\n```python\ncsv_data = \"name,age,city\\nAlice,30,NYC\"\nheaders = csv_data.split('\\n')[0].split(',')\n```\n\n---\n\n## üéØ Your Task\n\nExtract headers from the first line of CSV data.",
    "starter_code": "csv_data = '''product,price,quantity\nWidget,29.99,100\nGadget,49.99,50'''\n\n# Extract headers\nheaders = None  # Your code\n\nprint(f\"Headers: {headers}\")",
    "solution_code": "csv_data = '''product,price,quantity\nWidget,29.99,100\nGadget,49.99,50'''\n\n# Extract headers\nheaders = csv_data.split('\\n')[0].split(',')\n\nprint(f\"Headers: {headers}\")",
    "expected_output": "Headers: ['product', 'price', 'quantity']",
    "chapter_id": 8,
    "chapter_title": "File Handling"
  },
  "179": {
    "id": 179,
    "title": "JSON Navigator",
    "content": "# üß≠ JSON Navigation\n\n## Accessing Nested JSON\n\n```python\nimport json\ndata = json.loads(json_string)\nvalue = data['key']['nested_key']\n```\n\n---\n\n## üéØ Your Task\n\nExtract the user's email from nested JSON.",
    "starter_code": "import json\n\njson_str = '{\"user\": {\"name\": \"Alice\", \"contact\": {\"email\": \"alice@example.com\"}}}'\n\n# Parse and extract email\ndata = json.loads(json_str)\nemail = None  # Navigate to email\n\nprint(f\"Email: {email}\")",
    "solution_code": "import json\n\njson_str = '{\"user\": {\"name\": \"Alice\", \"contact\": {\"email\": \"alice@example.com\"}}}'\n\n# Parse and extract email\ndata = json.loads(json_str)\nemail = data['user']['contact']['email']\n\nprint(f\"Email: {email}\")",
    "expected_output": "Email: alice@example.com",
    "chapter_id": 8,
    "chapter_title": "File Handling"
  },
  "180": {
    "id": 180,
    "title": "Config Parser",
    "content": "# ‚öôÔ∏è Config File Parser\n\n## Parsing Key-Value Configs\n\n```python\nlines = config.split('\\n')\nfor line in lines:\n    key, value = line.split('=')\n```\n\n---\n\n## üéØ Your Task\n\nParse config into a dictionary.",
    "starter_code": "config = '''host=localhost\nport=5432\ndb=myapp'''\n\n# Parse into dictionary\nsettings = {}\nfor line in config.split('\\n'):\n    pass\n\nprint(settings)",
    "solution_code": "config = '''host=localhost\nport=5432\ndb=myapp'''\n\n# Parse into dictionary\nsettings = {}\nfor line in config.split('\\n'):\n    key, value = line.split('=')\n    settings[key] = value\n\nprint(settings)",
    "expected_output": "{'host': 'localhost', 'port': '5432', 'db': 'myapp'}",
    "chapter_id": 8,
    "chapter_title": "File Handling"
  },
  "181": {
    "id": 181,
    "title": "Pattern Finder",
    "content": "# üîç Pattern Finding\n\n## Finding All Occurrences\n\n```python\ntext = \"cat in the hat\"\npositions = [i for i, c in enumerate(text) if text[i:i+3] == \"cat\"]\n```\n\n---\n\n## üéØ Your Task\n\nFind all positions of 'the' in the text.",
    "starter_code": "text = \"the quick brown fox jumps over the lazy dog near the tree\"\npattern = \"the\"\n\n# Find all positions\npositions = []\nfor i in range(len(text) - len(pattern) + 1):\n    pass\n\nprint(f\"Found at positions: {positions}\")",
    "solution_code": "text = \"the quick brown fox jumps over the lazy dog near the tree\"\npattern = \"the\"\n\n# Find all positions\npositions = []\nfor i in range(len(text) - len(pattern) + 1):\n    if text[i:i+len(pattern)] == pattern:\n        positions.append(i)\n\nprint(f\"Found at positions: {positions}\")",
    "expected_output": "Found at positions: [0, 31, 49]",
    "chapter_id": 8,
    "chapter_title": "File Handling"
  },
  "182": {
    "id": 182,
    "title": "Batch Replace",
    "content": "# üîÑ Batch Text Replacement\n\n## Multiple Replacements\n\n```python\nfor old, new in replacements.items():\n    text = text.replace(old, new)\n```\n\n---\n\n## üéØ Your Task\n\nReplace multiple patterns in text.",
    "starter_code": "text = \"Hello World! Welcome to the World of Python!\"\n\nreplacements = {\n    \"World\": \"Universe\",\n    \"Hello\": \"Hi\",\n    \"Python\": \"Coding\"\n}\n\n# Apply all replacements\nfor old, new in replacements.items():\n    pass\n\nprint(text)",
    "solution_code": "text = \"Hello World! Welcome to the World of Python!\"\n\nreplacements = {\n    \"World\": \"Universe\",\n    \"Hello\": \"Hi\",\n    \"Python\": \"Coding\"\n}\n\n# Apply all replacements\nfor old, new in replacements.items():\n    text = text.replace(old, new)\n\nprint(text)",
    "expected_output": "Hi Universe! Welcome to the Universe of Coding!",
    "chapter_id": 8,
    "chapter_title": "File Handling"
  },
  "183": {
    "id": 183,
    "title": "Math Utilities",
    "content": "# üî¢ Math Module Utilities\n\n## Using the math Module\n\n```python\nimport math\nresult = math.sqrt(16)  # 4.0\nrounded = math.ceil(4.1)  # 5\n```\n\n---\n\n## üéØ Your Task\n\nCalculate the ceiling and floor of a number.",
    "starter_code": "import math\n\nvalue = 7.3\n\n# Calculate ceiling and floor\nceiling = None\nfloor = None\n\nprint(f\"Ceiling: {ceiling}, Floor: {floor}\")",
    "solution_code": "import math\n\nvalue = 7.3\n\n# Calculate ceiling and floor\nceiling = math.ceil(value)\nfloor = math.floor(value)\n\nprint(f\"Ceiling: {ceiling}, Floor: {floor}\")",
    "expected_output": "Ceiling: 8, Floor: 7",
    "chapter_id": 9,
    "chapter_title": "Modules & Packages"
  },
  "184": {
    "id": 184,
    "title": "Random Sampler",
    "content": "# üé≤ Random Sampling\n\n## Using random Module\n\n```python\nimport random\nrandom.seed(42)  # For reproducibility\nsample = random.sample(items, k=3)\n```\n\n---\n\n## üéØ Your Task\n\nRandomly select 3 items from the list.",
    "starter_code": "import random\nrandom.seed(42)\n\nitems = [\"apple\", \"banana\", \"cherry\", \"date\", \"elderberry\"]\n\n# Select 3 random items\nsample = None  # Your code\n\nprint(f\"Sample: {sample}\")",
    "solution_code": "import random\nrandom.seed(42)\n\nitems = [\"apple\", \"banana\", \"cherry\", \"date\", \"elderberry\"]\n\n# Select 3 random items\nsample = random.sample(items, k=3)\n\nprint(f\"Sample: {sample}\")",
    "expected_output": "Sample: ['banana', 'cherry', 'elderberry']",
    "chapter_id": 9,
    "chapter_title": "Modules & Packages"
  },
  "185": {
    "id": 185,
    "title": "Time Calculator",
    "content": "# ‚è∞ Date Calculations\n\n## Using datetime Module\n\n```python\nfrom datetime import datetime, timedelta\ntoday = datetime.now()\ntomorrow = today + timedelta(days=1)\n```\n\n---\n\n## ÔøΩÔøΩ Your Task\n\nCalculate the date 30 days from now.",
    "starter_code": "from datetime import datetime, timedelta\n\ntoday = datetime(2024, 1, 15)\n\n# Calculate 30 days from today\nfuture_date = None  # Your code\n\nprint(f\"30 days later: {future_date.strftime('%Y-%m-%d')}\")",
    "solution_code": "from datetime import datetime, timedelta\n\ntoday = datetime(2024, 1, 15)\n\n# Calculate 30 days from today\nfuture_date = today + timedelta(days=30)\n\nprint(f\"30 days later: {future_date.strftime('%Y-%m-%d')}\")",
    "expected_output": "30 days later: 2024-02-14",
    "chapter_id": 9,
    "chapter_title": "Modules & Packages"
  },
  "186": {
    "id": 186,
    "title": "Counter Analysis",
    "content": "# üìä Counter for Analysis\n\n## Using collections.Counter\n\n```python\nfrom collections import Counter\ncounts = Counter(items)\nmost_common = counts.most_common(3)\n```\n\n---\n\n## üéØ Your Task\n\nFind the 2 most common items.",
    "starter_code": "from collections import Counter\n\nitems = [\"a\", \"b\", \"a\", \"c\", \"a\", \"b\", \"d\", \"a\"]\n\n# Find 2 most common\ncounts = Counter(items)\nmost_common = None  # Your code\n\nprint(f\"Most common: {most_common}\")",
    "solution_code": "from collections import Counter\n\nitems = [\"a\", \"b\", \"a\", \"c\", \"a\", \"b\", \"d\", \"a\"]\n\n# Find 2 most common\ncounts = Counter(items)\nmost_common = counts.most_common(2)\n\nprint(f\"Most common: {most_common}\")",
    "expected_output": "Most common: [('a', 4), ('b', 2)]",
    "chapter_id": 9,
    "chapter_title": "Modules & Packages"
  },
  "187": {
    "id": 187,
    "title": "Path Operations",
    "content": "# üìÅ Path Operations\n\n## Using os.path\n\n```python\nimport os\nfilename = os.path.basename('/path/to/file.txt')\nextension = os.path.splitext(filename)[1]\n```\n\n---\n\n## üéØ Your Task\n\nExtract filename and extension from a path.",
    "starter_code": "import os\n\npath = \"/home/user/documents/report.pdf\"\n\n# Extract filename and extension\nfilename = None\nextension = None\n\nprint(f\"Filename: {filename}\")\nprint(f\"Extension: {extension}\")",
    "solution_code": "import os\n\npath = \"/home/user/documents/report.pdf\"\n\n# Extract filename and extension\nfilename = os.path.basename(path)\nextension = os.path.splitext(filename)[1]\n\nprint(f\"Filename: {filename}\")\nprint(f\"Extension: {extension}\")",
    "expected_output": "Filename: report.pdf\nExtension: .pdf",
    "chapter_id": 9,
    "chapter_title": "Modules & Packages"
  },
  "188": {
    "id": 188,
    "title": "Combinations Generator",
    "content": "# üî¢ Generating Combinations\n\n## Using itertools\n\n```python\nfrom itertools import combinations\ncombos = list(combinations(items, 2))\n```\n\n---\n\n## üéØ Your Task\n\nGenerate all pairs from the list.",
    "starter_code": "from itertools import combinations\n\nitems = [\"A\", \"B\", \"C\", \"D\"]\n\n# Generate all pairs\npairs = None  # Your code\n\nprint(f\"Pairs: {pairs}\")",
    "solution_code": "from itertools import combinations\n\nitems = [\"A\", \"B\", \"C\", \"D\"]\n\n# Generate all pairs\npairs = list(combinations(items, 2))\n\nprint(f\"Pairs: {pairs}\")",
    "expected_output": "Pairs: [('A', 'B'), ('A', 'C'), ('A', 'D'), ('B', 'C'), ('B', 'D'), ('C', 'D')]",
    "chapter_id": 9,
    "chapter_title": "Modules & Packages"
  },
  "189": {
    "id": 189,
    "title": "Custom Arrays",
    "content": "# üî¢ Custom NumPy Arrays\n\n## Creating Specific Arrays\n\n```python\nimport numpy as np\nzeros = np.zeros((3, 3))\nones = np.ones((2, 4))\nrange_arr = np.arange(0, 10, 2)\n```\n\n---\n\n## üéØ Your Task\n\nCreate an array of even numbers from 2 to 20.",
    "starter_code": "import numpy as np\n\n# Create array of even numbers 2-20\nevens = None  # Your code\n\nprint(evens)",
    "solution_code": "import numpy as np\n\n# Create array of even numbers 2-20\nevens = np.arange(2, 21, 2)\n\nprint(evens)",
    "expected_output": "[ 2  4  6  8 10 12 14 16 18 20]",
    "chapter_id": 95,
    "chapter_title": "NumPy Fundamentals"
  },
  "190": {
    "id": 190,
    "title": "Array Reshaping",
    "content": "# üîÑ Reshaping Arrays\n\n## Changing Array Dimensions\n\n```python\nimport numpy as np\narr = np.arange(12)\nreshaped = arr.reshape(3, 4)  # 3 rows, 4 columns\n```\n\n---\n\n## üéØ Your Task\n\nReshape a 1D array of 6 elements into 2 rows, 3 columns.",
    "starter_code": "import numpy as np\n\narr = np.array([1, 2, 3, 4, 5, 6])\n\n# Reshape to 2x3\nreshaped = None  # Your code\n\nprint(reshaped)",
    "solution_code": "import numpy as np\n\narr = np.array([1, 2, 3, 4, 5, 6])\n\n# Reshape to 2x3\nreshaped = arr.reshape(2, 3)\n\nprint(reshaped)",
    "expected_output": "[[1 2 3]\n [4 5 6]]",
    "chapter_id": 95,
    "chapter_title": "NumPy Fundamentals"
  },
  "191": {
    "id": 191,
    "title": "Element-wise Math",
    "content": "# ‚ûï Element-wise Operations\n\n## Array Math\n\n```python\nimport numpy as np\na = np.array([1, 2, 3])\nb = np.array([4, 5, 6])\nresult = a * b  # [4, 10, 18]\n```\n\n---\n\n## üéØ Your Task\n\nCalculate the element-wise product and sum.",
    "starter_code": "import numpy as np\n\na = np.array([2, 4, 6])\nb = np.array([1, 2, 3])\n\n# Element-wise product\nproduct = None\n\n# Element-wise sum\ntotal = None\n\nprint(f\"Product: {product}\")\nprint(f\"Sum: {total}\")",
    "solution_code": "import numpy as np\n\na = np.array([2, 4, 6])\nb = np.array([1, 2, 3])\n\n# Element-wise product\nproduct = a * b\n\n# Element-wise sum\ntotal = a + b\n\nprint(f\"Product: {product}\")\nprint(f\"Sum: {total}\")",
    "expected_output": "Product: [ 2  8 18]\nSum: [3 6 9]",
    "chapter_id": 95,
    "chapter_title": "NumPy Fundamentals"
  },
  "192": {
    "id": 192,
    "title": "Array Comparison",
    "content": "# ‚öñÔ∏è Array Comparison\n\n## Comparing Arrays\n\n```python\nimport numpy as np\na = np.array([1, 5, 3])\nb = np.array([2, 4, 3])\ngreater = a > b  # [False, True, False]\n```\n\n---\n\n## üéØ Your Task\n\nFind where array a is greater than array b.",
    "starter_code": "import numpy as np\n\na = np.array([10, 20, 30, 40])\nb = np.array([15, 15, 35, 35])\n\n# Where is a greater than b?\nmask = None  # Your code\n\nprint(f\"a > b: {mask}\")\nprint(f\"Values: {a[mask]}\")",
    "solution_code": "import numpy as np\n\na = np.array([10, 20, 30, 40])\nb = np.array([15, 15, 35, 35])\n\n# Where is a greater than b?\nmask = a > b\n\nprint(f\"a > b: {mask}\")\nprint(f\"Values: {a[mask]}\")",
    "expected_output": "a > b: [False  True False  True]\nValues: [20 40]",
    "chapter_id": 95,
    "chapter_title": "NumPy Fundamentals"
  },
  "193": {
    "id": 193,
    "title": "Filter Outliers",
    "content": "# üéØ Filtering Outliers\n\n## Boolean Masking\n\n```python\nimport numpy as np\ndata = np.array([1, 100, 3, 4, 5])\nmask = data < 50\nfiltered = data[mask]\n```\n\n---\n\n## üéØ Your Task\n\nRemove values outside the range [10, 90].",
    "starter_code": "import numpy as np\n\ndata = np.array([5, 25, 95, 50, 8, 75, 100, 30])\n\n# Keep only values between 10 and 90\nmask = None  # Your code\nfiltered = data[mask]\n\nprint(f\"Filtered: {filtered}\")",
    "solution_code": "import numpy as np\n\ndata = np.array([5, 25, 95, 50, 8, 75, 100, 30])\n\n# Keep only values between 10 and 90\nmask = (data >= 10) & (data <= 90)\nfiltered = data[mask]\n\nprint(f\"Filtered: {filtered}\")",
    "expected_output": "Filtered: [25 50 75 30]",
    "chapter_id": 95,
    "chapter_title": "NumPy Fundamentals"
  },
  "194": {
    "id": 194,
    "title": "Conditional Replace",
    "content": "# üîÑ Conditional Replacement\n\n## np.where for Replacement\n\n```python\nimport numpy as np\ndata = np.array([1, -2, 3, -4])\nresult = np.where(data < 0, 0, data)  # Replace negatives with 0\n```\n\n---\n\n## üéØ Your Task\n\nReplace all values below 50 with 'Fail' category (0), others with 'Pass' (1).",
    "starter_code": "import numpy as np\n\nscores = np.array([45, 72, 38, 91, 55, 48])\n\n# 0 for fail (<50), 1 for pass\npass_fail = None  # Use np.where\n\nprint(f\"Pass/Fail: {pass_fail}\")",
    "solution_code": "import numpy as np\n\nscores = np.array([45, 72, 38, 91, 55, 48])\n\n# 0 for fail (<50), 1 for pass\npass_fail = np.where(scores >= 50, 1, 0)\n\nprint(f\"Pass/Fail: {pass_fail}\")",
    "expected_output": "Pass/Fail: [0 1 0 1 1 0]",
    "chapter_id": 95,
    "chapter_title": "NumPy Fundamentals"
  },
  "195": {
    "id": 195,
    "title": "Matrix Operations",
    "content": "# üî¢ Matrix Operations\n\n## 2D Array Broadcasting\n\n```python\nimport numpy as np\nmatrix = np.array([[1, 2], [3, 4]])\nresult = matrix * 2\n```\n\n---\n\n## üéØ Your Task\n\nAdd a vector to each row of a matrix.",
    "starter_code": "import numpy as np\n\nmatrix = np.array([[1, 2, 3], [4, 5, 6]])\nvector = np.array([10, 20, 30])\n\n# Add vector to each row\nresult = None\n\nprint(result)",
    "solution_code": "import numpy as np\n\nmatrix = np.array([[1, 2, 3], [4, 5, 6]])\nvector = np.array([10, 20, 30])\n\n# Add vector to each row\nresult = matrix + vector\n\nprint(result)",
    "expected_output": "[[11 22 33]\n [14 25 36]]",
    "chapter_id": 95,
    "chapter_title": "NumPy Fundamentals"
  },
  "196": {
    "id": 196,
    "title": "Feature Scaling",
    "content": "# üìè Feature Scaling\n\n## Min-Max Normalization\n\n```python\nnormalized = (x - x.min()) / (x.max() - x.min())\n```\n\n---\n\n## üéØ Your Task\n\nScale values to 0-1 range.",
    "starter_code": "import numpy as np\n\ndata = np.array([10, 20, 30, 40, 50])\n\n# Normalize to 0-1\nnormalized = None\n\nprint(normalized)",
    "solution_code": "import numpy as np\n\ndata = np.array([10, 20, 30, 40, 50])\n\n# Normalize to 0-1\nnormalized = (data - data.min()) / (data.max() - data.min())\n\nprint(normalized)",
    "expected_output": "[0.   0.25 0.5  0.75 1.  ]",
    "chapter_id": 95,
    "chapter_title": "NumPy Fundamentals"
  },
  "197": {
    "id": 197,
    "title": "Distribution Analysis",
    "content": "# üìä Distribution Analysis\n\n## Understanding Data Distribution\n\n```python\nimport numpy as np\nmean = np.mean(data)\nstd = np.std(data)\nmedian = np.median(data)\n```\n\n---\n\n## üéØ Your Task\n\nAnalyze the distribution of scores.",
    "starter_code": "import numpy as np\n\nscores = np.array([65, 70, 75, 80, 85, 90, 95, 100])\n\n# Calculate statistics\nmean = None\nstd = None\nmedian = None\n\nprint(f\"Mean: {mean}, Std: {std:.2f}, Median: {median}\")",
    "solution_code": "import numpy as np\n\nscores = np.array([65, 70, 75, 80, 85, 90, 95, 100])\n\n# Calculate statistics\nmean = np.mean(scores)\nstd = np.std(scores)\nmedian = np.median(scores)\n\nprint(f\"Mean: {mean}, Std: {std:.2f}, Median: {median}\")",
    "expected_output": "Mean: 82.5, Std: 11.18, Median: 82.5",
    "chapter_id": 95,
    "chapter_title": "NumPy Fundamentals"
  },
  "198": {
    "id": 198,
    "title": "Correlation Check",
    "content": "# üìà Correlation Analysis\n\n## Checking Variable Relationships\n\n```python\nimport numpy as np\ncorr = np.corrcoef(x, y)[0, 1]\n```\n\n---\n\n## üéØ Your Task\n\nCalculate correlation between hours studied and scores.",
    "starter_code": "import numpy as np\n\nhours = np.array([1, 2, 3, 4, 5])\nscores = np.array([50, 55, 65, 70, 80])\n\n# Calculate correlation\ncorr = None\n\nprint(f\"Correlation: {corr:.4f}\")",
    "solution_code": "import numpy as np\n\nhours = np.array([1, 2, 3, 4, 5])\nscores = np.array([50, 55, 65, 70, 80])\n\n# Calculate correlation\ncorr = np.corrcoef(hours, scores)[0, 1]\n\nprint(f\"Correlation: {corr:.4f}\")",
    "expected_output": "Correlation: 0.9811",
    "chapter_id": 95,
    "chapter_title": "NumPy Fundamentals"
  },
  "199": {
    "id": 199,
    "title": "Column Selection",
    "content": "# üìä Selecting Multiple Columns\n\n## DataFrame Column Selection\n\n```python\ndf[['name', 'age']]  # Select multiple columns\ndf.loc[:, 'name':'age']  # Select range\n```\n\n---\n\n## üéØ Your Task\n\nSelect name and salary columns.",
    "starter_code": "import pandas as pd\n\ndf = pd.DataFrame({\n    'name': ['Alice', 'Bob'],\n    'age': [25, 30],\n    'salary': [50000, 60000],\n    'dept': ['HR', 'IT']\n})\n\n# Select name and salary\nresult = None\n\nprint(result)",
    "solution_code": "import pandas as pd\n\ndf = pd.DataFrame({\n    'name': ['Alice', 'Bob'],\n    'age': [25, 30],\n    'salary': [50000, 60000],\n    'dept': ['HR', 'IT']\n})\n\n# Select name and salary\nresult = df[['name', 'salary']]\n\nprint(result)",
    "expected_output": "    name  salary\n0  Alice   50000\n1    Bob   60000",
    "chapter_id": 10,
    "chapter_title": "Pandas & Data Wrangling"
  },
  "200": {
    "id": 200,
    "title": "Complex Filtering",
    "content": "# üîç Complex DataFrame Filtering\n\n## Multi-Condition Filters\n\n```python\ndf[(df['age'] > 25) & (df['salary'] > 50000)]\n```\n\n---\n\n## üéØ Your Task\n\nFilter employees: age > 25 AND salary > 55000.",
    "starter_code": "import pandas as pd\n\ndf = pd.DataFrame({\n    'name': ['Alice', 'Bob', 'Charlie'],\n    'age': [22, 28, 35],\n    'salary': [50000, 60000, 75000]\n})\n\n# Filter: age > 25 AND salary > 55000\nfiltered = None\n\nprint(filtered)",
    "solution_code": "import pandas as pd\n\ndf = pd.DataFrame({\n    'name': ['Alice', 'Bob', 'Charlie'],\n    'age': [22, 28, 35],\n    'salary': [50000, 60000, 75000]\n})\n\n# Filter: age > 25 AND salary > 55000\nfiltered = df[(df['age'] > 25) & (df['salary'] > 55000)]\n\nprint(filtered)",
    "expected_output": "      name  age  salary\n1      Bob   28   60000\n2  Charlie   35   75000",
    "chapter_id": 10,
    "chapter_title": "Pandas & Data Wrangling"
  },
  "201": {
    "id": 201,
    "title": "Pivot Analysis",
    "content": "# üìä Pivot Tables\n\n## Creating Pivot Tables\n\n```python\npd.pivot_table(df, values='sales', index='region', aggfunc='sum')\n```\n\n---\n\n## üéØ Your Task\n\nCreate a pivot table showing total sales by category.",
    "starter_code": "import pandas as pd\n\ndf = pd.DataFrame({\n    'category': ['A', 'A', 'B', 'B'],\n    'product': ['X', 'Y', 'X', 'Y'],\n    'sales': [100, 150, 200, 250]\n})\n\n# Pivot: total sales by category\npivot = None\n\nprint(pivot)",
    "solution_code": "import pandas as pd\n\ndf = pd.DataFrame({\n    'category': ['A', 'A', 'B', 'B'],\n    'product': ['X', 'Y', 'X', 'Y'],\n    'sales': [100, 150, 200, 250]\n})\n\n# Pivot: total sales by category\npivot = pd.pivot_table(df, values='sales', index='category', aggfunc='sum')\n\nprint(pivot)",
    "expected_output": "          sales\ncategory       \nA           250\nB           450",
    "chapter_id": 10,
    "chapter_title": "Pandas & Data Wrangling"
  },
  "202": {
    "id": 202,
    "title": "Rolling Calculations",
    "content": "# üìà Rolling Calculations\n\n## Moving Averages\n\n```python\ndf['rolling_avg'] = df['value'].rolling(window=3).mean()\n```\n\n---\n\n## üéØ Your Task\n\nCalculate 3-day moving average of prices.",
    "starter_code": "import pandas as pd\n\ndf = pd.DataFrame({\n    'day': [1, 2, 3, 4, 5],\n    'price': [100, 105, 102, 110, 108]\n})\n\n# Calculate 3-day moving average\ndf['ma_3'] = None\n\nprint(df)",
    "solution_code": "import pandas as pd\n\ndf = pd.DataFrame({\n    'day': [1, 2, 3, 4, 5],\n    'price': [100, 105, 102, 110, 108]\n})\n\n# Calculate 3-day moving average\ndf['ma_3'] = df['price'].rolling(window=3).mean()\n\nprint(df)",
    "expected_output": "   day  price        ma_3\n0    1    100         NaN\n1    2    105         NaN\n2    3    102  102.333333\n3    4    110  105.666667\n4    5    108  106.666667",
    "chapter_id": 10,
    "chapter_title": "Pandas & Data Wrangling"
  },
  "203": {
    "id": 203,
    "title": "Data Merging",
    "content": "# üîó Merging DataFrames\n\n## Join Operations\n\n```python\npd.merge(df1, df2, on='id', how='left')\n```\n\n---\n\n## üéØ Your Task\n\nMerge orders with customers on customer_id.",
    "starter_code": "import pandas as pd\n\norders = pd.DataFrame({\n    'order_id': [1, 2, 3],\n    'customer_id': [101, 102, 101],\n    'amount': [50, 75, 100]\n})\n\ncustomers = pd.DataFrame({\n    'customer_id': [101, 102],\n    'name': ['Alice', 'Bob']\n})\n\n# Merge on customer_id\nresult = None\n\nprint(result)",
    "solution_code": "import pandas as pd\n\norders = pd.DataFrame({\n    'order_id': [1, 2, 3],\n    'customer_id': [101, 102, 101],\n    'amount': [50, 75, 100]\n})\n\ncustomers = pd.DataFrame({\n    'customer_id': [101, 102],\n    'name': ['Alice', 'Bob']\n})\n\n# Merge on customer_id\nresult = pd.merge(orders, customers, on='customer_id')\n\nprint(result)",
    "expected_output": "   order_id  customer_id  amount   name\n0         1          101      50  Alice\n1         3          101     100  Alice\n2         2          102      75    Bob",
    "chapter_id": 10,
    "chapter_title": "Pandas & Data Wrangling"
  },
  "204": {
    "id": 204,
    "title": "Data Reshaping",
    "content": "# üîÑ Reshaping Data\n\n## Melt and Pivot\n\n```python\npd.melt(df, id_vars=['id'], value_vars=['col1', 'col2'])\n```\n\n---\n\n## üéØ Your Task\n\nReshape wide data to long format.",
    "starter_code": "import pandas as pd\n\ndf = pd.DataFrame({\n    'date': ['2024-01', '2024-02'],\n    'sales': [100, 120],\n    'costs': [80, 90]\n})\n\n# Reshape to long format\nlong_df = pd.melt(df, id_vars=['date'])\n\nprint(long_df)",
    "solution_code": "import pandas as pd\n\ndf = pd.DataFrame({\n    'date': ['2024-01', '2024-02'],\n    'sales': [100, 120],\n    'costs': [80, 90]\n})\n\n# Reshape to long format\nlong_df = pd.melt(df, id_vars=['date'])\n\nprint(long_df)",
    "expected_output": "      date variable  value\n0  2024-01    sales    100\n1  2024-02    sales    120\n2  2024-01    costs     80\n3  2024-02    costs     90",
    "chapter_id": 10,
    "chapter_title": "Pandas & Data Wrangling"
  },
  "205": {
    "id": 205,
    "title": "Multiple Series",
    "content": "# üìà Multiple Data Series\n\n## Plotting Multiple Lines\n\n```python\nimport matplotlib.pyplot as plt\nplt.plot(x, y1, label='Series 1')\nplt.plot(x, y2, label='Series 2')\nplt.legend()\n```\n\n---\n\n## üéØ Your Task\n\nPlot revenue and costs on the same chart.",
    "starter_code": "import matplotlib.pyplot as plt\n\nmonths = [1, 2, 3, 4, 5]\nrevenue = [100, 120, 115, 140, 160]\ncosts = [80, 85, 90, 95, 100]\n\n# Plot both series\nplt.plot(months, revenue, label='Revenue')\n# Add costs line\n\nplt.legend()\nplt.title('Revenue vs Costs')\nprint('Chart created')",
    "solution_code": "import matplotlib.pyplot as plt\n\nmonths = [1, 2, 3, 4, 5]\nrevenue = [100, 120, 115, 140, 160]\ncosts = [80, 85, 90, 95, 100]\n\n# Plot both series\nplt.plot(months, revenue, label='Revenue')\nplt.plot(months, costs, label='Costs')\n\nplt.legend()\nplt.title('Revenue vs Costs')\nprint('Chart created')",
    "expected_output": "Chart created",
    "chapter_id": 11,
    "chapter_title": "Data Visualization"
  },
  "206": {
    "id": 206,
    "title": "Annotated Charts",
    "content": "# üìù Chart Annotations\n\n## Adding Labels and Annotations\n\n```python\nplt.annotate('Peak', xy=(x, y), xytext=(x+1, y+10))\n```\n\n---\n\n## üéØ Your Task\n\nAnnotate the maximum value on the chart.",
    "starter_code": "import matplotlib.pyplot as plt\n\nx = [1, 2, 3, 4, 5]\ny = [10, 25, 15, 30, 20]\n\nplt.plot(x, y)\n\n# Find and annotate max\nmax_idx = y.index(max(y))\n# Add annotation here\n\nplt.title('Sales with Peak Annotation')\nprint('Chart created with annotation')",
    "solution_code": "import matplotlib.pyplot as plt\n\nx = [1, 2, 3, 4, 5]\ny = [10, 25, 15, 30, 20]\n\nplt.plot(x, y)\n\n# Find and annotate max\nmax_idx = y.index(max(y))\nplt.annotate(f'Peak: {max(y)}', xy=(x[max_idx], y[max_idx]))\n\nplt.title('Sales with Peak Annotation')\nprint('Chart created with annotation')",
    "expected_output": "Chart created with annotation",
    "chapter_id": 11,
    "chapter_title": "Data Visualization"
  },
  "207": {
    "id": 207,
    "title": "Density Plot",
    "content": "# üìä Density Visualization\n\n## Creating Histograms\n\n```python\nimport matplotlib.pyplot as plt\nplt.hist(data, bins=10, density=True)\n```\n\n---\n\n## üéØ Your Task\n\nCreate a histogram of the data.",
    "starter_code": "import matplotlib.pyplot as plt\nimport numpy as np\n\ndata = np.random.normal(100, 15, 200)\n\n# Create histogram\nplt.hist(data, bins=15)\nplt.title('Distribution')\nprint('Histogram created')",
    "solution_code": "import matplotlib.pyplot as plt\nimport numpy as np\n\ndata = np.random.normal(100, 15, 200)\n\n# Create histogram\nplt.hist(data, bins=15)\nplt.title('Distribution')\nprint('Histogram created')",
    "expected_output": "Histogram created",
    "chapter_id": 11,
    "chapter_title": "Data Visualization"
  },
  "208": {
    "id": 208,
    "title": "Box Plot",
    "content": "# üì¶ Box Plots\n\n## Visualizing Distributions\n\n```python\nimport matplotlib.pyplot as plt\nplt.boxplot(data)\n```\n\n---\n\n## üéØ Your Task\n\nCreate a box plot for scores.",
    "starter_code": "import matplotlib.pyplot as plt\n\nscores = [65, 70, 75, 80, 85, 90, 95, 60, 55, 100]\n\n# Create box plot\nplt.boxplot(scores)\nplt.title('Score Distribution')\nprint('Box plot created')",
    "solution_code": "import matplotlib.pyplot as plt\n\nscores = [65, 70, 75, 80, 85, 90, 95, 60, 55, 100]\n\n# Create box plot\nplt.boxplot(scores)\nplt.title('Score Distribution')\nprint('Box plot created')",
    "expected_output": "Box plot created",
    "chapter_id": 11,
    "chapter_title": "Data Visualization"
  },
  "209": {
    "id": 209,
    "title": "Grouped Bars",
    "content": "# üìä Grouped Bar Charts\n\n## Comparing Categories\n\n```python\nimport matplotlib.pyplot as plt\nimport numpy as np\nx = np.arange(len(labels))\nwidth = 0.35\nplt.bar(x - width/2, vals1, width, label='A')\nplt.bar(x + width/2, vals2, width, label='B')\n```\n\n---\n\n## üéØ Your Task\n\nCreate grouped bars for Q1 and Q2 sales.",
    "starter_code": "import matplotlib.pyplot as plt\nimport numpy as np\n\nproducts = ['A', 'B', 'C']\nq1 = [100, 150, 200]\nq2 = [120, 140, 180]\n\nx = np.arange(len(products))\nwidth = 0.35\n\nplt.bar(x - width/2, q1, width, label='Q1')\nplt.bar(x + width/2, q2, width, label='Q2')\nplt.xticks(x, products)\nplt.legend()\nprint('Grouped bar chart created')",
    "solution_code": "import matplotlib.pyplot as plt\nimport numpy as np\n\nproducts = ['A', 'B', 'C']\nq1 = [100, 150, 200]\nq2 = [120, 140, 180]\n\nx = np.arange(len(products))\nwidth = 0.35\n\nplt.bar(x - width/2, q1, width, label='Q1')\nplt.bar(x + width/2, q2, width, label='Q2')\nplt.xticks(x, products)\nplt.legend()\nprint('Grouped bar chart created')",
    "expected_output": "Grouped bar chart created",
    "chapter_id": 11,
    "chapter_title": "Data Visualization"
  },
  "210": {
    "id": 210,
    "title": "Dashboard Layout",
    "content": "# üìä Multi-Chart Layout\n\n## Creating Subplots\n\n```python\nfig, axes = plt.subplots(2, 2, figsize=(10, 8))\naxes[0, 0].plot(x, y)\n```\n\n---\n\n## üéØ Your Task\n\nCreate a 2x2 dashboard layout.",
    "starter_code": "import matplotlib.pyplot as plt\nimport numpy as np\n\nfig, axes = plt.subplots(2, 2, figsize=(10, 8))\n\nx = np.arange(10)\ny = np.random.rand(10)\n\naxes[0, 0].plot(x, y)\naxes[0, 0].set_title('Line Plot')\n\naxes[0, 1].bar(x, y)\naxes[0, 1].set_title('Bar Chart')\n\naxes[1, 0].scatter(x, y)\naxes[1, 0].set_title('Scatter Plot')\n\naxes[1, 1].hist(y)\naxes[1, 1].set_title('Histogram')\n\nplt.tight_layout()\nprint('Dashboard created')",
    "solution_code": "import matplotlib.pyplot as plt\nimport numpy as np\n\nfig, axes = plt.subplots(2, 2, figsize=(10, 8))\n\nx = np.arange(10)\ny = np.random.rand(10)\n\naxes[0, 0].plot(x, y)\naxes[0, 0].set_title('Line Plot')\n\naxes[0, 1].bar(x, y)\naxes[0, 1].set_title('Bar Chart')\n\naxes[1, 0].scatter(x, y)\naxes[1, 0].set_title('Scatter Plot')\n\naxes[1, 1].hist(y)\naxes[1, 1].set_title('Histogram')\n\nplt.tight_layout()\nprint('Dashboard created')",
    "expected_output": "Dashboard created",
    "chapter_id": 11,
    "chapter_title": "Data Visualization"
  },
  "211": {
    "id": 211,
    "title": "Search Variants",
    "content": "# üîç Search Variations\n\n## Finding First/Last Occurrence\n\n```python\ndef find_first(arr, target):\n    for i, val in enumerate(arr):\n        if val == target:\n            return i\n    return -1\n```\n\n---\n\n## üéØ Your Task\n\nFind the last occurrence of the target.",
    "starter_code": "def find_last(arr, target):\n    # Find last occurrence\n    pass\n\narr = [1, 2, 3, 2, 4, 2, 5]\nresult = find_last(arr, 2)\nprint(f\"Last occurrence at index: {result}\")",
    "solution_code": "def find_last(arr, target):\n    last_idx = -1\n    for i, val in enumerate(arr):\n        if val == target:\n            last_idx = i\n    return last_idx\n\narr = [1, 2, 3, 2, 4, 2, 5]\nresult = find_last(arr, 2)\nprint(f\"Last occurrence at index: {result}\")",
    "expected_output": "Last occurrence at index: 5",
    "chapter_id": 12,
    "chapter_title": "Algorithms"
  },
  "212": {
    "id": 212,
    "title": "Rotated Search",
    "content": "# üîç Search in Rotated Array\n\n## Modified Binary Search\n\n---\n\n## üéØ Your Task\n\nFind target in a rotated sorted array.",
    "starter_code": "def search_rotated(arr, target):\n    left, right = 0, len(arr) - 1\n    \n    while left <= right:\n        mid = (left + right) // 2\n        if arr[mid] == target:\n            return mid\n        # Determine which half is sorted\n        pass\n    return -1\n\narr = [4, 5, 6, 7, 0, 1, 2]\nprint(f\"Found at: {search_rotated(arr, 0)}\")",
    "solution_code": "def search_rotated(arr, target):\n    left, right = 0, len(arr) - 1\n    \n    while left <= right:\n        mid = (left + right) // 2\n        if arr[mid] == target:\n            return mid\n        if arr[left] <= arr[mid]:\n            if arr[left] <= target < arr[mid]:\n                right = mid - 1\n            else:\n                left = mid + 1\n        else:\n            if arr[mid] < target <= arr[right]:\n                left = mid + 1\n            else:\n                right = mid - 1\n    return -1\n\narr = [4, 5, 6, 7, 0, 1, 2]\nprint(f\"Found at: {search_rotated(arr, 0)}\")",
    "expected_output": "Found at: 4",
    "chapter_id": 12,
    "chapter_title": "Algorithms"
  },
  "213": {
    "id": 213,
    "title": "2D Search",
    "content": "# üîç Search in 2D Grid\n\n## Matrix Search\n\n---\n\n## üéØ Your Task\n\nFind target in a sorted 2D matrix.",
    "starter_code": "def search_matrix(matrix, target):\n    if not matrix:\n        return False\n    \n    rows, cols = len(matrix), len(matrix[0])\n    row, col = 0, cols - 1\n    \n    while row < rows and col >= 0:\n        # Start from top-right\n        pass\n    return False\n\nmatrix = [[1, 4, 7], [2, 5, 8], [3, 6, 9]]\nprint(f\"Found: {search_matrix(matrix, 5)}\")",
    "solution_code": "def search_matrix(matrix, target):\n    if not matrix:\n        return False\n    \n    rows, cols = len(matrix), len(matrix[0])\n    row, col = 0, cols - 1\n    \n    while row < rows and col >= 0:\n        if matrix[row][col] == target:\n            return True\n        elif matrix[row][col] > target:\n            col -= 1\n        else:\n            row += 1\n    return False\n\nmatrix = [[1, 4, 7], [2, 5, 8], [3, 6, 9]]\nprint(f\"Found: {search_matrix(matrix, 5)}\")",
    "expected_output": "Found: True",
    "chapter_id": 12,
    "chapter_title": "Algorithms"
  },
  "214": {
    "id": 214,
    "title": "Selection Sort",
    "content": "# üìä Selection Sort\n\n## Algorithm\n\nFind minimum, swap to front, repeat.\n\n```python\nfor i in range(len(arr)):\n    min_idx = i\n    for j in range(i+1, len(arr)):\n        if arr[j] < arr[min_idx]:\n            min_idx = j\n    arr[i], arr[min_idx] = arr[min_idx], arr[i]\n```\n\n---\n\n## üéØ Your Task\n\nImplement selection sort.",
    "starter_code": "def selection_sort(arr):\n    # Implement selection sort\n    pass\n\narr = [64, 25, 12, 22, 11]\nselection_sort(arr)\nprint(arr)",
    "solution_code": "def selection_sort(arr):\n    for i in range(len(arr)):\n        min_idx = i\n        for j in range(i+1, len(arr)):\n            if arr[j] < arr[min_idx]:\n                min_idx = j\n        arr[i], arr[min_idx] = arr[min_idx], arr[i]\n\narr = [64, 25, 12, 22, 11]\nselection_sort(arr)\nprint(arr)",
    "expected_output": "[11, 12, 22, 25, 64]",
    "chapter_id": 12,
    "chapter_title": "Algorithms"
  },
  "215": {
    "id": 215,
    "title": "Insertion Sort",
    "content": "# üìä Insertion Sort\n\n## Algorithm\n\nBuild sorted array one element at a time.\n\n---\n\n## üéØ Your Task\n\nImplement insertion sort.",
    "starter_code": "def insertion_sort(arr):\n    for i in range(1, len(arr)):\n        key = arr[i]\n        j = i - 1\n        # Move elements greater than key\n        pass\n\narr = [12, 11, 13, 5, 6]\ninsertion_sort(arr)\nprint(arr)",
    "solution_code": "def insertion_sort(arr):\n    for i in range(1, len(arr)):\n        key = arr[i]\n        j = i - 1\n        while j >= 0 and arr[j] > key:\n            arr[j + 1] = arr[j]\n            j -= 1\n        arr[j + 1] = key\n\narr = [12, 11, 13, 5, 6]\ninsertion_sort(arr)\nprint(arr)",
    "expected_output": "[5, 6, 11, 12, 13]",
    "chapter_id": 12,
    "chapter_title": "Algorithms"
  },
  "216": {
    "id": 216,
    "title": "Merge Sort",
    "content": "# üìä Merge Sort\n\n## Divide and Conquer\n\n---\n\n## üéØ Your Task\n\nImplement merge sort.",
    "starter_code": "def merge_sort(arr):\n    if len(arr) <= 1:\n        return arr\n    \n    mid = len(arr) // 2\n    left = merge_sort(arr[:mid])\n    right = merge_sort(arr[mid:])\n    \n    return merge(left, right)\n\ndef merge(left, right):\n    result = []\n    i = j = 0\n    # Merge two sorted arrays\n    return result\n\narr = [38, 27, 43, 3, 9, 82, 10]\nprint(merge_sort(arr))",
    "solution_code": "def merge_sort(arr):\n    if len(arr) <= 1:\n        return arr\n    \n    mid = len(arr) // 2\n    left = merge_sort(arr[:mid])\n    right = merge_sort(arr[mid:])\n    \n    return merge(left, right)\n\ndef merge(left, right):\n    result = []\n    i = j = 0\n    while i < len(left) and j < len(right):\n        if left[i] <= right[j]:\n            result.append(left[i])\n            i += 1\n        else:\n            result.append(right[j])\n            j += 1\n    result.extend(left[i:])\n    result.extend(right[j:])\n    return result\n\narr = [38, 27, 43, 3, 9, 82, 10]\nprint(merge_sort(arr))",
    "expected_output": "[3, 9, 10, 27, 38, 43, 82]",
    "chapter_id": 12,
    "chapter_title": "Algorithms"
  },
  "217": {
    "id": 217,
    "title": "Quick Sort",
    "content": "# ‚ö° Quick Sort\n\n## Partition-based Sorting\n\n---\n\n## üéØ Your Task\n\nImplement quick sort.",
    "starter_code": "def quick_sort(arr):\n    if len(arr) <= 1:\n        return arr\n    \n    pivot = arr[len(arr) // 2]\n    left = [x for x in arr if x < pivot]\n    middle = [x for x in arr if x == pivot]\n    right = [x for x in arr if x > pivot]\n    \n    return quick_sort(left) + middle + quick_sort(right)\n\narr = [64, 34, 25, 12, 22, 11, 90]\nprint(quick_sort(arr))",
    "solution_code": "def quick_sort(arr):\n    if len(arr) <= 1:\n        return arr\n    \n    pivot = arr[len(arr) // 2]\n    left = [x for x in arr if x < pivot]\n    middle = [x for x in arr if x == pivot]\n    right = [x for x in arr if x > pivot]\n    \n    return quick_sort(left) + middle + quick_sort(right)\n\narr = [64, 34, 25, 12, 22, 11, 90]\nprint(quick_sort(arr))",
    "expected_output": "[11, 12, 22, 25, 34, 64, 90]",
    "chapter_id": 12,
    "chapter_title": "Algorithms"
  },
  "1162": {
    "id": 1162,
    "title": "Table Structure Quiz",
    "content": "# üóÑÔ∏è Table Structure\n\n## Understanding Tables\n\nTables have columns (fields) and rows (records):\n\n```sql\nSELECT column_name\nFROM information_schema.columns\nWHERE table_name = 'users';\n```\n\n---\n\n## üéØ Your Task\n\nSelect all column names from the employees table.",
    "starter_code": "-- Get all column names from employees table\nSELECT column_name\nFROM information_schema.columns\nWHERE table_name = 'employees';",
    "solution_code": "SELECT column_name\nFROM information_schema.columns\nWHERE table_name = 'employees';",
    "expected_output": "id\nname\ndepartment\nsalary",
    "chapter_id": 200,
    "chapter_title": "Setup & Mental Model"
  },
  "1163": {
    "id": 1163,
    "title": "Data Relationships",
    "content": "# üîó Data Relationships\n\n## Understanding Table Connections\n\n---\n\n## üéØ Your Task\n\nIdentify the relationship between orders and customers.",
    "starter_code": "-- Describe the relationship\n-- One customer can have many orders\nSELECT c.name, COUNT(o.order_id) as order_count\nFROM customers c\nLEFT JOIN orders o ON c.id = o.customer_id\nGROUP BY c.name;",
    "solution_code": "SELECT c.name, COUNT(o.order_id) as order_count\nFROM customers c\nLEFT JOIN orders o ON c.id = o.customer_id\nGROUP BY c.name;",
    "expected_output": "Alice|5\nBob|3\nCharlie|0",
    "chapter_id": 200,
    "chapter_title": "Setup & Mental Model"
  },
  "1164": {
    "id": 1164,
    "title": "FK Navigation",
    "content": "# ÔøΩÔøΩ Foreign Key Navigation\n\n## Following Relationships\n\n---\n\n## üéØ Your Task\n\nNavigate from orders to products using foreign keys.",
    "starter_code": "-- Navigate FK relationships\nSELECT o.order_id, p.product_name, p.price\nFROM orders o\nJOIN products p ON o.product_id = p.id;",
    "solution_code": "SELECT o.order_id, p.product_name, p.price\nFROM orders o\nJOIN products p ON o.product_id = p.id;",
    "expected_output": "1|Widget|29.99\n2|Gadget|49.99",
    "chapter_id": 200,
    "chapter_title": "Setup & Mental Model"
  },
  "1165": {
    "id": 1165,
    "title": "Cardinality Check",
    "content": "# üìä Cardinality Analysis\n\n## Relationship Types\n\n- One-to-One\n- One-to-Many\n- Many-to-Many\n\n---\n\n## üéØ Your Task\n\nVerify the cardinality by counting related records.",
    "starter_code": "-- Check cardinality\nSELECT parent_id, COUNT(*) as child_count\nFROM child_table\nGROUP BY parent_id;",
    "solution_code": "SELECT parent_id, COUNT(*) as child_count\nFROM child_table\nGROUP BY parent_id;",
    "expected_output": "1|3\n2|5\n3|1",
    "chapter_id": 200,
    "chapter_title": "Setup & Mental Model"
  },
  "1166": {
    "id": 1166,
    "title": "NULL Logic Puzzle",
    "content": "# ‚ùì NULL Logic\n\n## Three-Valued Logic\n\n```sql\nNULL = NULL  -- Unknown (not TRUE)\nNULL IS NULL -- TRUE\n```\n\n---\n\n## üéØ Your Task\n\nFind records where department IS NULL.",
    "starter_code": "-- Find NULL departments\nSELECT name, department\nFROM employees\nWHERE department IS NULL;",
    "solution_code": "SELECT name, department\nFROM employees\nWHERE department IS NULL;",
    "expected_output": "New Hire|NULL",
    "chapter_id": 200,
    "chapter_title": "Setup & Mental Model"
  },
  "1167": {
    "id": 1167,
    "title": "Execution Order",
    "content": "# üìã Query Execution Order\n\n## Processing Sequence\n\n1. FROM\n2. WHERE\n3. GROUP BY\n4. HAVING\n5. SELECT\n6. ORDER BY\n\n---\n\n## üéØ Your Task\n\nWrite a query demonstrating all clauses.",
    "starter_code": "SELECT department, COUNT(*) as emp_count\nFROM employees\nWHERE salary > 50000\nGROUP BY department\nHAVING COUNT(*) > 2\nORDER BY emp_count DESC;",
    "solution_code": "SELECT department, COUNT(*) as emp_count\nFROM employees\nWHERE salary > 50000\nGROUP BY department\nHAVING COUNT(*) > 2\nORDER BY emp_count DESC;",
    "expected_output": "Engineering|5\nSales|3",
    "chapter_id": 200,
    "chapter_title": "Setup & Mental Model"
  },
  "1168": {
    "id": 1168,
    "title": "Column Expressions",
    "content": "# üìä Calculated Columns\n\n## Expressions in SELECT\n\n```sql\nSELECT price, quantity, price * quantity AS total\nFROM orders;\n```\n\n---\n\n## üéØ Your Task\n\nCalculate total value (price √ó quantity) for each order.",
    "starter_code": "-- Calculate total value per order\nSELECT product, price, quantity\n-- Add calculated column for total\nFROM orders;",
    "solution_code": "SELECT product, price, quantity, price * quantity AS total\nFROM orders;",
    "expected_output": "Widget|29.99|10|299.90\nGadget|49.99|5|249.95",
    "chapter_id": 201,
    "chapter_title": "SELECT Basics"
  },
  "1169": {
    "id": 1169,
    "title": "Distinct Values",
    "content": "# üéØ Finding Unique Values\n\n## DISTINCT Keyword\n\n```sql\nSELECT DISTINCT category\nFROM products;\n```\n\n---\n\n## üéØ Your Task\n\nFind all unique departments in the company.",
    "starter_code": "-- Find unique departments\nSELECT \nFROM employees;",
    "solution_code": "SELECT DISTINCT department\nFROM employees;",
    "expected_output": "Engineering\nSales\nMarketing\nHR",
    "chapter_id": 201,
    "chapter_title": "SELECT Basics"
  },
  "1170": {
    "id": 1170,
    "title": "Complex Aliases",
    "content": "# üè∑Ô∏è Column Aliases\n\n## Readable Column Names\n\n```sql\nSELECT first_name AS \"First Name\",\n       last_name AS \"Last Name\"\nFROM users;\n```\n\n---\n\n## üéØ Your Task\n\nCreate readable aliases for employee data.",
    "starter_code": "-- Create readable aliases\nSELECT emp_id, first_name, salary\nFROM employees;",
    "solution_code": "SELECT emp_id AS \"Employee ID\",\n       first_name AS \"First Name\",\n       salary AS \"Annual Salary\"\nFROM employees;",
    "expected_output": "Employee ID|First Name|Annual Salary\n1|John|75000\n2|Jane|82000",
    "chapter_id": 201,
    "chapter_title": "SELECT Basics"
  },
  "1171": {
    "id": 1171,
    "title": "Pagination",
    "content": "# üìÑ Pagination\n\n## LIMIT and OFFSET\n\n```sql\nSELECT *\nFROM products\nLIMIT 10 OFFSET 20;  -- Skip 20, get next 10\n```\n\n---\n\n## üéØ Your Task\n\nGet the second page of results (items 11-20).",
    "starter_code": "-- Get page 2 (items 11-20)\nSELECT *\nFROM products\nORDER BY id\n-- Add pagination;",
    "solution_code": "SELECT *\nFROM products\nORDER BY id\nLIMIT 10 OFFSET 10;",
    "expected_output": "Results 11-20 of products",
    "chapter_id": 201,
    "chapter_title": "SELECT Basics"
  },
  "1172": {
    "id": 1172,
    "title": "Multiple Conditions",
    "content": "# üîó Multiple WHERE Conditions\n\n## AND/OR Logic\n\n```sql\nSELECT *\nFROM orders\nWHERE status = 'pending'\n  AND total > 100;\n```\n\n---\n\n## üéØ Your Task\n\nFind employees in Engineering OR Sales with salary > 70000.",
    "starter_code": "-- Engineering or Sales, salary > 70000\nSELECT *\nFROM employees\nWHERE ;",
    "solution_code": "SELECT *\nFROM employees\nWHERE (department = 'Engineering' OR department = 'Sales')\n  AND salary > 70000;",
    "expected_output": "John|Engineering|75000\nJane|Sales|82000",
    "chapter_id": 201,
    "chapter_title": "SELECT Basics"
  },
  "1173": {
    "id": 1173,
    "title": "Negation Patterns",
    "content": "# üö´ Negation in WHERE\n\n## NOT Operator\n\n```sql\nWHERE NOT status = 'active'\nWHERE status <> 'active'\nWHERE status NOT IN ('a', 'b')\n```\n\n---\n\n## üéØ Your Task\n\nFind all non-active users.",
    "starter_code": "-- Find non-active users\nSELECT name, status\nFROM users\nWHERE status <> 'active';",
    "solution_code": "SELECT name, status\nFROM users\nWHERE status <> 'active';",
    "expected_output": "Bob|inactive\nCharlie|pending",
    "chapter_id": 201,
    "chapter_title": "SELECT Basics"
  },
  "1174": {
    "id": 1174,
    "title": "Wildcard Mastery",
    "content": "# üîç LIKE Wildcards\n\n## Pattern Matching\n\n- % = any characters\n- _ = single character\n\n---\n\n## üéØ Your Task\n\nFind products starting with 'Pro'.",
    "starter_code": "-- Products starting with 'Pro'\nSELECT product_name\nFROM products\nWHERE product_name LIKE 'Pro%';",
    "solution_code": "SELECT product_name\nFROM products\nWHERE product_name LIKE 'Pro%';",
    "expected_output": "ProWidget\nProGadget",
    "chapter_id": 201,
    "chapter_title": "SELECT Basics"
  },
  "1175": {
    "id": 1175,
    "title": "Range Combinations",
    "content": "# üìè Range Queries\n\n## BETWEEN with OR\n\n---\n\n## üéØ Your Task\n\nFind products priced $20-50 OR over $100.",
    "starter_code": "-- Price ranges\nSELECT product_name, price\nFROM products\nWHERE price BETWEEN 20 AND 50\n   OR price > 100;",
    "solution_code": "SELECT product_name, price\nFROM products\nWHERE price BETWEEN 20 AND 50\n   OR price > 100;",
    "expected_output": "Widget|29.99\nGadget|49.99\nLuxury|199.99",
    "chapter_id": 201,
    "chapter_title": "SELECT Basics"
  },
  "1176": {
    "id": 1176,
    "title": "Precision Math",
    "content": "# üî¢ Decimal Precision\n\n## Precise Calculations\n\n```sql\nSELECT ROUND(value, 2)\nSELECT CAST(value AS DECIMAL(10,2))\n```\n\n---\n\n## üéØ Your Task\n\nCalculate price with tax, rounded to 2 decimals.",
    "starter_code": "SELECT product,\n       price,\n       ROUND(price * 1.08, 2) as price_with_tax\nFROM products;",
    "solution_code": "SELECT product,\n       price,\n       ROUND(price * 1.08, 2) as price_with_tax\nFROM products;",
    "expected_output": "Widget|29.99|32.39\nGadget|49.99|53.99",
    "chapter_id": 202,
    "chapter_title": "Data Types, NULLs & Calculations"
  },
  "1177": {
    "id": 1177,
    "title": "Rounding Methods",
    "content": "# üîÑ Rounding Functions\n\n## Different Rounding Methods\n\n- ROUND(x, n) - standard rounding\n- FLOOR(x) - round down\n- CEILING(x) - round up\n- TRUNC(x, n) - truncate\n\n---\n\n## üéØ Your Task\n\nApply different rounding methods.",
    "starter_code": "SELECT 123.456 as original,\n       ROUND(123.456, 2) as rounded,\n       FLOOR(123.456) as floored,\n       CEILING(123.456) as ceiled;",
    "solution_code": "SELECT 123.456 as original,\n       ROUND(123.456, 2) as rounded,\n       FLOOR(123.456) as floored,\n       CEILING(123.456) as ceiled;",
    "expected_output": "123.456|123.46|123|124",
    "chapter_id": 202,
    "chapter_title": "Data Types, NULLs & Calculations"
  },
  "1178": {
    "id": 1178,
    "title": "Integer Division",
    "content": "# ‚ûó Division Behavior\n\n## Integer vs Float Division\n\n```sql\n5 / 2 = 2 (integer division)\n5.0 / 2 = 2.5 (float division)\n```\n\n---\n\n## üéØ Your Task\n\nCalculate percentage with proper division.",
    "starter_code": "SELECT completed,\n       total,\n       CAST(completed AS FLOAT) / total * 100 as pct\nFROM tasks;",
    "solution_code": "SELECT completed,\n       total,\n       CAST(completed AS FLOAT) / total * 100 as pct\nFROM tasks;",
    "expected_output": "7|10|70.0\n3|8|37.5",
    "chapter_id": 202,
    "chapter_title": "Data Types, NULLs & Calculations"
  },
  "1179": {
    "id": 1179,
    "title": "String Functions",
    "content": "# üìù String Manipulation\n\n## Common Functions\n\n- UPPER(), LOWER()\n- LENGTH()\n- SUBSTRING()\n- CONCAT()\n\n---\n\n## üéØ Your Task\n\nFormat names: uppercase last name, first initial.",
    "starter_code": "SELECT CONCAT(SUBSTRING(first_name, 1, 1), '. ', UPPER(last_name)) as formatted\nFROM employees;",
    "solution_code": "SELECT CONCAT(SUBSTRING(first_name, 1, 1), '. ', UPPER(last_name)) as formatted\nFROM employees;",
    "expected_output": "J. SMITH\nM. JONES",
    "chapter_id": 202,
    "chapter_title": "Data Types, NULLs & Calculations"
  },
  "1180": {
    "id": 1180,
    "title": "Date Formatting",
    "content": "# üìÖ Date Formatting\n\n## TO_CHAR Function\n\n```sql\nTO_CHAR(date, 'YYYY-MM-DD')\nTO_CHAR(date, 'Month DD, YYYY')\n```\n\n---\n\n## üéØ Your Task\n\nFormat order dates.",
    "starter_code": "SELECT order_id,\n       TO_CHAR(order_date, 'YYYY-MM-DD') as formatted_date\nFROM orders;",
    "solution_code": "SELECT order_id,\n       TO_CHAR(order_date, 'YYYY-MM-DD') as formatted_date\nFROM orders;",
    "expected_output": "1|2024-01-15\n2|2024-01-20",
    "chapter_id": 202,
    "chapter_title": "Data Types, NULLs & Calculations"
  },
  "1181": {
    "id": 1181,
    "title": "NULL Coalescing Chain",
    "content": "# üîó COALESCE Chains\n\n## Multiple Fallbacks\n\n```sql\nCOALESCE(val1, val2, val3, 'default')\n```\n\n---\n\n## üéØ Your Task\n\nUse chained COALESCE for contact info.",
    "starter_code": "SELECT name,\n       COALESCE(mobile, home_phone, work_phone, 'No phone') as contact\nFROM contacts;",
    "solution_code": "SELECT name,\n       COALESCE(mobile, home_phone, work_phone, 'No phone') as contact\nFROM contacts;",
    "expected_output": "Alice|555-1234\nBob|555-5678\nCharlie|No phone",
    "chapter_id": 202,
    "chapter_title": "Data Types, NULLs & Calculations"
  },
  "1182": {
    "id": 1182,
    "title": "Type Casting",
    "content": "# üîÑ Type Casting\n\n## CAST and ::\n\n```sql\nCAST(column AS type)\ncolumn::type  -- PostgreSQL\n```\n\n---\n\n## üéØ Your Task\n\nConvert string dates to DATE type.",
    "starter_code": "SELECT date_string,\n       CAST(date_string AS DATE) as date_value\nFROM raw_data;",
    "solution_code": "SELECT date_string,\n       CAST(date_string AS DATE) as date_value\nFROM raw_data;",
    "expected_output": "2024-01-15|2024-01-15",
    "chapter_id": 202,
    "chapter_title": "Data Types, NULLs & Calculations"
  },
  "1183": {
    "id": 1183,
    "title": "Safe Conversions",
    "content": "# üõ°Ô∏è Safe Type Conversion\n\n## Handling Errors\n\n```sql\nTRY_CAST(value AS INTEGER)\n```\n\n---\n\n## üéØ Your Task\n\nSafely convert string to number.",
    "starter_code": "SELECT value,\n       CASE WHEN value ~ '^[0-9]+$' \n            THEN CAST(value AS INTEGER)\n            ELSE NULL END as num\nFROM data;",
    "solution_code": "SELECT value,\n       CASE WHEN value ~ '^[0-9]+$' \n            THEN CAST(value AS INTEGER)\n            ELSE NULL END as num\nFROM data;",
    "expected_output": "123|123\nabc|NULL\n456|456",
    "chapter_id": 202,
    "chapter_title": "Data Types, NULLs & Calculations"
  },
  "1184": {
    "id": 1184,
    "title": "Conditional COUNT",
    "content": "# üìä Conditional Counting\n\n## COUNT with CASE\n\n```sql\nCOUNT(CASE WHEN condition THEN 1 END)\n```\n\n---\n\n## üéØ Your Task\n\nCount active and inactive users.",
    "starter_code": "SELECT\n    COUNT(CASE WHEN status = 'active' THEN 1 END) as active,\n    COUNT(CASE WHEN status = 'inactive' THEN 1 END) as inactive\nFROM users;",
    "solution_code": "SELECT\n    COUNT(CASE WHEN status = 'active' THEN 1 END) as active,\n    COUNT(CASE WHEN status = 'inactive' THEN 1 END) as inactive\nFROM users;",
    "expected_output": "45|15",
    "chapter_id": 203,
    "chapter_title": "Aggregations & Grouping"
  },
  "1185": {
    "id": 1185,
    "title": "NULL-aware SUM",
    "content": "# ‚ûï NULL in Aggregates\n\n## SUM Ignores NULLs\n\n```sql\nSUM(COALESCE(value, 0))\n```\n\n---\n\n## üéØ Your Task\n\nSum values treating NULL as zero.",
    "starter_code": "SELECT category,\n       SUM(COALESCE(amount, 0)) as total\nFROM transactions\nGROUP BY category;",
    "solution_code": "SELECT category,\n       SUM(COALESCE(amount, 0)) as total\nFROM transactions\nGROUP BY category;",
    "expected_output": "A|500\nB|300",
    "chapter_id": 203,
    "chapter_title": "Aggregations & Grouping"
  },
  "1186": {
    "id": 1186,
    "title": "Range Calculation",
    "content": "# üìè Range Calculation\n\n## MAX - MIN\n\n---\n\n## üéØ Your Task\n\nCalculate price range per category.",
    "starter_code": "SELECT category,\n       MIN(price) as min_price,\n       MAX(price) as max_price,\n       MAX(price) - MIN(price) as price_range\nFROM products\nGROUP BY category;",
    "solution_code": "SELECT category,\n       MIN(price) as min_price,\n       MAX(price) as max_price,\n       MAX(price) - MIN(price) as price_range\nFROM products\nGROUP BY category;",
    "expected_output": "Electronics|50|500|450\nClothing|20|150|130",
    "chapter_id": 203,
    "chapter_title": "Aggregations & Grouping"
  },
  "1187": {
    "id": 1187,
    "title": "Percentage Share",
    "content": "# üìä Percentage Calculations\n\n## Part of Whole\n\n---\n\n## üéØ Your Task\n\nCalculate each department's share of total salary.",
    "starter_code": "SELECT department,\n       SUM(salary) as dept_total,\n       ROUND(SUM(salary) * 100.0 / (SELECT SUM(salary) FROM employees), 2) as pct\nFROM employees\nGROUP BY department;",
    "solution_code": "SELECT department,\n       SUM(salary) as dept_total,\n       ROUND(SUM(salary) * 100.0 / (SELECT SUM(salary) FROM employees), 2) as pct\nFROM employees\nGROUP BY department;",
    "expected_output": "Engineering|500000|55.56\nSales|400000|44.44",
    "chapter_id": 203,
    "chapter_title": "Aggregations & Grouping"
  },
  "1188": {
    "id": 1188,
    "title": "Running Average",
    "content": "# üìà Running Average\n\n## Cumulative Calculations\n\n---\n\n## üéØ Your Task\n\nCalculate running average of daily sales.",
    "starter_code": "SELECT date,\n       sales,\n       AVG(sales) OVER (ORDER BY date) as running_avg\nFROM daily_sales;",
    "solution_code": "SELECT date,\n       sales,\n       AVG(sales) OVER (ORDER BY date) as running_avg\nFROM daily_sales;",
    "expected_output": "2024-01-01|100|100\n2024-01-02|200|150\n2024-01-03|150|150",
    "chapter_id": 203,
    "chapter_title": "Aggregations & Grouping"
  },
  "1189": {
    "id": 1189,
    "title": "Multi-level Grouping",
    "content": "# üìä Multi-level GROUP BY\n\n## Grouping by Multiple Columns\n\n---\n\n## üéØ Your Task\n\nGroup by region and category.",
    "starter_code": "SELECT region, category, SUM(sales) as total\nFROM sales_data\nGROUP BY region, category\nORDER BY region, category;",
    "solution_code": "SELECT region, category, SUM(sales) as total\nFROM sales_data\nGROUP BY region, category\nORDER BY region, category;",
    "expected_output": "East|A|1000\nEast|B|800\nWest|A|1200",
    "chapter_id": 203,
    "chapter_title": "Aggregations & Grouping"
  },
  "1190": {
    "id": 1190,
    "title": "Three-Table Join",
    "content": "# üîó Three-Table Join\n\n## Joining Multiple Tables\n\n```sql\nSELECT *\nFROM orders o\nJOIN customers c ON o.customer_id = c.id\nJOIN products p ON o.product_id = p.id;\n```\n\n---\n\n## üéØ Your Task\n\nJoin orders, customers, and products.",
    "starter_code": "-- Join 3 tables\nSELECT o.order_id, c.name, p.product_name\nFROM orders o\n-- Add joins",
    "solution_code": "SELECT o.order_id, c.name, p.product_name\nFROM orders o\nJOIN customers c ON o.customer_id = c.id\nJOIN products p ON o.product_id = p.id;",
    "expected_output": "1|Alice|Widget\n2|Bob|Gadget",
    "chapter_id": 204,
    "chapter_title": "Joins Like a Pro"
  },
  "1191": {
    "id": 1191,
    "title": "Self-Referential",
    "content": "# üîÑ Self Joins\n\n## Joining Table to Itself\n\n---\n\n## üéØ Your Task\n\nFind employees and their managers.",
    "starter_code": "SELECT e.name as employee,\n       m.name as manager\nFROM employees e\nLEFT JOIN employees m ON e.manager_id = m.id;",
    "solution_code": "SELECT e.name as employee,\n       m.name as manager\nFROM employees e\nLEFT JOIN employees m ON e.manager_id = m.id;",
    "expected_output": "Alice|Bob\nBob|NULL\nCharlie|Bob",
    "chapter_id": 204,
    "chapter_title": "Joins Like a Pro"
  },
  "1192": {
    "id": 1192,
    "title": "Anti-Join Pattern",
    "content": "# üö´ Anti-Join\n\n## Finding Non-Matches\n\n```sql\nLEFT JOIN ... WHERE right.id IS NULL\n```\n\n---\n\n## üéØ Your Task\n\nFind customers with no orders.",
    "starter_code": "SELECT c.name\nFROM customers c\nLEFT JOIN orders o ON c.id = o.customer_id\nWHERE o.order_id IS NULL;",
    "solution_code": "SELECT c.name\nFROM customers c\nLEFT JOIN orders o ON c.id = o.customer_id\nWHERE o.order_id IS NULL;",
    "expected_output": "Charlie\nDiana",
    "chapter_id": 204,
    "chapter_title": "Joins Like a Pro"
  },
  "1193": {
    "id": 1193,
    "title": "Correlated WHERE",
    "content": "# üîó Correlated Subqueries\n\n## Subquery References Outer Query\n\n---\n\n## üéØ Your Task\n\nFind employees earning above department average.",
    "starter_code": "SELECT name, department, salary\nFROM employees e\nWHERE salary > (\n    SELECT AVG(salary)\n    FROM employees\n    WHERE department = e.department\n);",
    "solution_code": "SELECT name, department, salary\nFROM employees e\nWHERE salary > (\n    SELECT AVG(salary)\n    FROM employees\n    WHERE department = e.department\n);",
    "expected_output": "Alice|Eng|90000\nBob|Sales|75000",
    "chapter_id": 205,
    "chapter_title": "Subqueries & Set Operations"
  },
  "1194": {
    "id": 1194,
    "title": "Multi-value IN",
    "content": "# üìã IN with Subquery\n\n## Filtering with Subquery Results\n\n---\n\n## üéØ Your Task\n\nFind products in active categories.",
    "starter_code": "SELECT product_name\nFROM products\nWHERE category_id IN (\n    SELECT id FROM categories WHERE active = true\n);",
    "solution_code": "SELECT product_name\nFROM products\nWHERE category_id IN (\n    SELECT id FROM categories WHERE active = true\n);",
    "expected_output": "Widget\nGadget",
    "chapter_id": 205,
    "chapter_title": "Subqueries & Set Operations"
  },
  "1195": {
    "id": 1195,
    "title": "Scalar Comparison",
    "content": "# üî¢ Scalar Subqueries\n\n## Single Value Subqueries\n\n---\n\n## üéØ Your Task\n\nFind employees earning above overall average.",
    "starter_code": "SELECT name, salary\nFROM employees\nWHERE salary > (SELECT AVG(salary) FROM employees);",
    "solution_code": "SELECT name, salary\nFROM employees\nWHERE salary > (SELECT AVG(salary) FROM employees);",
    "expected_output": "Alice|90000\nBob|85000",
    "chapter_id": 205,
    "chapter_title": "Subqueries & Set Operations"
  },
  "1196": {
    "id": 1196,
    "title": "Double EXISTS",
    "content": "# ‚úÖ Multiple EXISTS\n\n## Combining EXISTS Conditions\n\n---\n\n## üéØ Your Task\n\nFind customers who have both orders and reviews.",
    "starter_code": "SELECT c.name\nFROM customers c\nWHERE EXISTS (SELECT 1 FROM orders WHERE customer_id = c.id)\n  AND EXISTS (SELECT 1 FROM reviews WHERE customer_id = c.id);",
    "solution_code": "SELECT c.name\nFROM customers c\nWHERE EXISTS (SELECT 1 FROM orders WHERE customer_id = c.id)\n  AND EXISTS (SELECT 1 FROM reviews WHERE customer_id = c.id);",
    "expected_output": "Alice\nBob",
    "chapter_id": 205,
    "chapter_title": "Subqueries & Set Operations"
  },
  "1197": {
    "id": 1197,
    "title": "NOT EXISTS Pattern",
    "content": "# üö´ NOT EXISTS\n\n## Anti-Pattern with EXISTS\n\n---\n\n## üéØ Your Task\n\nFind products never ordered.",
    "starter_code": "SELECT p.product_name\nFROM products p\nWHERE NOT EXISTS (\n    SELECT 1 FROM orders WHERE product_id = p.id\n);",
    "solution_code": "SELECT p.product_name\nFROM products p\nWHERE NOT EXISTS (\n    SELECT 1 FROM orders WHERE product_id = p.id\n);",
    "expected_output": "Discontinued Widget",
    "chapter_id": 205,
    "chapter_title": "Subqueries & Set Operations"
  },
  "1198": {
    "id": 1198,
    "title": "Correlated EXISTS",
    "content": "# üîó Correlated EXISTS\n\n## Dependent EXISTS\n\n---\n\n## üéØ Your Task\n\nFind departments with high earners (>70k).",
    "starter_code": "SELECT DISTINCT department\nFROM employees d\nWHERE EXISTS (\n    SELECT 1 FROM employees\n    WHERE department = d.department AND salary > 70000\n);",
    "solution_code": "SELECT DISTINCT department\nFROM employees d\nWHERE EXISTS (\n    SELECT 1 FROM employees\n    WHERE department = d.department AND salary > 70000\n);",
    "expected_output": "Engineering\nSales",
    "chapter_id": 205,
    "chapter_title": "Subqueries & Set Operations"
  },
  "1199": {
    "id": 1199,
    "title": "Inline Views",
    "content": "# üì¶ FROM Subqueries\n\n## Derived Tables\n\n---\n\n## üéØ Your Task\n\nUse subquery in FROM to calculate averages.",
    "starter_code": "SELECT dept_avg.department, dept_avg.avg_salary\nFROM (\n    SELECT department, AVG(salary) as avg_salary\n    FROM employees\n    GROUP BY department\n) dept_avg\nWHERE dept_avg.avg_salary > 60000;",
    "solution_code": "SELECT dept_avg.department, dept_avg.avg_salary\nFROM (\n    SELECT department, AVG(salary) as avg_salary\n    FROM employees\n    GROUP BY department\n) dept_avg\nWHERE dept_avg.avg_salary > 60000;",
    "expected_output": "Engineering|75000\nSales|65000",
    "chapter_id": 205,
    "chapter_title": "Subqueries & Set Operations"
  },
  "1200": {
    "id": 1200,
    "title": "SELECT Subqueries",
    "content": "# üìä Subqueries in SELECT\n\n## Calculated Columns\n\n---\n\n## üéØ Your Task\n\nAdd company-wide comparison to each row.",
    "starter_code": "SELECT name, salary,\n       salary - (SELECT AVG(salary) FROM employees) as diff_from_avg\nFROM employees;",
    "solution_code": "SELECT name, salary,\n       salary - (SELECT AVG(salary) FROM employees) as diff_from_avg\nFROM employees;",
    "expected_output": "Alice|80000|15000\nBob|60000|-5000",
    "chapter_id": 205,
    "chapter_title": "Subqueries & Set Operations"
  },
  "1201": {
    "id": 1201,
    "title": "Recursive Logic",
    "content": "# üîÑ Recursive Patterns\n\n## Self-Referential Data\n\n---\n\n## üéØ Your Task\n\nFind full management chain.",
    "starter_code": "WITH RECURSIVE mgmt_chain AS (\n    SELECT id, name, manager_id, 1 as level\n    FROM employees WHERE manager_id IS NULL\n    UNION ALL\n    SELECT e.id, e.name, e.manager_id, mc.level + 1\n    FROM employees e\n    JOIN mgmt_chain mc ON e.manager_id = mc.id\n)\nSELECT * FROM mgmt_chain;",
    "solution_code": "WITH RECURSIVE mgmt_chain AS (\n    SELECT id, name, manager_id, 1 as level\n    FROM employees WHERE manager_id IS NULL\n    UNION ALL\n    SELECT e.id, e.name, e.manager_id, mc.level + 1\n    FROM employees e\n    JOIN mgmt_chain mc ON e.manager_id = mc.id\n)\nSELECT * FROM mgmt_chain;",
    "expected_output": "1|CEO|NULL|1\n2|VP|1|2\n3|Manager|2|3",
    "chapter_id": 205,
    "chapter_title": "Subqueries & Set Operations"
  },
  "1202": {
    "id": 1202,
    "title": "Union Dedup",
    "content": "# ‚ãÉ UNION\n\n## Combining Results (Deduped)\n\n---\n\n## üéØ Your Task\n\nCombine customers from two sources.",
    "starter_code": "SELECT email FROM old_customers\nUNION\nSELECT email FROM new_customers;",
    "solution_code": "SELECT email FROM old_customers\nUNION\nSELECT email FROM new_customers;",
    "expected_output": "alice@example.com\nbob@example.com",
    "chapter_id": 205,
    "chapter_title": "Subqueries & Set Operations"
  },
  "1203": {
    "id": 1203,
    "title": "Intersection Find",
    "content": "# ‚à© INTERSECT\n\n## Finding Common Records\n\n---\n\n## üéØ Your Task\n\nFind customers in both lists.",
    "starter_code": "SELECT customer_id FROM list_a\nINTERSECT\nSELECT customer_id FROM list_b;",
    "solution_code": "SELECT customer_id FROM list_a\nINTERSECT\nSELECT customer_id FROM list_b;",
    "expected_output": "101\n105",
    "chapter_id": 205,
    "chapter_title": "Subqueries & Set Operations"
  },
  "1204": {
    "id": 1204,
    "title": "Query Decomposition",
    "content": "# üì¶ CTEs for Clarity\n\n## Breaking Down Complex Queries\n\n```sql\nWITH sales_summary AS (\n    SELECT region, SUM(amount) as total\n    FROM sales\n    GROUP BY region\n)\nSELECT * FROM sales_summary;\n```\n\n---\n\n## üéØ Your Task\n\nUse a CTE to calculate department totals.",
    "starter_code": "-- Use CTE for department totals\nWITH dept_totals AS (\n    -- Calculate sum of salaries per department\n)\nSELECT * FROM dept_totals;",
    "solution_code": "WITH dept_totals AS (\n    SELECT department, SUM(salary) as total_salary\n    FROM employees\n    GROUP BY department\n)\nSELECT * FROM dept_totals;",
    "expected_output": "Engineering|250000\nSales|180000",
    "chapter_id": 206,
    "chapter_title": "CTEs (WITH Clause)"
  },
  "1205": {
    "id": 1205,
    "title": "Readable CTEs",
    "content": "# üìñ Readable CTEs\n\n## Self-Documenting Queries\n\n---\n\n## üéØ Your Task\n\nRefactor complex query with CTEs.",
    "starter_code": "WITH active_customers AS (\n    SELECT * FROM customers WHERE status = 'active'\n),\nrecent_orders AS (\n    SELECT * FROM orders WHERE order_date > '2024-01-01'\n)\nSELECT ac.name, COUNT(ro.order_id) as recent_order_count\nFROM active_customers ac\nJOIN recent_orders ro ON ac.id = ro.customer_id\nGROUP BY ac.name;",
    "solution_code": "WITH active_customers AS (\n    SELECT * FROM customers WHERE status = 'active'\n),\nrecent_orders AS (\n    SELECT * FROM orders WHERE order_date > '2024-01-01'\n)\nSELECT ac.name, COUNT(ro.order_id) as recent_order_count\nFROM active_customers ac\nJOIN recent_orders ro ON ac.id = ro.customer_id\nGROUP BY ac.name;",
    "expected_output": "Alice|5\nBob|3",
    "chapter_id": 206,
    "chapter_title": "CTEs (WITH Clause)"
  },
  "1206": {
    "id": 1206,
    "title": "CTE Pipeline",
    "content": "# üîó CTE Pipelines\n\n## Sequential Processing\n\n---\n\n## üéØ Your Task\n\nChain CTEs for multi-step transformation.",
    "starter_code": "WITH step1 AS (\n    SELECT *, price * quantity as subtotal FROM orders\n),\nstep2 AS (\n    SELECT *, subtotal * 1.08 as total_with_tax FROM step1\n)\nSELECT order_id, total_with_tax FROM step2;",
    "solution_code": "WITH step1 AS (\n    SELECT *, price * quantity as subtotal FROM orders\n),\nstep2 AS (\n    SELECT *, subtotal * 1.08 as total_with_tax FROM step1\n)\nSELECT order_id, total_with_tax FROM step2;",
    "expected_output": "1|324.00\n2|270.00",
    "chapter_id": 206,
    "chapter_title": "CTEs (WITH Clause)"
  },
  "1207": {
    "id": 1207,
    "title": "Parallel CTEs",
    "content": "# ‚ö° Parallel CTEs\n\n## Independent CTEs\n\n---\n\n## üéØ Your Task\n\nDefine independent CTEs used together.",
    "starter_code": "WITH sales_totals AS (\n    SELECT region, SUM(amount) as total FROM sales GROUP BY region\n),\nregion_targets AS (\n    SELECT region, target FROM targets\n)\nSELECT st.region, st.total, rt.target,\n       st.total - rt.target as variance\nFROM sales_totals st\nJOIN region_targets rt ON st.region = rt.region;",
    "solution_code": "WITH sales_totals AS (\n    SELECT region, SUM(amount) as total FROM sales GROUP BY region\n),\nregion_targets AS (\n    SELECT region, target FROM targets\n)\nSELECT st.region, st.total, rt.target,\n       st.total - rt.target as variance\nFROM sales_totals st\nJOIN region_targets rt ON st.region = rt.region;",
    "expected_output": "East|12000|10000|2000\nWest|8000|10000|-2000",
    "chapter_id": 206,
    "chapter_title": "CTEs (WITH Clause)"
  },
  "1208": {
    "id": 1208,
    "title": "CTE Reuse",
    "content": "# ‚ôªÔ∏è Reusing CTEs\n\n## Reference CTE Multiple Times\n\n---\n\n## üéØ Your Task\n\nUse same CTE in multiple places.",
    "starter_code": "WITH monthly_sales AS (\n    SELECT EXTRACT(MONTH FROM date) as month, SUM(amount) as total\n    FROM sales GROUP BY 1\n)\nSELECT\n    (SELECT MAX(total) FROM monthly_sales) as best_month,\n    (SELECT MIN(total) FROM monthly_sales) as worst_month,\n    (SELECT AVG(total) FROM monthly_sales) as avg_month;",
    "solution_code": "WITH monthly_sales AS (\n    SELECT EXTRACT(MONTH FROM date) as month, SUM(amount) as total\n    FROM sales GROUP BY 1\n)\nSELECT\n    (SELECT MAX(total) FROM monthly_sales) as best_month,\n    (SELECT MIN(total) FROM monthly_sales) as worst_month,\n    (SELECT AVG(total) FROM monthly_sales) as avg_month;",
    "expected_output": "15000|8000|11500",
    "chapter_id": 206,
    "chapter_title": "CTEs (WITH Clause)"
  },
  "1209": {
    "id": 1209,
    "title": "Debug with CTEs",
    "content": "# üîç Debugging with CTEs\n\n## Step-by-Step Analysis\n\n---\n\n## üéØ Your Task\n\nBreak down query for debugging.",
    "starter_code": "-- Debug by examining each step\nWITH raw_data AS (\n    SELECT * FROM orders -- Examine: SELECT * FROM raw_data\n),\nfiltered AS (\n    SELECT * FROM raw_data WHERE status = 'completed'\n),\naggregated AS (\n    SELECT customer_id, COUNT(*) as count FROM filtered GROUP BY 1\n)\nSELECT * FROM aggregated;",
    "solution_code": "WITH raw_data AS (\n    SELECT * FROM orders\n),\nfiltered AS (\n    SELECT * FROM raw_data WHERE status = 'completed'\n),\naggregated AS (\n    SELECT customer_id, COUNT(*) as count FROM filtered GROUP BY 1\n)\nSELECT * FROM aggregated;",
    "expected_output": "101|5\n102|3",
    "chapter_id": 206,
    "chapter_title": "CTEs (WITH Clause)"
  },
  "1210": {
    "id": 1210,
    "title": "Window vs GROUP BY",
    "content": "# üÜö Window vs GROUP BY\n\n## Key Differences\n\n- GROUP BY collapses rows\n- Window functions keep rows\n\n---\n\n## üéØ Your Task\n\nShow individual rows with group total.",
    "starter_code": "SELECT name, department, salary,\n       SUM(salary) OVER (PARTITION BY department) as dept_total\nFROM employees;",
    "solution_code": "SELECT name, department, salary,\n       SUM(salary) OVER (PARTITION BY department) as dept_total\nFROM employees;",
    "expected_output": "Alice|Eng|80000|150000\nBob|Eng|70000|150000\nCharlie|Sales|60000|60000",
    "chapter_id": 207,
    "chapter_title": "Window Functions"
  },
  "1211": {
    "id": 1211,
    "title": "Top N per Group",
    "content": "# üèÜ Top N per Group\n\n## Using ROW_NUMBER\n\n```sql\nWITH ranked AS (\n    SELECT *, ROW_NUMBER() OVER (PARTITION BY category ORDER BY value DESC) as rn\n    FROM items\n)\nSELECT * FROM ranked WHERE rn <= 3;\n```\n\n---\n\n## üéØ Your Task\n\nFind top 2 salaries per department.",
    "starter_code": "-- Top 2 salaries per department\nWITH ranked AS (\n    SELECT *,\n           ROW_NUMBER() OVER (PARTITION BY department ORDER BY salary DESC) as rn\n    FROM employees\n)\nSELECT name, department, salary\nFROM ranked\nWHERE rn <= 2;",
    "solution_code": "WITH ranked AS (\n    SELECT *,\n           ROW_NUMBER() OVER (PARTITION BY department ORDER BY salary DESC) as rn\n    FROM employees\n)\nSELECT name, department, salary\nFROM ranked\nWHERE rn <= 2;",
    "expected_output": "Alice|Engineering|90000\nBob|Engineering|85000\nCharlie|Sales|75000\nDiana|Sales|70000",
    "chapter_id": 207,
    "chapter_title": "Window Functions"
  },
  "1212": {
    "id": 1212,
    "title": "Percentile Rank",
    "content": "# üìä Percentile Ranking\n\n## PERCENT_RANK Function\n\n```sql\nSELECT name, salary,\n       PERCENT_RANK() OVER (ORDER BY salary) as percentile\nFROM employees;\n```\n\n---\n\n## üéØ Your Task\n\nCalculate percentile rank of salaries.",
    "starter_code": "-- Calculate percentile rank\nSELECT name, salary,\n       -- Add PERCENT_RANK\nFROM employees\nORDER BY salary;",
    "solution_code": "SELECT name, salary,\n       PERCENT_RANK() OVER (ORDER BY salary) as percentile\nFROM employees\nORDER BY salary;",
    "expected_output": "Alice|50000|0.0\nBob|60000|0.33\nCharlie|70000|0.67\nDiana|80000|1.0",
    "chapter_id": 207,
    "chapter_title": "Window Functions"
  },
  "1213": {
    "id": 1213,
    "title": "Dense vs Regular",
    "content": "# üèÜ Ranking Differences\n\n## RANK vs DENSE_RANK\n\n```sql\nRANK() -- Skips numbers after ties\nDENSE_RANK() -- No gaps\n```\n\n---\n\n## üéØ Your Task\n\nCompare RANK and DENSE_RANK.",
    "starter_code": "-- Compare ranking functions\nSELECT name, score,\n       RANK() OVER (ORDER BY score DESC) as rank,\n       DENSE_RANK() OVER (ORDER BY score DESC) as dense_rank\nFROM students;",
    "solution_code": "SELECT name, score,\n       RANK() OVER (ORDER BY score DESC) as rank,\n       DENSE_RANK() OVER (ORDER BY score DESC) as dense_rank\nFROM students;",
    "expected_output": "Alice|95|1|1\nBob|95|1|1\nCharlie|90|3|2\nDiana|85|4|3",
    "chapter_id": 207,
    "chapter_title": "Window Functions"
  },
  "1214": {
    "id": 1214,
    "title": "Cumulative Sum",
    "content": "# üìä Running Totals\n\n## Window Function for Cumulative Sum\n\n```sql\nSELECT date, amount,\n       SUM(amount) OVER (ORDER BY date) as running_total\nFROM transactions;\n```\n\n---\n\n## üéØ Your Task\n\nCalculate cumulative sales.",
    "starter_code": "-- Calculate running total\nSELECT date, sales,\n       -- Add window function for running total\nFROM daily_sales\nORDER BY date;",
    "solution_code": "SELECT date, sales,\n       SUM(sales) OVER (ORDER BY date) as running_total\nFROM daily_sales\nORDER BY date;",
    "expected_output": "2024-01-01|100|100\n2024-01-02|150|250\n2024-01-03|75|325",
    "chapter_id": 207,
    "chapter_title": "Window Functions"
  },
  "1215": {
    "id": 1215,
    "title": "Rolling Window",
    "content": "# üìà Rolling Window Calculations\n\n## Moving Aggregations\n\n```sql\nSELECT date, value,\n       AVG(value) OVER (ORDER BY date ROWS BETWEEN 2 PRECEDING AND CURRENT ROW) as ma_3\nFROM data;\n```\n\n---\n\n## üéØ Your Task\n\nCalculate 3-day moving average.",
    "starter_code": "-- 3-day moving average\nSELECT date, sales,\n       AVG(sales) OVER (\n           ORDER BY date\n           ROWS BETWEEN 2 PRECEDING AND CURRENT ROW\n       ) as ma_3\nFROM daily_sales;",
    "solution_code": "SELECT date, sales,\n       AVG(sales) OVER (\n           ORDER BY date\n           ROWS BETWEEN 2 PRECEDING AND CURRENT ROW\n       ) as ma_3\nFROM daily_sales;",
    "expected_output": "2024-01-01|100|100\n2024-01-02|150|125\n2024-01-03|120|123.33",
    "chapter_id": 207,
    "chapter_title": "Window Functions"
  },
  "1216": {
    "id": 1216,
    "title": "YTD Calculations",
    "content": "# üìÖ Year-to-Date\n\n## YTD Aggregations\n\n---\n\n## üéØ Your Task\n\nCalculate YTD sales by month.",
    "starter_code": "SELECT month,\n       monthly_sales,\n       SUM(monthly_sales) OVER (ORDER BY month) as ytd_sales\nFROM monthly_sales\nWHERE EXTRACT(YEAR FROM month) = 2024;",
    "solution_code": "SELECT month,\n       monthly_sales,\n       SUM(monthly_sales) OVER (ORDER BY month) as ytd_sales\nFROM monthly_sales\nWHERE EXTRACT(YEAR FROM month) = 2024;",
    "expected_output": "2024-01|1000|1000\n2024-02|1200|2200\n2024-03|900|3100",
    "chapter_id": 207,
    "chapter_title": "Window Functions"
  },
  "1217": {
    "id": 1217,
    "title": "Period Comparison",
    "content": "# üìä Period Over Period\n\n## Using LAG for Comparison\n\n```sql\nSELECT date, value,\n       LAG(value) OVER (ORDER BY date) as prev_value,\n       value - LAG(value) OVER (ORDER BY date) as change\nFROM data;\n```\n\n---\n\n## üéØ Your Task\n\nCalculate month-over-month change.",
    "starter_code": "-- Month over month comparison\nSELECT month, revenue,\n       LAG(revenue) OVER (ORDER BY month) as prev_month,\n       revenue - LAG(revenue) OVER (ORDER BY month) as change\nFROM monthly_sales;",
    "solution_code": "SELECT month, revenue,\n       LAG(revenue) OVER (ORDER BY month) as prev_month,\n       revenue - LAG(revenue) OVER (ORDER BY month) as change\nFROM monthly_sales;",
    "expected_output": "2024-01|1000|NULL|NULL\n2024-02|1200|1000|200\n2024-03|1100|1200|-100",
    "chapter_id": 207,
    "chapter_title": "Window Functions"
  },
  "1218": {
    "id": 1218,
    "title": "Period Grouping",
    "content": "# üìÖ Period Grouping\n\n## Grouping by Time Periods\n\n---\n\n## üéØ Your Task\n\nGroup sales by week.",
    "starter_code": "SELECT DATE_TRUNC('week', order_date) as week,\n       SUM(amount) as weekly_sales\nFROM orders\nGROUP BY 1\nORDER BY 1;",
    "solution_code": "SELECT DATE_TRUNC('week', order_date) as week,\n       SUM(amount) as weekly_sales\nFROM orders\nGROUP BY 1\nORDER BY 1;",
    "expected_output": "2024-01-01|5000\n2024-01-08|6200",
    "chapter_id": 208,
    "chapter_title": "Time-Series SQL"
  },
  "1219": {
    "id": 1219,
    "title": "Date Range",
    "content": "# üìÜ Date Series\n\n## Generating Date Ranges\n\n---\n\n## üéØ Your Task\n\nGenerate a date series for reporting.",
    "starter_code": "SELECT date::date\nFROM generate_series('2024-01-01', '2024-01-07', '1 day') as date;",
    "solution_code": "SELECT date::date\nFROM generate_series('2024-01-01', '2024-01-07', '1 day') as date;",
    "expected_output": "2024-01-01\n2024-01-02\n2024-01-03\n...",
    "chapter_id": 208,
    "chapter_title": "Time-Series SQL"
  },
  "1220": {
    "id": 1220,
    "title": "Age Calculation",
    "content": "# ‚è∞ Age Calculation\n\n## Time Differences\n\n---\n\n## üéØ Your Task\n\nCalculate account age in days.",
    "starter_code": "SELECT name,\n       created_at,\n       CURRENT_DATE - created_at::date as account_age_days\nFROM users;",
    "solution_code": "SELECT name,\n       created_at,\n       CURRENT_DATE - created_at::date as account_age_days\nFROM users;",
    "expected_output": "Alice|2023-06-15|200\nBob|2024-01-01|15",
    "chapter_id": 208,
    "chapter_title": "Time-Series SQL"
  },
  "1221": {
    "id": 1221,
    "title": "Business Days",
    "content": "# üíº Business Days\n\n## Counting Weekdays\n\n---\n\n## üéØ Your Task\n\nCount business days between dates (simplified).",
    "starter_code": "SELECT start_date, end_date,\n       (end_date - start_date) as total_days\nFROM projects;",
    "solution_code": "SELECT start_date, end_date,\n       (end_date - start_date) as total_days\nFROM projects;",
    "expected_output": "2024-01-01|2024-01-15|14",
    "chapter_id": 208,
    "chapter_title": "Time-Series SQL"
  },
  "1222": {
    "id": 1222,
    "title": "Date Intervals",
    "content": "# ‚ûï Date Arithmetic\n\n## Adding Time Intervals\n\n---\n\n## üéØ Your Task\n\nAdd 30 days to dates.",
    "starter_code": "SELECT order_date,\n       order_date + INTERVAL '30 days' as due_date\nFROM orders;",
    "solution_code": "SELECT order_date,\n       order_date + INTERVAL '30 days' as due_date\nFROM orders;",
    "expected_output": "2024-01-15|2024-02-14",
    "chapter_id": 208,
    "chapter_title": "Time-Series SQL"
  },
  "1223": {
    "id": 1223,
    "title": "First-Time Users",
    "content": "# üë§ First-Time Detection\n\n## New User Analysis\n\n---\n\n## üéØ Your Task\n\nIdentify first-time purchasers.",
    "starter_code": "WITH first_purchase AS (\n    SELECT user_id, MIN(purchase_date) as first_date\n    FROM purchases GROUP BY user_id\n)\nSELECT p.*, fp.first_date\nFROM purchases p\nJOIN first_purchase fp ON p.user_id = fp.user_id\nWHERE p.purchase_date = fp.first_date;",
    "solution_code": "WITH first_purchase AS (\n    SELECT user_id, MIN(purchase_date) as first_date\n    FROM purchases GROUP BY user_id\n)\nSELECT p.*, fp.first_date\nFROM purchases p\nJOIN first_purchase fp ON p.user_id = fp.user_id\nWHERE p.purchase_date = fp.first_date;",
    "expected_output": "101|2024-01-05|2024-01-05",
    "chapter_id": 208,
    "chapter_title": "Time-Series SQL"
  },
  "1224": {
    "id": 1224,
    "title": "Return Visitors",
    "content": "# üîÑ Return Visitors\n\n## Tracking Returning Users\n\n---\n\n## üéØ Your Task\n\nIdentify return visitors.",
    "starter_code": "SELECT user_id, COUNT(DISTINCT visit_date) as visit_count\nFROM visits\nGROUP BY user_id\nHAVING COUNT(DISTINCT visit_date) > 1;",
    "solution_code": "SELECT user_id, COUNT(DISTINCT visit_date) as visit_count\nFROM visits\nGROUP BY user_id\nHAVING COUNT(DISTINCT visit_date) > 1;",
    "expected_output": "101|5\n102|3",
    "chapter_id": 208,
    "chapter_title": "Time-Series SQL"
  },
  "1225": {
    "id": 1225,
    "title": "Funnel Metrics",
    "content": "# üìä Conversion Funnels\n\n## Funnel Analysis\n\n---\n\n## üéØ Your Task\n\nCalculate conversion rate between steps.",
    "starter_code": "SELECT\n    COUNT(CASE WHEN step = 'view' THEN 1 END) as views,\n    COUNT(CASE WHEN step = 'cart' THEN 1 END) as carts,\n    COUNT(CASE WHEN step = 'purchase' THEN 1 END) as purchases,\n    ROUND(COUNT(CASE WHEN step = 'purchase' THEN 1 END) * 100.0 / \n          NULLIF(COUNT(CASE WHEN step = 'view' THEN 1 END), 0), 2) as conversion_rate\nFROM funnel_events;",
    "solution_code": "SELECT\n    COUNT(CASE WHEN step = 'view' THEN 1 END) as views,\n    COUNT(CASE WHEN step = 'cart' THEN 1 END) as carts,\n    COUNT(CASE WHEN step = 'purchase' THEN 1 END) as purchases,\n    ROUND(COUNT(CASE WHEN step = 'purchase' THEN 1 END) * 100.0 / \n          NULLIF(COUNT(CASE WHEN step = 'view' THEN 1 END), 0), 2) as conversion_rate\nFROM funnel_events;",
    "expected_output": "1000|300|50|5.00",
    "chapter_id": 208,
    "chapter_title": "Time-Series SQL"
  },
  "1226": {
    "id": 1226,
    "title": "Fuzzy Duplicates",
    "content": "# üîç Fuzzy Matching\n\n## Near-Duplicate Detection\n\n---\n\n## üéØ Your Task\n\nFind similar names (simplified matching).",
    "starter_code": "SELECT a.name, b.name\nFROM customers a\nJOIN customers b ON a.id < b.id\nWHERE LOWER(a.name) = LOWER(b.name);",
    "solution_code": "SELECT a.name, b.name\nFROM customers a\nJOIN customers b ON a.id < b.id\nWHERE LOWER(a.name) = LOWER(b.name);",
    "expected_output": "Alice|ALICE",
    "chapter_id": 209,
    "chapter_title": "Data Cleaning & Metrics"
  },
  "1227": {
    "id": 1227,
    "title": "Keep Latest",
    "content": "# üìÖ Keep Most Recent\n\n## Dedupe by Date\n\n---\n\n## üéØ Your Task\n\nKeep only most recent record per user.",
    "starter_code": "WITH ranked AS (\n    SELECT *, ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY updated_at DESC) as rn\n    FROM user_data\n)\nSELECT * FROM ranked WHERE rn = 1;",
    "solution_code": "WITH ranked AS (\n    SELECT *, ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY updated_at DESC) as rn\n    FROM user_data\n)\nSELECT * FROM ranked WHERE rn = 1;",
    "expected_output": "101|latest|2024-01-15",
    "chapter_id": 209,
    "chapter_title": "Data Cleaning & Metrics"
  },
  "1228": {
    "id": 1228,
    "title": "IQR Method",
    "content": "# üìä IQR Outlier Detection\n\n## Interquartile Range\n\n---\n\n## üéØ Your Task\n\nIdentify outliers using IQR.",
    "starter_code": "WITH stats AS (\n    SELECT \n        PERCENTILE_CONT(0.25) WITHIN GROUP (ORDER BY value) as q1,\n        PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY value) as q3\n    FROM measurements\n)\nSELECT m.value\nFROM measurements m, stats\nWHERE m.value < q1 - 1.5*(q3-q1) OR m.value > q3 + 1.5*(q3-q1);",
    "solution_code": "WITH stats AS (\n    SELECT \n        PERCENTILE_CONT(0.25) WITHIN GROUP (ORDER BY value) as q1,\n        PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY value) as q3\n    FROM measurements\n)\nSELECT m.value\nFROM measurements m, stats\nWHERE m.value < q1 - 1.5*(q3-q1) OR m.value > q3 + 1.5*(q3-q1);",
    "expected_output": "100 (outlier)",
    "chapter_id": 209,
    "chapter_title": "Data Cleaning & Metrics"
  },
  "1229": {
    "id": 1229,
    "title": "Z-Score Filter",
    "content": "# üìà Z-Score Filtering\n\n## Standard Deviation Method\n\n---\n\n## üéØ Your Task\n\nFilter values more than 2 std devs from mean.",
    "starter_code": "WITH stats AS (\n    SELECT AVG(value) as mean, STDDEV(value) as std\n    FROM measurements\n)\nSELECT m.value, (m.value - mean) / std as z_score\nFROM measurements m, stats\nWHERE ABS((m.value - mean) / std) > 2;",
    "solution_code": "WITH stats AS (\n    SELECT AVG(value) as mean, STDDEV(value) as std\n    FROM measurements\n)\nSELECT m.value, (m.value - mean) / std as z_score\nFROM measurements m, stats\nWHERE ABS((m.value - mean) / std) > 2;",
    "expected_output": "100|2.5",
    "chapter_id": 209,
    "chapter_title": "Data Cleaning & Metrics"
  },
  "1230": {
    "id": 1230,
    "title": "DAU/MAU Ratio",
    "content": "# üìä DAU/MAU Ratio\n\n## Engagement Metrics\n\nDaily Active Users / Monthly Active Users = stickiness\n\n---\n\n## üéØ Your Task\n\nCalculate DAU/MAU ratio.",
    "starter_code": "WITH daily AS (\n    SELECT COUNT(DISTINCT user_id) as dau FROM events WHERE date = CURRENT_DATE\n),\nmonthly AS (\n    SELECT COUNT(DISTINCT user_id) as mau FROM events WHERE date >= CURRENT_DATE - 30\n)\nSELECT ROUND(dau * 100.0 / mau, 2) as stickiness FROM daily, monthly;",
    "solution_code": "WITH daily AS (\n    SELECT COUNT(DISTINCT user_id) as dau FROM events WHERE date = CURRENT_DATE\n),\nmonthly AS (\n    SELECT COUNT(DISTINCT user_id) as mau FROM events WHERE date >= CURRENT_DATE - 30\n)\nSELECT ROUND(dau * 100.0 / mau, 2) as stickiness FROM daily, monthly;",
    "expected_output": "25.5 (example)",
    "chapter_id": 209,
    "chapter_title": "Data Cleaning & Metrics"
  },
  "1231": {
    "id": 1231,
    "title": "Cohort Retention",
    "content": "# üìà Cohort Retention\n\n## Tracking User Retention\n\n---\n\n## üéØ Your Task\n\nCalculate retention by cohort.",
    "starter_code": "WITH cohorts AS (\n    SELECT user_id, MIN(DATE_TRUNC('month', first_action)) as cohort\n    FROM users GROUP BY 1\n)\nSELECT cohort, COUNT(DISTINCT user_id) as users\nFROM cohorts GROUP BY 1;",
    "solution_code": "WITH cohorts AS (\n    SELECT user_id, MIN(DATE_TRUNC('month', first_action)) as cohort\n    FROM users GROUP BY 1\n)\nSELECT cohort, COUNT(DISTINCT user_id) as users\nFROM cohorts GROUP BY 1;",
    "expected_output": "2024-01|100\n2024-02|120",
    "chapter_id": 209,
    "chapter_title": "Data Cleaning & Metrics"
  },
  "1232": {
    "id": 1232,
    "title": "Completeness Check",
    "content": "# ‚úÖ Data Completeness\n\n## Checking for Missing Data\n\n---\n\n## üéØ Your Task\n\nReport missing data percentages.",
    "starter_code": "SELECT\n    COUNT(*) as total_rows,\n    SUM(CASE WHEN name IS NULL THEN 1 ELSE 0 END) as missing_name,\n    SUM(CASE WHEN email IS NULL THEN 1 ELSE 0 END) as missing_email\nFROM users;",
    "solution_code": "SELECT\n    COUNT(*) as total_rows,\n    SUM(CASE WHEN name IS NULL THEN 1 ELSE 0 END) as missing_name,\n    SUM(CASE WHEN email IS NULL THEN 1 ELSE 0 END) as missing_email\nFROM users;",
    "expected_output": "1000|5|25",
    "chapter_id": 209,
    "chapter_title": "Data Cleaning & Metrics"
  },
  "1233": {
    "id": 1233,
    "title": "Consistency Check",
    "content": "# üîç Data Consistency\n\n## Validating Relationships\n\n---\n\n## üéØ Your Task\n\nFind orphaned records.",
    "starter_code": "SELECT o.order_id\nFROM orders o\nLEFT JOIN customers c ON o.customer_id = c.id\nWHERE c.id IS NULL;",
    "solution_code": "SELECT o.order_id\nFROM orders o\nLEFT JOIN customers c ON o.customer_id = c.id\nWHERE c.id IS NULL;",
    "expected_output": "(empty - good data quality)",
    "chapter_id": 209,
    "chapter_title": "Data Cleaning & Metrics"
  },
  "1234": {
    "id": 1234,
    "title": "Dependency Analysis",
    "content": "# üîó Functional Dependencies\n\n## Identifying Dependencies\n\n---\n\n## üéØ Your Task\n\nIdentify column dependencies.",
    "starter_code": "SELECT zip_code, COUNT(DISTINCT city) as cities\nFROM addresses\nGROUP BY zip_code\nHAVING COUNT(DISTINCT city) > 1;",
    "solution_code": "SELECT zip_code, COUNT(DISTINCT city) as cities\nFROM addresses\nGROUP BY zip_code\nHAVING COUNT(DISTINCT city) > 1;",
    "expected_output": "(empty if well-normalized)",
    "chapter_id": 210,
    "chapter_title": "Database Design Essentials"
  },
  "1235": {
    "id": 1235,
    "title": "Dimension Building",
    "content": "# üìê Dimension Tables\n\n## Creating Dimensions\n\n---\n\n## üéØ Your Task\n\nCreate a product dimension.",
    "starter_code": "SELECT DISTINCT\n    product_id,\n    product_name,\n    category,\n    subcategory\nFROM products;",
    "solution_code": "SELECT DISTINCT\n    product_id,\n    product_name,\n    category,\n    subcategory\nFROM products;",
    "expected_output": "1|Widget|Electronics|Gadgets",
    "chapter_id": 210,
    "chapter_title": "Database Design Essentials"
  },
  "1236": {
    "id": 1236,
    "title": "Fact Table Design",
    "content": "# üìä Fact Tables\n\n## Designing Fact Tables\n\n---\n\n## üéØ Your Task\n\nCreate a sales fact query.",
    "starter_code": "SELECT\n    date_id,\n    product_id,\n    customer_id,\n    SUM(quantity) as total_qty,\n    SUM(amount) as total_amount\nFROM sales\nGROUP BY 1, 2, 3;",
    "solution_code": "SELECT\n    date_id,\n    product_id,\n    customer_id,\n    SUM(quantity) as total_qty,\n    SUM(amount) as total_amount\nFROM sales\nGROUP BY 1, 2, 3;",
    "expected_output": "20240115|1|101|5|250.00",
    "chapter_id": 210,
    "chapter_title": "Database Design Essentials"
  },
  "1237": {
    "id": 1237,
    "title": "Constraint Testing",
    "content": "# üîí Testing Constraints\n\n## Validating Data Integrity\n\n---\n\n## üéØ Your Task\n\nFind constraint violations.",
    "starter_code": "SELECT id, email, COUNT(*)\nFROM users\nGROUP BY id, email\nHAVING COUNT(*) > 1;",
    "solution_code": "SELECT id, email, COUNT(*)\nFROM users\nGROUP BY id, email\nHAVING COUNT(*) > 1;",
    "expected_output": "(empty - no duplicates)",
    "chapter_id": 210,
    "chapter_title": "Database Design Essentials"
  },
  "1238": {
    "id": 1238,
    "title": "Cascade Behavior",
    "content": "# üîÑ CASCADE Options\n\n## FK Cascade Behavior\n\n```sql\nON DELETE CASCADE\nON DELETE SET NULL\nON DELETE RESTRICT\n```\n\n---\n\n## üéØ Your Task\n\nUnderstand cascade behavior.",
    "starter_code": "-- When deleting a customer, orders are also deleted\nALTER TABLE orders\nADD CONSTRAINT fk_customer\nFOREIGN KEY (customer_id) REFERENCES customers(id)\nON DELETE CASCADE;",
    "solution_code": "ALTER TABLE orders\nADD CONSTRAINT fk_customer\nFOREIGN KEY (customer_id) REFERENCES customers(id)\nON DELETE CASCADE;",
    "expected_output": "Constraint added",
    "chapter_id": 210,
    "chapter_title": "Database Design Essentials"
  },
  "1239": {
    "id": 1239,
    "title": "Denormalize Trade-offs",
    "content": "# ‚öñÔ∏è Denormalization\n\n## When to Denormalize\n\n- Read-heavy workloads\n- Complex joins hurting performance\n\n---\n\n## üéØ Your Task\n\nCreate denormalized view for reporting.",
    "starter_code": "CREATE VIEW order_summary AS\nSELECT\n    o.order_id,\n    o.order_date,\n    c.name as customer_name,\n    p.product_name,\n    o.quantity,\n    o.amount\nFROM orders o\nJOIN customers c ON o.customer_id = c.id\nJOIN products p ON o.product_id = p.id;",
    "solution_code": "CREATE VIEW order_summary AS\nSELECT o.order_id, o.order_date, c.name, p.product_name, o.quantity, o.amount\nFROM orders o\nJOIN customers c ON o.customer_id = c.id\nJOIN products p ON o.product_id = p.id;",
    "expected_output": "View created",
    "chapter_id": 210,
    "chapter_title": "Database Design Essentials"
  },
  "1240": {
    "id": 1240,
    "title": "SCD Implementation",
    "content": "# üìÖ Slowly Changing Dimensions\n\n## Type 2 SCD Pattern\n\n---\n\n## üéØ Your Task\n\nFind current dimension records.",
    "starter_code": "SELECT *\nFROM dim_customer\nWHERE is_current = TRUE;",
    "solution_code": "SELECT *\nFROM dim_customer\nWHERE is_current = TRUE;",
    "expected_output": "1|Alice|NYC|2024-01-01|NULL|TRUE",
    "chapter_id": 210,
    "chapter_title": "Database Design Essentials"
  },
  "1241": {
    "id": 1241,
    "title": "Audit Columns",
    "content": "# üìù Audit Columns\n\n## Tracking Changes\n\n---\n\n## üéØ Your Task\n\nAdd audit columns to query.",
    "starter_code": "SELECT\n    id,\n    name,\n    created_at,\n    updated_at,\n    created_by\nFROM products\nWHERE updated_at > CURRENT_DATE - 7;",
    "solution_code": "SELECT id, name, created_at, updated_at, created_by\nFROM products\nWHERE updated_at > CURRENT_DATE - 7;",
    "expected_output": "1|Widget|2024-01-01|2024-01-14|admin",
    "chapter_id": 210,
    "chapter_title": "Database Design Essentials"
  },
  "1242": {
    "id": 1242,
    "title": "Index Selection",
    "content": "# üìá Index Strategy\n\n## Choosing Indexes\n\n---\n\n## üéØ Your Task\n\nIdentify columns for indexing.",
    "starter_code": "-- Index on frequently filtered columns\nCREATE INDEX idx_orders_date ON orders(order_date);\nCREATE INDEX idx_orders_customer ON orders(customer_id);",
    "solution_code": "CREATE INDEX idx_orders_date ON orders(order_date);\nCREATE INDEX idx_orders_customer ON orders(customer_id);",
    "expected_output": "Indexes created",
    "chapter_id": 211,
    "chapter_title": "Performance & Query Plans"
  },
  "1243": {
    "id": 1243,
    "title": "Cost Analysis",
    "content": "# üìä Query Cost Analysis\n\n## EXPLAIN Output\n\n---\n\n## üéØ Your Task\n\nAnalyze query execution plan.",
    "starter_code": "EXPLAIN ANALYZE\nSELECT * FROM orders WHERE customer_id = 101;",
    "solution_code": "EXPLAIN ANALYZE\nSELECT * FROM orders WHERE customer_id = 101;",
    "expected_output": "Index Scan using idx_customer (cost=0.15..8.17)",
    "chapter_id": 211,
    "chapter_title": "Performance & Query Plans"
  },
  "1244": {
    "id": 1244,
    "title": "Join Order",
    "content": "# üîó Join Optimization\n\n## Join Order Matters\n\n---\n\n## üéØ Your Task\n\nStart with the smallest table.",
    "starter_code": "SELECT *\nFROM small_lookup_table l\nJOIN large_fact_table f ON l.id = f.lookup_id\nWHERE l.category = 'A';",
    "solution_code": "SELECT *\nFROM small_lookup_table l\nJOIN large_fact_table f ON l.id = f.lookup_id\nWHERE l.category = 'A';",
    "expected_output": "Optimized join order",
    "chapter_id": 211,
    "chapter_title": "Performance & Query Plans"
  },
  "1245": {
    "id": 1245,
    "title": "Scan Types",
    "content": "# üîç Scan Types\n\n## Sequential vs Index Scans\n\n---\n\n## üéØ Your Task\n\nUnderstand when each is used.",
    "starter_code": "-- Sequential scan for large portions of table\n-- Index scan for selective queries\nEXPLAIN SELECT * FROM orders WHERE customer_id = 101;",
    "solution_code": "EXPLAIN SELECT * FROM orders WHERE customer_id = 101;",
    "expected_output": "Index Scan on orders",
    "chapter_id": 211,
    "chapter_title": "Performance & Query Plans"
  },
  "1246": {
    "id": 1246,
    "title": "Query Rewrite",
    "content": "# ‚úèÔ∏è Query Optimization\n\n## Rewriting for Performance\n\n---\n\n## üéØ Your Task\n\nRewrite subquery as JOIN.",
    "starter_code": "-- Instead of:\n-- SELECT * FROM orders WHERE customer_id IN (SELECT id FROM customers WHERE status='active')\n\n-- Use:\nSELECT o.*\nFROM orders o\nJOIN customers c ON o.customer_id = c.id\nWHERE c.status = 'active';",
    "solution_code": "SELECT o.*\nFROM orders o\nJOIN customers c ON o.customer_id = c.id\nWHERE c.status = 'active';",
    "expected_output": "Optimized query",
    "chapter_id": 211,
    "chapter_title": "Performance & Query Plans"
  },
  "1247": {
    "id": 1247,
    "title": "Sargable Queries",
    "content": "# ‚ö° Sargable Queries\n\n## Index-Friendly WHERE Clauses\n\n---\n\n## üéØ Your Task\n\nMake query sargable.",
    "starter_code": "-- Non-sargable: WHERE YEAR(date) = 2024\n-- Sargable:\nSELECT *\nFROM orders\nWHERE order_date >= '2024-01-01' AND order_date < '2025-01-01';",
    "solution_code": "SELECT *\nFROM orders\nWHERE order_date >= '2024-01-01' AND order_date < '2025-01-01';",
    "expected_output": "Sargable query using index",
    "chapter_id": 211,
    "chapter_title": "Performance & Query Plans"
  },
  "1248": {
    "id": 1248,
    "title": "Upsert Pattern",
    "content": "# üîÑ UPSERT Pattern\n\n## INSERT or UPDATE\n\n---\n\n## üéØ Your Task\n\nImplement upsert logic.",
    "starter_code": "INSERT INTO settings (key, value)\nVALUES ('theme', 'dark')\nON CONFLICT (key)\nDO UPDATE SET value = EXCLUDED.value;",
    "solution_code": "INSERT INTO settings (key, value)\nVALUES ('theme', 'dark')\nON CONFLICT (key)\nDO UPDATE SET value = EXCLUDED.value;",
    "expected_output": "INSERT or UPDATE successful",
    "chapter_id": 212,
    "chapter_title": "Mutations & Transactions"
  },
  "1249": {
    "id": 1249,
    "title": "Default Values",
    "content": "# üìù DEFAULT Keyword\n\n## Using Column Defaults\n\n---\n\n## üéØ Your Task\n\nInsert using DEFAULT values.",
    "starter_code": "INSERT INTO orders (customer_id, product_id, quantity)\nVALUES (101, 5, DEFAULT);  -- Uses column default for quantity",
    "solution_code": "INSERT INTO orders (customer_id, product_id, quantity)\nVALUES (101, 5, DEFAULT);",
    "expected_output": "Row inserted with default quantity",
    "chapter_id": 212,
    "chapter_title": "Mutations & Transactions"
  },
  "1250": {
    "id": 1250,
    "title": "Conditional Update",
    "content": "# ‚úèÔ∏è CASE in UPDATE\n\n## Conditional Updates\n\n---\n\n## üéØ Your Task\n\nUpdate with CASE logic.",
    "starter_code": "UPDATE products\nSET price = CASE\n    WHEN category = 'Electronics' THEN price * 1.1\n    WHEN category = 'Clothing' THEN price * 0.9\n    ELSE price\nEND;",
    "solution_code": "UPDATE products\nSET price = CASE\n    WHEN category = 'Electronics' THEN price * 1.1\n    WHEN category = 'Clothing' THEN price * 0.9\n    ELSE price\nEND;",
    "expected_output": "X rows updated",
    "chapter_id": 212,
    "chapter_title": "Mutations & Transactions"
  },
  "1251": {
    "id": 1251,
    "title": "Batch Update",
    "content": "# üì¶ Batch Updates\n\n## Updating Multiple Rows\n\n---\n\n## üéØ Your Task\n\nUpdate multiple rows efficiently.",
    "starter_code": "UPDATE orders\nSET status = 'shipped'\nWHERE order_date < CURRENT_DATE - 3\n  AND status = 'processing';",
    "solution_code": "UPDATE orders\nSET status = 'shipped'\nWHERE order_date < CURRENT_DATE - 3\n  AND status = 'processing';",
    "expected_output": "50 rows updated",
    "chapter_id": 212,
    "chapter_title": "Mutations & Transactions"
  },
  "218": {
    "id": 218,
    "title": "Imputation Strategy",
    "content": "# üîß Imputation Strategy\n\n## Choosing Fill Methods\n\n```python\nimport pandas as pd\ndf['column'].fillna(df['column'].mean())  # Fill with mean\n```\n\n---\n\n## ÔøΩÔøΩ Your Task\n\nFill missing ages with the median age.",
    "starter_code": "import pandas as pd\nimport numpy as np\n\ndf = pd.DataFrame({\n    'name': ['Alice', 'Bob', 'Charlie', 'Diana'],\n    'age': [25, np.nan, 35, np.nan]\n})\n\n# Fill missing ages with median\nmedian_age = df['age'].median()\ndf['age'] = None  # Fill missing\n\nprint(df)",
    "solution_code": "import pandas as pd\nimport numpy as np\n\ndf = pd.DataFrame({\n    'name': ['Alice', 'Bob', 'Charlie', 'Diana'],\n    'age': [25, np.nan, 35, np.nan]\n})\n\n# Fill missing ages with median\nmedian_age = df['age'].median()\ndf['age'] = df['age'].fillna(median_age)\n\nprint(df)",
    "expected_output": "      name   age\n0    Alice  25.0\n1      Bob  30.0\n2  Charlie  35.0\n3    Diana  30.0",
    "chapter_id": 96,
    "chapter_title": "Data Cleaning"
  },
  "219": {
    "id": 219,
    "title": "Missing Data Report",
    "content": "# üìä Missing Data Analysis\n\n## Counting Missing Values\n\n```python\nmissing = df.isnull().sum()\npercent = (missing / len(df)) * 100\n```\n\n---\n\n## üéØ Your Task\n\nGenerate a report of missing data percentages.",
    "starter_code": "import pandas as pd\nimport numpy as np\n\ndf = pd.DataFrame({\n    'A': [1, np.nan, 3, np.nan, 5],\n    'B': [np.nan, 2, 3, 4, 5],\n    'C': [1, 2, np.nan, np.nan, np.nan]\n})\n\n# Calculate missing percentages\nmissing_pct = None  # Your code\n\nprint(missing_pct)",
    "solution_code": "import pandas as pd\nimport numpy as np\n\ndf = pd.DataFrame({\n    'A': [1, np.nan, 3, np.nan, 5],\n    'B': [np.nan, 2, 3, 4, 5],\n    'C': [1, 2, np.nan, np.nan, np.nan]\n})\n\n# Calculate missing percentages\nmissing_pct = (df.isnull().sum() / len(df) * 100).round(1)\n\nprint(missing_pct)",
    "expected_output": "A    40.0\nB    20.0\nC    60.0\ndtype: float64",
    "chapter_id": 96,
    "chapter_title": "Data Cleaning"
  },
  "220": {
    "id": 220,
    "title": "Forward Fill",
    "content": "# ‚û°Ô∏è Forward Fill\n\n## Time Series Filling\n\n```python\ndf['value'].ffill()  # Forward fill\ndf['value'].bfill()  # Backward fill\n```\n\n---\n\n## üéØ Your Task\n\nForward fill missing sensor readings.",
    "starter_code": "import pandas as pd\nimport numpy as np\n\ndf = pd.DataFrame({\n    'time': [1, 2, 3, 4, 5],\n    'reading': [100, np.nan, np.nan, 150, np.nan]\n})\n\n# Forward fill missing readings\ndf['reading'] = None  # Apply ffill\n\nprint(df)",
    "solution_code": "import pandas as pd\nimport numpy as np\n\ndf = pd.DataFrame({\n    'time': [1, 2, 3, 4, 5],\n    'reading': [100, np.nan, np.nan, 150, np.nan]\n})\n\n# Forward fill missing readings\ndf['reading'] = df['reading'].ffill()\n\nprint(df)",
    "expected_output": "   time  reading\n0     1    100.0\n1     2    100.0\n2     3    100.0\n3     4    150.0\n4     5    150.0",
    "chapter_id": 96,
    "chapter_title": "Data Cleaning"
  },
  "221": {
    "id": 221,
    "title": "Group-based Fill",
    "content": "# üìä Group-based Filling\n\n## Fill by Category\n\n```python\ndf['value'] = df.groupby('category')['value'].transform(\n    lambda x: x.fillna(x.mean())\n)\n```\n\n---\n\n## üéØ Your Task\n\nFill missing salaries with department average.",
    "starter_code": "import pandas as pd\nimport numpy as np\n\ndf = pd.DataFrame({\n    'dept': ['A', 'A', 'B', 'B'],\n    'salary': [50000, np.nan, 60000, np.nan]\n})\n\n# Fill with department average\ndf['salary'] = df.groupby('dept')['salary'].transform(\n    # Your lambda here\n)\n\nprint(df)",
    "solution_code": "import pandas as pd\nimport numpy as np\n\ndf = pd.DataFrame({\n    'dept': ['A', 'A', 'B', 'B'],\n    'salary': [50000, np.nan, 60000, np.nan]\n})\n\n# Fill with department average\ndf['salary'] = df.groupby('dept')['salary'].transform(\n    lambda x: x.fillna(x.mean())\n)\n\nprint(df)",
    "expected_output": "  dept   salary\n0    A  50000.0\n1    A  50000.0\n2    B  60000.0\n3    B  60000.0",
    "chapter_id": 96,
    "chapter_title": "Data Cleaning"
  },
  "222": {
    "id": 222,
    "title": "Duplicate Report",
    "content": "# üëØ Identifying Duplicates\n\n## Finding Duplicates\n\n```python\nduplicates = df[df.duplicated(keep=False)]\nprint(f\"Found {len(duplicates)} duplicates\")\n```\n\n---\n\n## üéØ Your Task\n\nFind and count duplicate rows.",
    "starter_code": "import pandas as pd\n\ndf = pd.DataFrame({\n    'id': [1, 2, 2, 3, 3, 3],\n    'name': ['A', 'B', 'B', 'C', 'C', 'C']\n})\n\n# Find duplicates\ndupes = None  # Your code\n\nprint(f\"Duplicate rows: {len(dupes)}\")\nprint(dupes)",
    "solution_code": "import pandas as pd\n\ndf = pd.DataFrame({\n    'id': [1, 2, 2, 3, 3, 3],\n    'name': ['A', 'B', 'B', 'C', 'C', 'C']\n})\n\n# Find duplicates\ndupes = df[df.duplicated(keep=False)]\n\nprint(f\"Duplicate rows: {len(dupes)}\")\nprint(dupes)",
    "expected_output": "Duplicate rows: 5\n   id name\n1   2    B\n2   2    B\n3   3    C\n4   3    C\n5   3    C",
    "chapter_id": 96,
    "chapter_title": "Data Cleaning"
  },
  "223": {
    "id": 223,
    "title": "Smart Dedup",
    "content": "# üéØ Smart Deduplication\n\n## Keeping Specific Records\n\n```python\n# Keep last occurrence\ndf.drop_duplicates(subset=['id'], keep='last')\n```\n\n---\n\n## üéØ Your Task\n\nKeep only the most recent record for each user.",
    "starter_code": "import pandas as pd\n\ndf = pd.DataFrame({\n    'user_id': [1, 1, 2, 2, 2],\n    'date': ['2024-01-01', '2024-01-15', '2024-01-05', '2024-01-10', '2024-01-20'],\n    'value': [100, 150, 200, 250, 300]\n})\n\n# Keep latest record per user\nresult = None  # Your code\n\nprint(result)",
    "solution_code": "import pandas as pd\n\ndf = pd.DataFrame({\n    'user_id': [1, 1, 2, 2, 2],\n    'date': ['2024-01-01', '2024-01-15', '2024-01-05', '2024-01-10', '2024-01-20'],\n    'value': [100, 150, 200, 250, 300]\n})\n\n# Keep latest record per user\ndf = df.sort_values('date')\nresult = df.drop_duplicates(subset=['user_id'], keep='last')\n\nprint(result)",
    "expected_output": "   user_id        date  value\n1        1  2024-01-15    150\n4        2  2024-01-20    300",
    "chapter_id": 96,
    "chapter_title": "Data Cleaning"
  },
  "224": {
    "id": 224,
    "title": "Regex Cleanup",
    "content": "# üîç Regex for Cleanup\n\n## Pattern-Based Cleaning\n\n```python\nimport re\ncleaned = re.sub(r'[^a-zA-Z0-9]', '', text)\n```\n\n---\n\n## üéØ Your Task\n\nRemove all non-alphanumeric characters from names.",
    "starter_code": "import re\nimport pandas as pd\n\ndf = pd.DataFrame({'name': ['John-Doe', 'Jane.Smith', 'Bob_Jones']})\n\n# Remove special characters\ndf['clean_name'] = df['name'].apply(lambda x: re.sub(r'[^a-zA-Z]', '', x))\n\nprint(df)",
    "solution_code": "import re\nimport pandas as pd\n\ndf = pd.DataFrame({'name': ['John-Doe', 'Jane.Smith', 'Bob_Jones']})\n\n# Remove special characters\ndf['clean_name'] = df['name'].apply(lambda x: re.sub(r'[^a-zA-Z]', '', x))\n\nprint(df)",
    "expected_output": "          name clean_name\n0     John-Doe    JohnDoe\n1   Jane.Smith  JaneSmith\n2    Bob_Jones   BobJones",
    "chapter_id": 96,
    "chapter_title": "Data Cleaning"
  },
  "225": {
    "id": 225,
    "title": "Standardize Format",
    "content": "# üìè Format Standardization\n\n## Consistent Formatting\n\n```python\ndf['phone'] = df['phone'].str.replace(r'[^0-9]', '', regex=True)\n```\n\n---\n\n## üéØ Your Task\n\nStandardize phone numbers to digits only.",
    "starter_code": "import pandas as pd\n\ndf = pd.DataFrame({'phone': ['(555) 123-4567', '555.123.4567', '555-123-4567']})\n\n# Standardize to digits only\ndf['clean_phone'] = df['phone'].str.replace(r'[^0-9]', '', regex=True)\n\nprint(df)",
    "solution_code": "import pandas as pd\n\ndf = pd.DataFrame({'phone': ['(555) 123-4567', '555.123.4567', '555-123-4567']})\n\n# Standardize to digits only\ndf['clean_phone'] = df['phone'].str.replace(r'[^0-9]', '', regex=True)\n\nprint(df)",
    "expected_output": "            phone clean_phone\n0  (555) 123-4567  5551234567\n1    555.123.4567  5551234567\n2    555-123-4567  5551234567",
    "chapter_id": 96,
    "chapter_title": "Data Cleaning"
  },
  "226": {
    "id": 226,
    "title": "Batch Conversion",
    "content": "# üîÑ Batch Type Conversion\n\n## Converting Multiple Columns\n\n```python\ndf[cols] = df[cols].astype(float)\n```\n\n---\n\n## üéØ Your Task\n\nConvert multiple columns to numeric.",
    "starter_code": "import pandas as pd\n\ndf = pd.DataFrame({\n    'a': ['1', '2', '3'],\n    'b': ['4.5', '5.5', '6.5'],\n    'c': ['7', '8', '9']\n})\n\n# Convert all columns to numeric\nfor col in df.columns:\n    df[col] = pd.to_numeric(df[col])\n\nprint(df.dtypes)",
    "solution_code": "import pandas as pd\n\ndf = pd.DataFrame({\n    'a': ['1', '2', '3'],\n    'b': ['4.5', '5.5', '6.5'],\n    'c': ['7', '8', '9']\n})\n\n# Convert all columns to numeric\nfor col in df.columns:\n    df[col] = pd.to_numeric(df[col])\n\nprint(df.dtypes)",
    "expected_output": "a      int64\nb    float64\nc      int64\ndtype: object",
    "chapter_id": 96,
    "chapter_title": "Data Cleaning"
  },
  "227": {
    "id": 227,
    "title": "Error Handling",
    "content": "# ‚ö†Ô∏è Handling Conversion Errors\n\n## Graceful Error Handling\n\n```python\npd.to_numeric(df['col'], errors='coerce')  # Invalid becomes NaN\n```\n\n---\n\n## üéØ Your Task\n\nConvert to numeric, handling errors gracefully.",
    "starter_code": "import pandas as pd\n\ndf = pd.DataFrame({'value': ['100', '200', 'N/A', '400', 'invalid']})\n\n# Convert with error handling\ndf['numeric'] = pd.to_numeric(df['value'], errors='coerce')\n\nprint(df)",
    "solution_code": "import pandas as pd\n\ndf = pd.DataFrame({'value': ['100', '200', 'N/A', '400', 'invalid']})\n\n# Convert with error handling\ndf['numeric'] = pd.to_numeric(df['value'], errors='coerce')\n\nprint(df)",
    "expected_output": "     value  numeric\n0      100    100.0\n1      200    200.0\n2      N/A      NaN\n3      400    400.0\n4  invalid      NaN",
    "chapter_id": 96,
    "chapter_title": "Data Cleaning"
  },
  "228": {
    "title": "Weighted Mean",
    "chapter_title": "Statistics",
    "content": "# ‚öñÔ∏è Weighted Mean: When Not All Values Are Equal\n\n## What is a Weighted Mean?\n\nIn a regular mean, every value counts equally. But what if some values are MORE important? That's where **weighted mean** comes in!\n\n## Real-World Analogy\n\nYour final grade isn't a simple average‚Äîexams (worth 60%) matter more than homework (worth 40%):\n\n| Component | Score | Weight |\n|-----------|-------|--------|\n| Homework | 95 | 40% |\n| Exam | 80 | 60% |\n\nSimple average: (95 + 80) / 2 = 87.5\nWeighted average: (95 √ó 0.4) + (80 √ó 0.6) = 38 + 48 = **86**\n\nThe exam pulls your grade down more because it's weighted higher!\n\n## The Formula\n\n```python\nweighted_mean = sum(value √ó weight) / sum(weights)\n```\n\n## Using NumPy\n\n```python\nimport numpy as np\n\nscores = np.array([95, 80])\nweights = np.array([0.4, 0.6])\n\nweighted_avg = np.average(scores, weights=weights)\nprint(weighted_avg)  # 86.0\n```\n\n## When to Use\n\n‚úÖ Grading systems with different component weights\n‚úÖ Financial portfolio returns\n‚úÖ Survey data where some responses are more reliable\n‚úÖ Moving averages in time series\n\n---\n\n## üéØ Your Task\n\nYou're analyzing customer satisfaction scores from different regions. Each region has a different number of customers (the weight). Calculate the weighted average satisfaction score!\n\n**Data:**\n- Region A: Score 4.2, 1000 customers\n- Region B: Score 4.8, 500 customers\n- Region C: Score 3.9, 2000 customers",
    "starter_code": "import numpy as np\n\n# Satisfaction scores by region\nscores = np.array([4.2, 4.8, 3.9])\n\n# Number of customers in each region (weights)\ncustomers = np.array([1000, 500, 2000])\n\n# Calculate weighted average satisfaction\n# Hint: Use np.average() with the weights parameter\nweighted_satisfaction = None  # Your code here\n\nprint(f\"Weighted Average Satisfaction: {weighted_satisfaction:.2f} / 5.0\")",
    "solution_code": "import numpy as np\n\n# Satisfaction scores by region\nscores = np.array([4.2, 4.8, 3.9])\n\n# Number of customers in each region (weights)\ncustomers = np.array([1000, 500, 2000])\n\n# Calculate weighted average satisfaction\nweighted_satisfaction = np.average(scores, weights=customers)\n\nprint(f\"Weighted Average Satisfaction: {weighted_satisfaction:.2f} / 5.0\")",
    "expected_output": "Weighted Average Satisfaction: 4.09 / 5.0"
  },
  "229": {
    "title": "Central Tendency Challenge",
    "chapter_title": "Statistics",
    "content": "# üèÜ Central Tendency Challenge: Salary Analysis\n\n## The Scenario\n\nYou're a data analyst at a tech company. HR wants to understand the salary distribution to make fair hiring decisions. But here's the twist‚Äî**the CEO makes $10 million!**\n\n## Why This Matters\n\nThis challenge demonstrates a critical real-world problem: **extreme outliers** can dramatically affect some statistics but not others.\n\n## What You'll Calculate\n\n1. **Mean**: The arithmetic average\n2. **Median**: The middle value\n3. **Mode**: The most common value\n4. **Impact Analysis**: How the CEO's salary affects each measure\n\n## The Dataset\n\n```python\n# Regular employees (in thousands)\nsalaries = [65, 72, 68, 75, 70, 72, 80, 72, 85, 78]\n\n# With CEO included\nsalaries_with_ceo = [65, 72, 68, 75, 70, 72, 80, 72, 85, 78, 10000]\n```\n\n## Key Insight Preview\n\nYou'll discover why **median** is often called \"resistant\" or \"robust\"‚Äîit doesn't get pulled by outliers!\n\n---\n\n## üéØ Your Task\n\n1. Calculate mean, median, and mode for the regular salaries\n2. Calculate the same for salaries WITH the CEO\n3. Calculate the percentage change in each statistic\n4. Determine which measure is most \"robust\" to outliers",
    "starter_code": "import numpy as np\nfrom collections import Counter\n\n# Salaries in thousands\nregular_salaries = np.array([65, 72, 68, 75, 70, 72, 80, 72, 85, 78])\nwith_ceo = np.array([65, 72, 68, 75, 70, 72, 80, 72, 85, 78, 10000])\n\n# Calculate for regular salaries\nmean_regular = np.mean(regular_salaries)\nmedian_regular = np.median(regular_salaries)\nmode_regular = Counter(regular_salaries).most_common(1)[0][0]\n\n# Calculate for salaries with CEO\nmean_ceo = np.mean(with_ceo)\nmedian_ceo = np.median(with_ceo)\nmode_ceo = Counter(with_ceo).most_common(1)[0][0]\n\n# Calculate percentage change\nmean_change = ((mean_ceo - mean_regular) / mean_regular) * 100\nmedian_change = ((median_ceo - median_regular) / median_regular) * 100\n\nprint(\"=== Regular Salaries ===\")\nprint(f\"Mean: ${mean_regular}K\")\nprint(f\"Median: ${median_regular}K\")\nprint(f\"Mode: ${mode_regular}K\")\n\nprint(\"\\n=== With CEO ($10M) ===\")\nprint(f\"Mean: ${mean_ceo:.1f}K\")\nprint(f\"Median: ${median_ceo}K\")\nprint(f\"Mode: ${mode_ceo}K\")\n\nprint(\"\\n=== Outlier Impact ===\")\nprint(f\"Mean changed by: {mean_change:.1f}%\")\nprint(f\"Median changed by: {median_change:.1f}%\")\nprint(f\"\\nMost robust measure: {'Median' if median_change < mean_change else 'Mean'}\")",
    "solution_code": "import numpy as np\nfrom collections import Counter\n\nregular_salaries = np.array([65, 72, 68, 75, 70, 72, 80, 72, 85, 78])\nwith_ceo = np.array([65, 72, 68, 75, 70, 72, 80, 72, 85, 78, 10000])\n\nmean_regular = np.mean(regular_salaries)\nmedian_regular = np.median(regular_salaries)\nmode_regular = Counter(regular_salaries).most_common(1)[0][0]\n\nmean_ceo = np.mean(with_ceo)\nmedian_ceo = np.median(with_ceo)\nmode_ceo = Counter(with_ceo).most_common(1)[0][0]\n\nmean_change = ((mean_ceo - mean_regular) / mean_regular) * 100\nmedian_change = ((median_ceo - median_regular) / median_regular) * 100\n\nprint(\"=== Regular Salaries ===\")\nprint(f\"Mean: ${mean_regular}K\")\nprint(f\"Median: ${median_regular}K\")\nprint(f\"Mode: ${mode_regular}K\")\n\nprint(\"\\n=== With CEO ($10M) ===\")\nprint(f\"Mean: ${mean_ceo:.1f}K\")\nprint(f\"Median: ${median_ceo}K\")\nprint(f\"Mode: ${mode_ceo}K\")\n\nprint(\"\\n=== Outlier Impact ===\")\nprint(f\"Mean changed by: {mean_change:.1f}%\")\nprint(f\"Median changed by: {median_change:.1f}%\")\nprint(f\"\\nMost robust measure: Median\")",
    "expected_output": "=== Regular Salaries ===\nMean: $73.7K\nMedian: $72.0K\nMode: $72K\n\n=== With CEO ($10M) ===\nMean: $983.4K\nMedian: $72.0K\nMode: $72K\n\n=== Outlier Impact ===\nMean changed by: 1234.0%\nMedian changed by: 0.0%\n\nMost robust measure: Median"
  },
  "230": {
    "title": "Interquartile Range (IQR)",
    "chapter_title": "Statistics",
    "content": "# üìä IQR: The Outlier-Resistant Spread\n\n## What is the IQR?\n\nThe **Interquartile Range (IQR)** measures the spread of the middle 50% of your data. It's calculated as:\n\n```\nIQR = Q3 - Q1\n```\n\nWhere Q1 is the 25th percentile and Q3 is the 75th percentile.\n\n## Why IQR is Powerful\n\nUnlike range (max - min), IQR ignores extreme values! It only looks at the middle portion of your data.\n\n## Visual Representation\n\n```\nData: [1, 2, 3, 4, 5, 6, 7, 8, 9, 100]\n       ‚Üë           ‚Üë           ‚Üë\n      Q1=2.5      Q2=5.5     Q3=7.5\n      \nRange = 100 - 1 = 99 (affected by outlier!)\nIQR = 7.5 - 2.5 = 5 (ignores outlier!)\n```\n\n## Using IQR for Outlier Detection\n\nA value is considered an outlier if:\n- Below: Q1 - 1.5 √ó IQR\n- Above: Q3 + 1.5 √ó IQR\n\n## Using NumPy\n\n```python\nimport numpy as np\n\ndata = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 100])\nq1 = np.percentile(data, 25)\nq3 = np.percentile(data, 75)\niqr = q3 - q1\n\n# Outlier boundaries\nlower_bound = q1 - 1.5 * iqr\nupper_bound = q3 + 1.5 * iqr\n```\n\n---\n\n## üéØ Your Task\n\nAnalyze house prices and identify any outliers using the IQR method.",
    "starter_code": "import numpy as np\n\n# House prices (in thousands)\nprices = np.array([250, 275, 300, 285, 295, 310, 280, 290, 305, 750, 270, 295])\n\n# Calculate Q1, Q3, and IQR\nq1 = np.percentile(prices, 25)\nq3 = np.percentile(prices, 75)\niqr = q3 - q1\n\n# Calculate outlier boundaries\nlower_bound = q1 - 1.5 * iqr\nupper_bound = q3 + 1.5 * iqr\n\n# Find outliers\noutliers = prices[(prices < lower_bound) | (prices > upper_bound)]\n\nprint(f\"Q1 (25th percentile): ${q1}K\")\nprint(f\"Q3 (75th percentile): ${q3}K\")\nprint(f\"IQR: ${iqr}K\")\nprint(f\"\\nOutlier Boundaries: ${lower_bound:.1f}K to ${upper_bound:.1f}K\")\nprint(f\"Outliers found: {outliers}\")",
    "solution_code": "import numpy as np\n\nprices = np.array([250, 275, 300, 285, 295, 310, 280, 290, 305, 750, 270, 295])\n\nq1 = np.percentile(prices, 25)\nq3 = np.percentile(prices, 75)\niqr = q3 - q1\n\nlower_bound = q1 - 1.5 * iqr\nupper_bound = q3 + 1.5 * iqr\n\noutliers = prices[(prices < lower_bound) | (prices > upper_bound)]\n\nprint(f\"Q1 (25th percentile): ${q1}K\")\nprint(f\"Q3 (75th percentile): ${q3}K\")\nprint(f\"IQR: ${iqr}K\")\nprint(f\"\\nOutlier Boundaries: ${lower_bound:.1f}K to ${upper_bound:.1f}K\")\nprint(f\"Outliers found: {outliers}\")",
    "expected_output": "Q1 (25th percentile): $278.75K\nQ3 (75th percentile): $301.25K\nIQR: $22.5K\n\nOutlier Boundaries: $245.0K to $335.0K\nOutliers found: [750]"
  },
  "231": {
    "title": "Outlier Detection Challenge",
    "chapter_title": "Statistics",
    "content": "# üîç Outlier Detection Challenge: Quality Control\n\n## The Scenario\n\nYou're a quality control analyst at a manufacturing plant. Products coming off the assembly line should be between 9.5cm and 10.5cm. But some defective products slip through!\n\n## Your Mission\n\nUse statistical outlier detection to automatically flag potentially defective products. You'll use BOTH methods:\n\n1. **IQR Method**: Flag values outside Q1 - 1.5√óIQR or Q3 + 1.5√óIQR\n2. **Z-Score Method**: Flag values where |Z| > 2\n\n## Why Two Methods?\n\n| Method | Best For | Limitation |\n|--------|----------|------------|\n| IQR | Non-normal data, resistant to extreme outliers | May miss outliers in small datasets |\n| Z-Score | Normal distributions, quantifies \"how unusual\" | Assumes normal distribution |\n\n## The Manufacturing Data\n\n100 product measurements with some defects mixed in:\n\n```python\n# Most are around 10cm, but some are clearly wrong!\nmeasurements = [9.8, 10.1, 9.9, 10.2, 8.5, 10.0, ...]\n```\n\n---\n\n## üéØ Your Task\n\n1. Detect outliers using the IQR method\n2. Detect outliers using the Z-score method\n3. Compare which products each method flags\n4. Determine which products should be rejected from the assembly line",
    "starter_code": "import numpy as np\n\n# 50 product measurements (cm)\nnp.random.seed(42)\nnormal_products = np.random.normal(10, 0.2, 45)  # Most around 10cm\ndefects = np.array([8.5, 11.8, 7.9, 12.1, 8.2])  # Known defects\n\nmeasurements = np.concatenate([normal_products, defects])\nnp.random.shuffle(measurements)\n\n# IQR Method\nq1 = np.percentile(measurements, 25)\nq3 = np.percentile(measurements, 75)\niqr = q3 - q1\niqr_lower = q1 - 1.5 * iqr\niqr_upper = q3 + 1.5 * iqr\niqr_outliers = measurements[(measurements < iqr_lower) | (measurements > iqr_upper)]\n\n# Z-Score Method\nmean = np.mean(measurements)\nstd = np.std(measurements)\nz_scores = (measurements - mean) / std\nzscore_outliers = measurements[np.abs(z_scores) > 2]\n\nprint(f\"=== IQR Method ===\")\nprint(f\"Bounds: {iqr_lower:.2f} to {iqr_upper:.2f}\")\nprint(f\"Outliers found: {len(iqr_outliers)}\")\nprint(f\"Values: {np.round(iqr_outliers, 2)}\")\n\nprint(f\"\\n=== Z-Score Method ===\")\nprint(f\"Mean: {mean:.2f}, Std: {std:.2f}\")\nprint(f\"Outliers found: {len(zscore_outliers)}\")\nprint(f\"Values: {np.round(zscore_outliers, 2)}\")",
    "solution_code": "import numpy as np\n\nnp.random.seed(42)\nnormal_products = np.random.normal(10, 0.2, 45)\ndefects = np.array([8.5, 11.8, 7.9, 12.1, 8.2])\nmeasurements = np.concatenate([normal_products, defects])\nnp.random.shuffle(measurements)\n\nq1 = np.percentile(measurements, 25)\nq3 = np.percentile(measurements, 75)\niqr = q3 - q1\niqr_lower = q1 - 1.5 * iqr\niqr_upper = q3 + 1.5 * iqr\niqr_outliers = measurements[(measurements < iqr_lower) | (measurements > iqr_upper)]\n\nmean = np.mean(measurements)\nstd = np.std(measurements)\nz_scores = (measurements - mean) / std\nzscore_outliers = measurements[np.abs(z_scores) > 2]\n\nprint(f\"=== IQR Method ===\")\nprint(f\"Bounds: {iqr_lower:.2f} to {iqr_upper:.2f}\")\nprint(f\"Outliers found: {len(iqr_outliers)}\")\nprint(f\"Values: {np.round(iqr_outliers, 2)}\")\n\nprint(f\"\\n=== Z-Score Method ===\")\nprint(f\"Mean: {mean:.2f}, Std: {std:.2f}\")\nprint(f\"Outliers found: {len(zscore_outliers)}\")\nprint(f\"Values: {np.round(zscore_outliers, 2)}\")",
    "expected_output": "=== IQR Method ===\nBounds: 9.47 to 10.49\nOutliers found: 5\nValues: [ 8.5  11.8  7.9  12.1  8.2 ]"
  },
  "232": {
    "title": "Covariance",
    "chapter_title": "Statistics",
    "content": "# üìâ Covariance: Do They Move Together?\n\n## What is Covariance?\n\n**Covariance** measures whether two variables tend to increase or decrease together. Unlike correlation (which is standardized), covariance is in the original units!\n\n## Positive vs Negative Covariance\n\n| Sign | Relationship | Example |\n|------|-------------|---------|\n| Positive | Both increase together | Height & Weight |\n| Negative | One increases, other decreases | Price & Demand |\n| Near Zero | No relationship | Shoe size & IQ |\n\n## The Intuition\n\nCovariance asks: \"When X is above its mean, is Y also above its mean?\"\n\n```python\n# If both are above OR both below their means: positive contribution\n# If one is above and one is below: negative contribution\n```\n\n## Using NumPy\n\n```python\nimport numpy as np\n\nx = np.array([1, 2, 3, 4, 5])\ny = np.array([2, 4, 5, 4, 5])\n\n# Covariance matrix\ncov_matrix = np.cov(x, y)\ncovariance = cov_matrix[0, 1]  # The off-diagonal element\n```\n\n## Covariance vs Correlation\n\n| Measure | Range | Interpretation |\n|---------|-------|----------------|\n| Covariance | -‚àû to +‚àû | Hard to interpret |\n| Correlation | -1 to +1 | Easy: 0.9 = strong! |\n\nCorrelation = Covariance / (std_x √ó std_y)\n\n---\n\n## üéØ Your Task\n\nCalculate the covariance between advertising spend and sales revenue. Then verify using correlation!",
    "starter_code": "import numpy as np\n\n# Monthly data\nad_spend = np.array([1000, 1500, 2000, 2500, 3000, 3500, 4000])\nsales = np.array([10000, 12000, 15000, 18000, 20000, 22000, 25000])\n\n# Calculate covariance\ncov_matrix = np.cov(ad_spend, sales)\ncovariance = cov_matrix[0, 1]\n\n# Also calculate correlation for reference\ncorrelation = np.corrcoef(ad_spend, sales)[0, 1]\n\nprint(f\"Covariance: {covariance:,.0f}\")\nprint(f\"Correlation: {correlation:.3f}\")\n\n# Interpret\nif covariance > 0:\n    print(\"\\nüìà Positive covariance: Ad spend and sales move together!\")\nelif covariance < 0:\n    print(\"\\nüìâ Negative covariance: They move in opposite directions!\")",
    "solution_code": "import numpy as np\n\nad_spend = np.array([1000, 1500, 2000, 2500, 3000, 3500, 4000])\nsales = np.array([10000, 12000, 15000, 18000, 20000, 22000, 25000])\n\ncov_matrix = np.cov(ad_spend, sales)\ncovariance = cov_matrix[0, 1]\n\ncorrelation = np.corrcoef(ad_spend, sales)[0, 1]\n\nprint(f\"Covariance: {covariance:,.0f}\")\nprint(f\"Correlation: {correlation:.3f}\")\n\nif covariance > 0:\n    print(\"\\nüìà Positive covariance: Ad spend and sales move together!\")",
    "expected_output": "Covariance: 5,833,333\nCorrelation: 0.998\n\nüìà Positive covariance: Ad spend and sales move together!"
  },
  "233": {
    "title": "Statistical Analysis Project",
    "chapter_title": "Statistics",
    "content": "# üèÜ Statistical Analysis Project: Sales Performance\n\n## The Grand Challenge\n\nYou're the head of analytics at a retail company. The CEO wants a COMPLETE statistical analysis of this quarter's sales data to present to the board. This is your moment to shine!\n\n## What the Board Needs\n\n1. **Central Tendency**: What's our \"typical\" daily sales?\n2. **Spread**: How consistent are we day-to-day?\n3. **Outliers**: Any unusually good or bad days?\n4. **Trends**: Are weekends different from weekdays?\n\n## The Dataset\n\n90 days of sales data with:\n- Regular weekday sales\n- Weekend boosts\n- Some holiday spikes\n- One Black Friday blockbuster\n\n## Your Deliverables\n\nGenerate a comprehensive report with:\n- Mean, Median, Mode\n- Standard Deviation, IQR\n- Outlier identification\n- Summary insights\n\n---\n\n## üéØ Your Task\n\nComplete the analysis and generate an executive summary that even non-technical board members can understand!",
    "starter_code": "import numpy as np\nfrom collections import Counter\n\nnp.random.seed(42)\n\n# Generate realistic sales data\nweekday_sales = np.random.normal(5000, 800, 65)  # Weekdays\nweekend_sales = np.random.normal(8000, 1200, 20)  # Weekends (higher)\nblack_friday = np.array([25000])  # One massive day\nholidays = np.random.normal(3000, 500, 4)  # Slow holiday days\n\nall_sales = np.concatenate([weekday_sales, weekend_sales, black_friday, holidays])\nnp.random.shuffle(all_sales)\n\n# === YOUR ANALYSIS ===\n\n# Central Tendency\nmean_sales = np.mean(all_sales)\nmedian_sales = np.median(all_sales)\n\n# Spread\nstd_sales = np.std(all_sales)\nq1 = np.percentile(all_sales, 25)\nq3 = np.percentile(all_sales, 75)\niqr = q3 - q1\n\n# Outliers (IQR method)\nlower = q1 - 1.5 * iqr\nupper = q3 + 1.5 * iqr\noutliers = all_sales[(all_sales < lower) | (all_sales > upper)]\n\n# Generate Executive Summary\nprint(\"=\" * 50)\nprint(\"üìä QUARTERLY SALES ANALYSIS - EXECUTIVE SUMMARY\")\nprint(\"=\" * 50)\nprint(f\"\\nüìà Central Tendency:\")\nprint(f\"   ‚Ä¢ Average Daily Sales: ${mean_sales:,.0f}\")\nprint(f\"   ‚Ä¢ Median Daily Sales: ${median_sales:,.0f}\")\nprint(f\"\\nüìè Variability:\")\nprint(f\"   ‚Ä¢ Standard Deviation: ${std_sales:,.0f}\")\nprint(f\"   ‚Ä¢ Interquartile Range: ${iqr:,.0f}\")\nprint(f\"\\nüîç Outlier Analysis:\")\nprint(f\"   ‚Ä¢ {len(outliers)} unusual days detected\")\nprint(f\"   ‚Ä¢ Notable outliers: {np.round(outliers, 0)}\")",
    "solution_code": "import numpy as np\n\nnp.random.seed(42)\n\nweekday_sales = np.random.normal(5000, 800, 65)\nweekend_sales = np.random.normal(8000, 1200, 20)\nblack_friday = np.array([25000])\nholidays = np.random.normal(3000, 500, 4)\n\nall_sales = np.concatenate([weekday_sales, weekend_sales, black_friday, holidays])\n\nmean_sales = np.mean(all_sales)\nmedian_sales = np.median(all_sales)\nstd_sales = np.std(all_sales)\nq1 = np.percentile(all_sales, 25)\nq3 = np.percentile(all_sales, 75)\niqr = q3 - q1\n\nlower = q1 - 1.5 * iqr\nupper = q3 + 1.5 * iqr\noutliers = all_sales[(all_sales < lower) | (all_sales > upper)]\n\nprint(\"=\" * 50)\nprint(\"üìä QUARTERLY SALES ANALYSIS - EXECUTIVE SUMMARY\")\nprint(\"=\" * 50)\nprint(f\"\\nüìà Central Tendency:\")\nprint(f\"   ‚Ä¢ Average Daily Sales: ${mean_sales:,.0f}\")\nprint(f\"   ‚Ä¢ Median Daily Sales: ${median_sales:,.0f}\")\nprint(f\"\\nüìè Variability:\")\nprint(f\"   ‚Ä¢ Standard Deviation: ${std_sales:,.0f}\")\nprint(f\"   ‚Ä¢ Interquartile Range: ${iqr:,.0f}\")\nprint(f\"\\nüîç Outlier Analysis:\")\nprint(f\"   ‚Ä¢ {len(outliers)} unusual days detected\")",
    "expected_output": "QUARTERLY SALES ANALYSIS - EXECUTIVE SUMMARY"
  },
  "234": {
    "title": "Feature Engineering Basics",
    "chapter_title": "Machine Learning Intro",
    "content": "# üîß Feature Engineering: Creating Better Inputs\n\n## What is Feature Engineering?\n\nRaw data rarely comes in the perfect format for ML. **Feature engineering** transforms raw data into features that better represent the underlying patterns!\n\n## Real-World Analogy\n\nImagine predicting house prices. The raw data might just have \"address\". But you can engineer features like:\n- Distance to downtown\n- School district rating\n- Crime rate of neighborhood\n\nThese engineered features are MORE useful than the raw address!\n\n## Common Techniques\n\n### 1. Mathematical Transformations\n```python\n# Log transform for skewed data\ndf['log_income'] = np.log(df['income'])\n\n# Square for polynomial relationships\ndf['age_squared'] = df['age'] ** 2\n```\n\n### 2. Combining Features\n```python\n# Ratios\ndf['price_per_sqft'] = df['price'] / df['sqft']\n\n# Interactions\ndf['income_x_age'] = df['income'] * df['age']\n```\n\n### 3. Extracting from Dates\n```python\ndf['day_of_week'] = df['date'].dt.dayofweek\ndf['is_weekend'] = df['day_of_week'] >= 5\n```\n\n### 4. Binning/Bucketing\n```python\ndf['age_group'] = pd.cut(df['age'], bins=[0, 18, 35, 55, 100])\n```\n\n---\n\n## üéØ Your Task\n\nEngineer useful features from customer data to improve churn prediction!",
    "starter_code": "import pandas as pd\nimport numpy as np\n\n# Customer data\ndf = pd.DataFrame({\n    'customer_id': range(1, 11),\n    'tenure_days': [30, 365, 730, 60, 180, 90, 450, 1095, 15, 240],\n    'monthly_charges': [50, 75, 60, 45, 85, 55, 95, 70, 40, 65],\n    'total_charges': [50, 2737, 4380, 90, 1530, 495, 4275, 7665, 20, 1560]\n})\n\n# Feature Engineering\n\n# 1. Tenure in months (more interpretable)\ndf['tenure_months'] = df['tenure_days'] / 30\n\n# 2. Average monthly spend (charges / tenure)\ndf['avg_monthly'] = df['total_charges'] / (df['tenure_days'] / 30)\n\n# 3. Customer \"value\" indicator\ndf['is_high_value'] = (df['monthly_charges'] > 70).astype(int)\n\n# 4. New customer flag\ndf['is_new'] = (df['tenure_days'] < 90).astype(int)\n\nprint(\"Original columns:\", ['customer_id', 'tenure_days', 'monthly_charges', 'total_charges'])\nprint(\"\\nNew engineered features:\")\nprint(df[['customer_id', 'tenure_months', 'avg_monthly', 'is_high_value', 'is_new']].to_string())",
    "solution_code": "import pandas as pd\nimport numpy as np\n\ndf = pd.DataFrame({\n    'customer_id': range(1, 11),\n    'tenure_days': [30, 365, 730, 60, 180, 90, 450, 1095, 15, 240],\n    'monthly_charges': [50, 75, 60, 45, 85, 55, 95, 70, 40, 65],\n    'total_charges': [50, 2737, 4380, 90, 1530, 495, 4275, 7665, 20, 1560]\n})\n\ndf['tenure_months'] = df['tenure_days'] / 30\ndf['avg_monthly'] = df['total_charges'] / (df['tenure_days'] / 30)\ndf['is_high_value'] = (df['monthly_charges'] > 70).astype(int)\ndf['is_new'] = (df['tenure_days'] < 90).astype(int)\n\nprint(\"Original columns:\", ['customer_id', 'tenure_days', 'monthly_charges', 'total_charges'])\nprint(\"\\nNew engineered features:\")\nprint(df[['customer_id', 'tenure_months', 'avg_monthly', 'is_high_value', 'is_new']].to_string())",
    "expected_output": "New engineered features:"
  },
  "235": {
    "title": "Data Preprocessing Pipeline",
    "chapter_title": "Machine Learning Intro",
    "content": "# üîÑ Data Preprocessing Pipeline: Organized ML Prep\n\n## The Problem with Ad-Hoc Preprocessing\n\nWhen you preprocess training data one way and test data another way, your model fails! A **pipeline** ensures consistent transformations.\n\n## What is a Pipeline?\n\nA Pipeline chains multiple preprocessing steps into a single object that:\n1. Fits on training data\n2. Transforms both train and test data identically\n3. Prevents data leakage\n\n## Visual Flow\n\n```\nRaw Data ‚Üí [Scale] ‚Üí [Encode] ‚Üí [Select Features] ‚Üí ML Model\n           \\_____Pipeline chains these together____/\n```\n\n## Using sklearn Pipeline\n\n```python\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.svm import SVC\n\npipeline = Pipeline([\n    ('scaler', StandardScaler()),\n    ('classifier', SVC())\n])\n\n# Now one line does everything!\npipeline.fit(X_train, y_train)\npredictions = pipeline.predict(X_test)\n```\n\n## Why Pipelines Matter\n\n‚úÖ No data leakage (test data never influences scaling)\n‚úÖ Reproducible (same preprocessing every time)\n‚úÖ Cleaner code (one object instead of many steps)\n‚úÖ Easy deployment (save one pipeline object)\n\n---\n\n## üéØ Your Task\n\nBuild a preprocessing pipeline that scales features and trains a KNN classifier!",
    "starter_code": "from sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.datasets import load_wine\nfrom sklearn.model_selection import train_test_split\n\n# Load data\nwine = load_wine()\nX_train, X_test, y_train, y_test = train_test_split(\n    wine.data, wine.target, test_size=0.2, random_state=42\n)\n\n# Create pipeline: Scale then classify\npipeline = Pipeline([\n    ('scaler', StandardScaler()),\n    ('knn', KNeighborsClassifier(n_neighbors=5))\n])\n\n# One line does it all!\npipeline.fit(X_train, y_train)\n\n# Evaluate\naccuracy = pipeline.score(X_test, y_test)\nprint(f\"Pipeline Accuracy: {accuracy:.1%}\")",
    "solution_code": "from sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.datasets import load_wine\nfrom sklearn.model_selection import train_test_split\n\nwine = load_wine()\nX_train, X_test, y_train, y_test = train_test_split(\n    wine.data, wine.target, test_size=0.2, random_state=42\n)\n\npipeline = Pipeline([\n    ('scaler', StandardScaler()),\n    ('knn', KNeighborsClassifier(n_neighbors=5))\n])\n\npipeline.fit(X_train, y_train)\naccuracy = pipeline.score(X_test, y_test)\nprint(f\"Pipeline Accuracy: {accuracy:.1%}\")",
    "expected_output": "Pipeline Accuracy: 97.2%"
  },
  "236": {
    "title": "Training Your First Model",
    "chapter_title": "Machine Learning Intro",
    "content": "# üöÄ Training Your First Model: Hands-On Linear Regression\n\n## The Moment of Truth!\n\nIt's time to train your first real machine learning model. We'll predict a continuous value (regression) using linear regression.\n\n## The 4-Step ML Workflow\n\n```python\n# 1. Prepare Data\nX_train, X_test, y_train, y_test = train_test_split(...)\n\n# 2. Create Model\nmodel = LinearRegression()\n\n# 3. Train (Fit)\nmodel.fit(X_train, y_train)\n\n# 4. Predict & Evaluate\npredictions = model.predict(X_test)\n```\n\n## What Happens During Training?\n\nThe model finds the best line through your data by minimizing error:\n\n```\nError = Actual - Predicted\nGoal: Make total error as small as possible!\n```\n\n## After Training\n\nThe model learns:\n- **Coefficients (slopes)**: How much output changes per unit of input\n- **Intercept**: The baseline value when inputs are zero\n\n```python\nprint(model.coef_)      # [2.5] - Output increases 2.5 for each unit of input\nprint(model.intercept_)  # 10 - Starting point\n```\n\n---\n\n## üéØ Your Task\n\nTrain a linear regression model to predict study hours ‚Üí exam scores, then interpret the coefficients!",
    "starter_code": "from sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\n\n# Study hours and corresponding exam scores\nnp.random.seed(42)\nhours = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10]).reshape(-1, 1)\nscores = 10 * hours.flatten() + 40 + np.random.randn(10) * 3\n\n# Split data\nX_train, X_test, y_train, y_test = train_test_split(\n    hours, scores, test_size=0.3, random_state=42\n)\n\n# Create and train model\nmodel = LinearRegression()\nmodel.fit(X_train, y_train)\n\n# Make predictions\npredictions = model.predict(X_test)\n\n# Evaluate\nscore = model.score(X_test, y_test)\n\nprint(\"üéì Study Hours ‚Üí Exam Score Model\")\nprint(f\"\\nModel Equation: Score = {model.coef_[0]:.1f} √ó Hours + {model.intercept_:.1f}\")\nprint(f\"\\nInterpretation: Each hour of study = {model.coef_[0]:.1f} more points!\")\nprint(f\"R¬≤ Score: {score:.3f}\")",
    "solution_code": "from sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\n\nnp.random.seed(42)\nhours = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10]).reshape(-1, 1)\nscores = 10 * hours.flatten() + 40 + np.random.randn(10) * 3\n\nX_train, X_test, y_train, y_test = train_test_split(hours, scores, test_size=0.3, random_state=42)\n\nmodel = LinearRegression()\nmodel.fit(X_train, y_train)\n\npredictions = model.predict(X_test)\nscore = model.score(X_test, y_test)\n\nprint(\"üéì Study Hours ‚Üí Exam Score Model\")\nprint(f\"\\nModel Equation: Score = {model.coef_[0]:.1f} √ó Hours + {model.intercept_:.1f}\")\nprint(f\"\\nInterpretation: Each hour of study = {model.coef_[0]:.1f} more points!\")\nprint(f\"R¬≤ Score: {score:.3f}\")",
    "expected_output": "üéì Study Hours ‚Üí Exam Score Model\n\nModel Equation: Score = 10.2 √ó Hours + 39.2\n\nInterpretation: Each hour of study = 10.2 more points!"
  },
  "237": {
    "title": "Evaluating Regression Models",
    "chapter_title": "Machine Learning Intro",
    "content": "# üìè Evaluating Regression Models: Beyond R¬≤\n\n## R¬≤ Isn't Everything\n\nR¬≤ (coefficient of determination) is popular but has limitations. Let's explore multiple evaluation metrics!\n\n## Common Metrics\n\n### 1. R¬≤ Score (Coefficient of Determination)\n- How much variance is explained?\n- Range: 0 to 1 (higher is better)\n- Limitation: Can be misleading with non-linear data\n\n### 2. Mean Absolute Error (MAE)\n```python\nMAE = mean(|actual - predicted|)\n```\n- Average absolute difference\n- Same units as your target\n- Easy to interpret!\n\n### 3. Mean Squared Error (MSE)\n```python\nMSE = mean((actual - predicted)¬≤)\n```\n- Penalizes large errors more\n- In squared units (harder to interpret)\n\n### 4. Root Mean Squared Error (RMSE)\n```python\nRMSE = ‚àöMSE\n```\n- Back to original units\n- Standard measure in competitions\n\n## Which to Use?\n\n| Metric | When to Use |\n|--------|------------|\n| R¬≤ | Quick sanity check |\n| MAE | When all errors matter equally |\n| RMSE | When large errors are really bad |\n\n---\n\n## üéØ Your Task\n\nCompare multiple evaluation metrics for a house price prediction model!",
    "starter_code": "from sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\nimport numpy as np\n\n# House data: sqft ‚Üí price\nnp.random.seed(42)\nsqft = np.random.randint(800, 3000, 100).reshape(-1, 1)\nprice = 150 * sqft.flatten() + 50000 + np.random.randn(100) * 20000\n\nX_train, X_test, y_train, y_test = train_test_split(sqft, price, test_size=0.2, random_state=42)\n\n# Train model\nmodel = LinearRegression()\nmodel.fit(X_train, y_train)\npredictions = model.predict(X_test)\n\n# Calculate all metrics\nr2 = r2_score(y_test, predictions)\nmae = mean_absolute_error(y_test, predictions)\nmse = mean_squared_error(y_test, predictions)\nrmse = np.sqrt(mse)\n\nprint(\"üè† House Price Prediction Metrics\")\nprint(\"=\" * 40)\nprint(f\"R¬≤ Score: {r2:.3f}\")\nprint(f\"MAE: ${mae:,.0f}\")\nprint(f\"MSE: {mse:,.0f}\")\nprint(f\"RMSE: ${rmse:,.0f}\")\nprint(\"\\nüí° Interpretation:\")\nprint(f\"   On average, predictions are off by ${mae:,.0f}\")",
    "solution_code": "from sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\nimport numpy as np\n\nnp.random.seed(42)\nsqft = np.random.randint(800, 3000, 100).reshape(-1, 1)\nprice = 150 * sqft.flatten() + 50000 + np.random.randn(100) * 20000\n\nX_train, X_test, y_train, y_test = train_test_split(sqft, price, test_size=0.2, random_state=42)\n\nmodel = LinearRegression()\nmodel.fit(X_train, y_train)\npredictions = model.predict(X_test)\n\nr2 = r2_score(y_test, predictions)\nmae = mean_absolute_error(y_test, predictions)\nmse = mean_squared_error(y_test, predictions)\nrmse = np.sqrt(mse)\n\nprint(\"üè† House Price Prediction Metrics\")\nprint(\"=\" * 40)\nprint(f\"R¬≤ Score: {r2:.3f}\")\nprint(f\"MAE: ${mae:,.0f}\")\nprint(f\"MSE: {mse:,.0f}\")\nprint(f\"RMSE: ${rmse:,.0f}\")",
    "expected_output": "üè† House Price Prediction Metrics"
  },
  "240": {
    "title": "Precision vs Recall",
    "chapter_title": "Machine Learning Intro",
    "content": "# ‚öñÔ∏è Precision vs Recall: The Tradeoff\n\n## Why Accuracy Isn't Enough\n\nImagine a disease affects 1% of people. A model that ALWAYS predicts \"healthy\" gets 99% accuracy‚Äîbut misses every sick person!\n\n## Precision: \"When I predict positive, am I right?\"\n\n```\nPrecision = True Positives / All Predicted Positives\n```\n\nHigh precision = Few false alarms\n\n## Recall: \"Of all positives, how many did I find?\"\n\n```\nRecall = True Positives / All Actual Positives\n```\n\nHigh recall = Find most positive cases\n\n## The Tradeoff\n\n| Situation | Prioritize | Why |\n|-----------|-----------|-----|\n| Spam filter | Precision | Don't want real emails in spam! |\n| Cancer screening | Recall | Don't want to miss any cases! |\n| Fraud detection | Balance | Both matter |\n\n## The F1 Score\n\nBalances precision and recall:\n```python\nF1 = 2 √ó (Precision √ó Recall) / (Precision + Recall)\n```\n\n---\n\n## üéØ Your Task\n\nAnalyze a fraud detection model and understand the precision-recall tradeoff!",
    "starter_code": "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\nimport numpy as np\n\n# Simulated fraud detection results\n# 1 = Fraud, 0 = Legitimate\nnp.random.seed(42)\ny_true = np.array([0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0])\ny_pred = np.array([0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0])\n\n# Calculate metrics\nprecision = precision_score(y_true, y_pred)\nrecall = recall_score(y_true, y_pred)\nf1 = f1_score(y_true, y_pred)\n\n# Confusion matrix breakdown\ntn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n\nprint(\"üîç Fraud Detection Model Analysis\")\nprint(\"=\" * 45)\nprint(f\"\\nConfusion Matrix:\")\nprint(f\"   True Negatives (correct non-fraud): {tn}\")\nprint(f\"   False Positives (false alarms): {fp}\")\nprint(f\"   False Negatives (missed fraud): {fn}\")\nprint(f\"   True Positives (caught fraud): {tp}\")\nprint(f\"\\nüìä Performance Metrics:\")\nprint(f\"   Precision: {precision:.1%} (When we flag fraud, we're right this often)\")\nprint(f\"   Recall: {recall:.1%} (We catch this much of actual fraud)\")\nprint(f\"   F1 Score: {f1:.1%} (Balanced measure)\")",
    "solution_code": "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\nimport numpy as np\n\nnp.random.seed(42)\ny_true = np.array([0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0])\ny_pred = np.array([0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0])\n\nprecision = precision_score(y_true, y_pred)\nrecall = recall_score(y_true, y_pred)\nf1 = f1_score(y_true, y_pred)\n\ntn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n\nprint(\"üîç Fraud Detection Model Analysis\")\nprint(\"=\" * 45)\nprint(f\"\\nConfusion Matrix:\")\nprint(f\"   True Negatives: {tn}\")\nprint(f\"   False Positives: {fp}\")\nprint(f\"   False Negatives: {fn}\")\nprint(f\"   True Positives: {tp}\")\nprint(f\"\\nüìä Performance Metrics:\")\nprint(f\"   Precision: {precision:.1%}\")\nprint(f\"   Recall: {recall:.1%}\")\nprint(f\"   F1 Score: {f1:.1%}\")",
    "expected_output": "üîç Fraud Detection Model Analysis"
  }
}